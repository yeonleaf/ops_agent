#!/usr/bin/env python3
"""
Jira ë™ê¸°í™” ë°°ì¹˜ ë©”ì¸ ëª¨ë“ˆ

Jira APIë¥¼ í†µí•´ ì´ìŠˆë¥¼ ê°€ì ¸ì™€ UnifiedChunkë¡œ ë³€í™˜í•˜ê³ 
ChromaDBì— ì €ì¥í•©ë‹ˆë‹¤.
"""

import logging
import argparse
import sys
import os
from typing import Dict, List
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ë¡œì»¬ ëª¨ë“ˆ import
from batch.jira_config import (
    create_batch_history_table,
    load_jira_config,
    get_last_sync_time,
    update_batch_history
)
from batch.jira_client import JiraClient, JiraAPIError
from batch.chunking import build_jira_jql, process_issues_to_chunks
from models.unified_chunk import UnifiedChunk
from chromadb_singleton import get_chromadb_client

logger = logging.getLogger(__name__)


def save_chunks_to_chromadb(chunks: List[UnifiedChunk]) -> int:
    """
    UnifiedChunkë¥¼ ChromaDBì— ì €ì¥ (upsert)

    Args:
        chunks: UnifiedChunk ë¦¬ìŠ¤íŠ¸

    Returns:
        ì €ì¥ëœ ì²­í¬ ê°œìˆ˜

    Raises:
        Exception: ChromaDB ì €ì¥ ì‹¤íŒ¨ ì‹œ
    """
    if not chunks:
        logger.warning("âš ï¸ ì €ì¥í•  ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤")
        return 0

    try:
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
        client = get_chromadb_client()

        # jira_chunks ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°/ìƒì„±
        try:
            collection = client.get_collection("jira_chunks")
            logger.debug("âœ… ê¸°ì¡´ jira_chunks ì»¬ë ‰ì…˜ ì‚¬ìš©")
        except:
            collection = client.create_collection(
                name="jira_chunks",
                metadata={
                    "hnsw:space": "cosine",
                    "description": "Jira issue chunks for RAG system",
                    "schema_version": "unified_v1",
                    "created_at": datetime.now().isoformat()
                }
            )
            logger.info("âœ… jira_chunks ì»¬ë ‰ì…˜ ìƒì„±")

        # Upsert ë¡œì§
        saved_count = 0
        for chunk in chunks:
            try:
                # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
                metadata = {
                    # ê³µí†µ í•„ë“œ
                    "data_source": chunk.data_source,
                    "created_at": chunk.created_at,
                    "updated_at": chunk.updated_at,
                }

                # jira_metadata ì£¼ìš” í•„ë“œ ì¶”ì¶œ
                if chunk.jira_metadata:
                    metadata["issue_key"] = chunk.jira_metadata.get("issue_key", "")
                    metadata["chunk_type"] = chunk.jira_metadata.get("chunk_type", "")
                    metadata["chunk_index"] = chunk.jira_metadata.get("chunk_index", 0)
                    metadata["issue_type"] = chunk.jira_metadata.get("issue_type", "")
                    metadata["status"] = chunk.jira_metadata.get("status", "")
                    metadata["priority"] = chunk.jira_metadata.get("priority", "")
                    metadata["project_key"] = chunk.jira_metadata.get("project_key", "")
                    metadata["source_url"] = chunk.jira_metadata.get("source_url", "")

                    # ë¦¬ìŠ¤íŠ¸ í•„ë“œëŠ” JSON ì§ë ¬í™”
                    import json
                    if chunk.jira_metadata.get("labels"):
                        metadata["labels"] = json.dumps(chunk.jira_metadata["labels"], ensure_ascii=False)
                    if chunk.jira_metadata.get("components"):
                        metadata["components"] = json.dumps(chunk.jira_metadata["components"], ensure_ascii=False)
                    if chunk.jira_metadata.get("fix_versions"):
                        metadata["fix_versions"] = json.dumps(chunk.jira_metadata["fix_versions"], ensure_ascii=False)

                    # ì„ íƒì  í•„ë“œ
                    if chunk.jira_metadata.get("assignee"):
                        metadata["assignee"] = chunk.jira_metadata["assignee"]
                    if chunk.jira_metadata.get("reporter"):
                        metadata["reporter"] = chunk.jira_metadata["reporter"]
                    if chunk.jira_metadata.get("summary"):
                        metadata["summary"] = chunk.jira_metadata["summary"]
                    if chunk.jira_metadata.get("comment_author"):
                        metadata["comment_author"] = chunk.jira_metadata["comment_author"]

                # None ê°’ ì œê±° (ChromaDBëŠ” None í—ˆìš© ì•ˆ í•¨)
                metadata = {k: v for k, v in metadata.items() if v is not None}

                # Upsert
                collection.upsert(
                    ids=[chunk.chunk_id],
                    documents=[chunk.text_chunk],
                    metadatas=[metadata]
                )

                saved_count += 1

                # ì§„í–‰ìƒí™© ë¡œê¹… (100ê°œë§ˆë‹¤)
                if saved_count % 100 == 0:
                    logger.info(f"   ğŸ’¾ {saved_count}/{len(chunks)} ì €ì¥ ì¤‘...")

            except Exception as e:
                logger.error(f"âŒ ì²­í¬ ì €ì¥ ì‹¤íŒ¨ ({chunk.chunk_id}): {e}")
                continue

        logger.info(f"âœ… ChromaDB ì €ì¥ ì™„ë£Œ: {saved_count}ê°œ ì²­í¬")
        return saved_count

    except Exception as e:
        logger.error(f"âŒ ChromaDB ì €ì¥ ì‹¤íŒ¨: {e}")
        raise


def run_jira_sync_batch(
    user_id: int,
    db_path: str = "tickets.db",
    force_full_sync: bool = False
) -> Dict:
    """
    Jira ë™ê¸°í™” ë°°ì¹˜ ì‹¤í–‰

    Args:
        user_id: ì‚¬ìš©ì ID
        db_path: SQLite DB ê²½ë¡œ
        force_full_sync: Trueë©´ ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê° ë¬´ì‹œí•˜ê³  ì „ì²´ ë™ê¸°í™” (7ì¼)

    Returns:
        {
            "status": "success" | "failed",
            "processed_count": ìˆ«ì,
            "issues_count": ìˆ«ì,
            "error": ì—ëŸ¬ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
        }
    """
    start_time = datetime.now()

    logger.info("=" * 60)
    logger.info(f"ğŸš€ Jira ë™ê¸°í™” ë°°ì¹˜ ì‹œì‘")
    logger.info(f"   User ID: {user_id}")
    logger.info(f"   ì‹œì‘ ì‹œê°: {start_time}")
    logger.info("=" * 60)

    try:
        # 1. Jira ì„¤ì • ë¡œë“œ
        logger.info("\n[1/7] Jira ì„¤ì • ë¡œë“œ")
        config = load_jira_config(user_id, db_path)
        if not config or not config.get("token"):
            raise ValueError("Jira ì—°ë™ ì •ë³´ê°€ ì—†ê±°ë‚˜ í† í°ì´ ì—†ìŠµë‹ˆë‹¤")

        logger.info(f"   âœ… Endpoint: {config['endpoint']}")
        logger.info(f"   âœ… Projects: {config.get('projects', [])}")

        # 2. ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê° ì¡°íšŒ
        logger.info("\n[2/7] ë§ˆì§€ë§‰ ë™ê¸°í™” ì‹œê° ì¡°íšŒ")
        if force_full_sync:
            from datetime import timedelta
            last_sync_time = datetime.now() - timedelta(days=7)
            logger.info(f"   ğŸ”„ ì „ì²´ ë™ê¸°í™” ëª¨ë“œ: 7ì¼ ì „ë¶€í„°")
        else:
            last_sync_time = get_last_sync_time(user_id, "jira_sync", db_path)
        logger.info(f"   ğŸ“… ì¡°íšŒ ì‹œì‘ ì‹œê°: {last_sync_time}")

        # 3. JQL ì¿¼ë¦¬ ìƒì„±
        logger.info("\n[3/7] JQL ì¿¼ë¦¬ ìƒì„±")
        jql = build_jira_jql(config, last_sync_time)
        logger.info(f"   ğŸ“ JQL: {jql}")

        # 4. Jira ì´ìŠˆ ê°€ì ¸ì˜¤ê¸°
        logger.info("\n[4/7] Jira API í˜¸ì¶œ")
        client = JiraClient(config["endpoint"], config["token"])

        # ì—°ê²° í…ŒìŠ¤íŠ¸
        if not client.test_connection():
            raise JiraAPIError("Jira ì—°ê²° ì‹¤íŒ¨")

        issues = client.search_issues(jql, max_results=100)
        logger.info(f"   âœ… ì¡°íšŒëœ ì´ìŠˆ: {len(issues)}ê°œ")

        if len(issues) == 0:
            logger.info("   â„¹ï¸ ìƒˆë¡œìš´ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤")
            update_batch_history(
                user_id=user_id,
                batch_type="jira_sync",
                status="success",
                processed_count=0,
                db_path=db_path
            )
            return {
                "status": "success",
                "processed_count": 0,
                "issues_count": 0
            }

        # 5. UnifiedChunkë¡œ ë³€í™˜
        logger.info("\n[5/7] ì´ìŠˆ â†’ ì²­í¬ ë³€í™˜")
        all_chunks = process_issues_to_chunks(issues, config["endpoint"])
        logger.info(f"   âœ… ìƒì„±ëœ ì²­í¬: {len(all_chunks)}ê°œ")

        # 6. ChromaDB ì €ì¥
        logger.info("\n[6/7] ChromaDB ì €ì¥")
        processed_count = save_chunks_to_chromadb(all_chunks)

        # 7. ë°°ì¹˜ ì´ë ¥ ì €ì¥
        logger.info("\n[7/7] ë°°ì¹˜ ì´ë ¥ ì €ì¥")
        update_batch_history(
            user_id=user_id,
            batch_type="jira_sync",
            status="success",
            processed_count=processed_count,
            db_path=db_path
        )

        # ì™„ë£Œ
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        logger.info("\n" + "=" * 60)
        logger.info(f"âœ… Jira ë™ê¸°í™” ë°°ì¹˜ ì™„ë£Œ")
        logger.info(f"   ì´ìŠˆ ìˆ˜: {len(issues)}ê°œ")
        logger.info(f"   ì²­í¬ ìˆ˜: {processed_count}ê°œ")
        logger.info(f"   ì†Œìš” ì‹œê°„: {duration:.2f}ì´ˆ")
        logger.info("=" * 60)

        return {
            "status": "success",
            "processed_count": processed_count,
            "issues_count": len(issues),
            "duration": duration
        }

    except Exception as e:
        logger.error(f"\nâŒ Jira ë™ê¸°í™” ë°°ì¹˜ ì‹¤íŒ¨: {e}", exc_info=True)

        # ë°°ì¹˜ ì´ë ¥ ì €ì¥ (ì‹¤íŒ¨)
        update_batch_history(
            user_id=user_id,
            batch_type="jira_sync",
            status="failed",
            processed_count=0,
            error_message=str(e),
            db_path=db_path
        )

        return {
            "status": "failed",
            "error": str(e)
        }


def main():
    """CLI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    parser = argparse.ArgumentParser(
        description="Jira ì´ìŠˆ ë™ê¸°í™” ë°°ì¹˜",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ë‹¨ì¼ ì‚¬ìš©ì ì‹¤í–‰
  python batch/jira_sync.py --user-id 1

  # ëª¨ë“  Jira ì‚¬ìš©ì ì‹¤í–‰
  python batch/jira_sync.py --all-users

  # íŠ¹ì • ì‚¬ìš©ìë“¤ë§Œ ì‹¤í–‰
  python batch/jira_sync.py --user-ids 1,2,3

  # ë³‘ë ¬ ì‹¤í–‰
  python batch/jira_sync.py --all-users --parallel --max-workers 5

  # ì „ì²´ ë™ê¸°í™” (7ì¼ê°„)
  python batch/jira_sync.py --user-id 1 --full-sync

  # DB ì´ˆê¸°í™”
  python batch/jira_sync.py --init-db
        """
    )

    # ì‚¬ìš©ì ì„ íƒ ì˜µì…˜ (mutually exclusive)
    user_group = parser.add_mutually_exclusive_group(required=False)
    user_group.add_argument(
        "--user-id",
        type=int,
        help="ë‹¨ì¼ ì‚¬ìš©ì ID"
    )
    user_group.add_argument(
        "--all-users",
        action="store_true",
        help="ëª¨ë“  Jira ì—°ë™ ì‚¬ìš©ì ì‹¤í–‰"
    )
    user_group.add_argument(
        "--user-ids",
        type=str,
        help="ì‚¬ìš©ì ID ëª©ë¡ (ì‰¼í‘œ êµ¬ë¶„, ì˜ˆ: 1,2,3)"
    )

    # ê³µí†µ ì˜µì…˜
    parser.add_argument(
        "--db-path",
        type=str,
        default="tickets.db",
        help="SQLite DB ê²½ë¡œ (ê¸°ë³¸ê°’: tickets.db)"
    )
    parser.add_argument(
        "--full-sync",
        action="store_true",
        help="ì „ì²´ ë™ê¸°í™” (ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê° ë¬´ì‹œ)"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="ë””ë²„ê·¸ ëª¨ë“œ (ìƒì„¸ ë¡œê·¸ ì¶œë ¥)"
    )
    parser.add_argument(
        "--init-db",
        action="store_true",
        help="batch_history í…Œì´ë¸” ì´ˆê¸°í™”"
    )

    # ë‹¤ì¤‘ ì‚¬ìš©ì ì˜µì…˜
    parser.add_argument(
        "--parallel",
        action="store_true",
        help="ë³‘ë ¬ ì‹¤í–‰ (--all-users ë˜ëŠ” --user-idsì™€ í•¨ê»˜ ì‚¬ìš©)"
    )
    parser.add_argument(
        "--max-workers",
        type=int,
        default=3,
        help="ë³‘ë ¬ ì‹¤í–‰ ì‹œ ìµœëŒ€ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: 3)"
    )

    args = parser.parse_args()

    # ë¡œê¹… ì„¤ì •
    log_level = logging.DEBUG if args.debug else logging.INFO
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # DB ì´ˆê¸°í™” (ì„ íƒì )
    if args.init_db:
        print("ğŸ”§ batch_history í…Œì´ë¸” ì´ˆê¸°í™” ì¤‘...")
        success = create_batch_history_table(args.db_path)
        if success:
            print("âœ… ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            print("âŒ ì´ˆê¸°í™” ì‹¤íŒ¨")
            sys.exit(1)
        # init-dbë§Œ ì‹¤í–‰í•˜ê³  ì¢…ë£Œ
        if not (args.user_id or args.all_users or args.user_ids):
            sys.exit(0)

    # ì‚¬ìš©ì ì„ íƒ í™•ì¸
    if not (args.user_id or args.all_users or args.user_ids):
        parser.error("--user-id, --all-users, ë˜ëŠ” --user-ids ì¤‘ í•˜ë‚˜ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤")

    # ë‹¤ì¤‘ ì‚¬ìš©ì ë°°ì¹˜ ì‹¤í–‰
    if args.all_users or args.user_ids:
        from batch.multi_user_sync import run_multi_user_batch, print_batch_summary

        # ì‚¬ìš©ì ID ëª©ë¡ ìƒì„±
        user_ids = None
        if args.user_ids:
            try:
                user_ids = [int(uid.strip()) for uid in args.user_ids.split(",")]
            except ValueError:
                print("âŒ --user-ids í˜•ì‹ ì˜¤ë¥˜: ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 1,2,3)")
                sys.exit(1)

        # ë‹¤ì¤‘ ì‚¬ìš©ì ë°°ì¹˜ ì‹¤í–‰
        result = run_multi_user_batch(
            user_ids=user_ids,
            db_path=args.db_path,
            parallel=args.parallel,
            max_workers=args.max_workers,
            force_full_sync=args.full_sync
        )

        # ê²°ê³¼ ì¶œë ¥
        print_batch_summary(result)

        # ì¢…ë£Œ ì½”ë“œ ê²°ì •
        if result["failed"] == 0:
            sys.exit(0)
        elif result["successful"] > 0:
            sys.exit(2)  # ì¼ë¶€ ì„±ê³µ, ì¼ë¶€ ì‹¤íŒ¨
        else:
            sys.exit(1)  # ì „ì²´ ì‹¤íŒ¨

    # ë‹¨ì¼ ì‚¬ìš©ì ë°°ì¹˜ ì‹¤í–‰
    else:
        result = run_jira_sync_batch(
            user_id=args.user_id,
            db_path=args.db_path,
            force_full_sync=args.full_sync
        )

        # ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“Š ë°°ì¹˜ ì‹¤í–‰ ê²°ê³¼:")
        print(f"   ìƒíƒœ: {result['status']}")
        if result["status"] == "success":
            print(f"   ì²˜ë¦¬ ì´ìŠˆ: {result.get('issues_count', 0)}ê°œ")
            print(f"   ì €ì¥ ì²­í¬: {result.get('processed_count', 0)}ê°œ")
            print(f"   ì†Œìš” ì‹œê°„: {result.get('duration', 0):.2f}ì´ˆ")
            sys.exit(0)
        else:
            print(f"   ì—ëŸ¬: {result.get('error', 'Unknown')}")
            sys.exit(1)


if __name__ == "__main__":
    main()
