"""
Cohere Re-rankingì„ í™œìš©í•œ ì••ì¶• ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ LangChainì˜ ContextualCompressionRetrieverì™€ Cohereì˜ Re-rank ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬
RAG ì‹œìŠ¤í…œì˜ ê²€ìƒ‰ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
"""

import os
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from langchain.retrievers import ContextualCompressionRetriever
from langchain_cohere import CohereRerank
from langchain.retrievers.document_compressors import DocumentCompressorPipeline
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
from vector_db_models import VectorDBManager

# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ëª¨ë“ˆ import
from text_preprocessor import preprocess_for_embedding

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class CohereRerankRetriever:
    """Cohere Re-rankingì„ í™œìš©í•œ ì••ì¶• ê²€ìƒ‰ê¸°"""
    
    def __init__(self, cohere_api_key: Optional[str] = None):
        """
        Cohere Re-ranking ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        
        Args:
            cohere_api_key: Cohere API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
        """
        self.cohere_api_key = cohere_api_key or os.getenv('COHERE_API_KEY')
        if not self.cohere_api_key:
            raise ValueError("COHERE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— COHERE_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        
        self.vector_db = VectorDBManager()
        self._setup_retrievers()
    
    def _setup_retrievers(self):
        """ê²€ìƒ‰ê¸° ì„¤ì •"""
        # 1. ê¸°ë³¸ ê²€ìƒ‰ê¸° (Vector DB Retriever) ìƒì„±
        self.base_retriever = VectorDBRetriever(self.vector_db)
        
        # 2. Cohere Re-rank ì••ì¶•ê¸° ìƒì„±
        self.rerank_compressor = CohereRerank(
            cohere_api_key=self.cohere_api_key,
            top_n=3,  # ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
            model="rerank-multilingual-v3.0"  # ë‹¤êµ­ì–´ ì§€ì› ëª¨ë¸
        )
        
        # 3. ì••ì¶• ê²€ìƒ‰ê¸° ìƒì„±
        self.compression_retriever = ContextualCompressionRetriever(
            base_compressor=self.rerank_compressor,
            base_retriever=self.base_retriever
        )
    
    def search_with_rerank(self, query: str, k: int = 20) -> List[Dict[str, Any]]:
        """
        Cohere Re-rankingì„ í™œìš©í•œ ì••ì¶• ê²€ìƒ‰ ì‹¤í–‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: 1ì°¨ ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¬ í›„ë³´ ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸ê°’: 20)
            
        Returns:
            ì¬ìˆœìœ„í™”ëœ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ì¿¼ë¦¬ ì „ì²˜ë¦¬ ì ìš©
            preprocessed_query = preprocess_for_embedding(query)
            
            print(f"ğŸ” Cohere Re-ranking ê²€ìƒ‰ ì‹œì‘: '{preprocessed_query}'")
            
            # 1ì°¨ ê²€ìƒ‰ì—ì„œ ë” ë§ì€ í›„ë³´ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ k ì„¤ì •
            self.base_retriever.k = k
            
            # ì••ì¶• ê²€ìƒ‰ ì‹¤í–‰
            documents = self.compression_retriever.get_relevant_documents(preprocessed_query)
            
            # ê²°ê³¼ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            results = []
            for i, doc in enumerate(documents):
                result = {
                    "id": f"rerank-{i}",
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "similarity_score": doc.metadata.get("similarity_score", 0.0),
                    "rerank_score": doc.metadata.get("rerank_score", 0.0),
                    "source": "cohere_rerank"
                }
                results.append(result)
            
            print(f"âœ… Cohere Re-ranking ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            print(f"âŒ Cohere Re-ranking ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            # í´ë°±: ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ ì‚¬ìš©
            print("ğŸ”„ ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ í´ë°±...")
            return self._fallback_search(query)
    
    def _fallback_search(self, query: str) -> List[Dict[str, Any]]:
        """Cohere Re-ranking ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ í´ë°±"""
        try:
            # ë©”ì¼ ê²€ìƒ‰
            similar_emails = self.vector_db.search_similar_mails(query, n_results=2)
            
            # íŒŒì¼ ì²­í¬ ê²€ìƒ‰
            similar_chunks = self.vector_db.search_similar_file_chunks(query, n_results=3)
            
            # ê²°ê³¼ í†µí•©
            results = []
            
            # ë©”ì¼ ê²°ê³¼ ì¶”ê°€
            for email in similar_emails:
                results.append({
                    "id": email.get("message_id", "unknown"),
                    "content": email.get("content", ""),
                    "metadata": {
                        "source": "mail",
                        "subject": email.get("subject", ""),
                        "sender": email.get("sender", "")
                    },
                    "similarity_score": email.get("similarity_score", 0.0),
                    "source": "fallback_mail"
                })
            
            # íŒŒì¼ ì²­í¬ ê²°ê³¼ ì¶”ê°€
            for chunk in similar_chunks:
                results.append({
                    "id": chunk.get("chunk_id", "unknown"),
                    "content": chunk.get("content", ""),
                    "metadata": {
                        "source": "file_chunk",
                        "file_name": chunk.get("file_name", ""),
                        "file_type": chunk.get("file_type", "")
                    },
                    "similarity_score": chunk.get("similarity_score", 0.0),
                    "source": "fallback_chunk"
                })
            
            # ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            results.sort(key=lambda x: x.get("similarity_score", 0.0), reverse=True)
            
            return results[:5]  # ìƒìœ„ 5ê°œë§Œ ë°˜í™˜
            
        except Exception as e:
            print(f"âŒ í´ë°± ê²€ìƒ‰ë„ ì‹¤íŒ¨: {str(e)}")
            return []


class VectorDBRetriever(BaseRetriever):
    """Vector DBë¥¼ LangChain Retrieverë¡œ ë˜í•‘"""
    
    def __init__(self, vector_db: VectorDBManager, k: int = 20):
        """
        Vector DB Retriever ì´ˆê¸°í™”
        
        Args:
            vector_db: VectorDBManager ì¸ìŠ¤í„´ìŠ¤
            k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
        """
        super().__init__()
        # Pydantic ëª¨ë¸ì´ë¯€ë¡œ í•„ë“œë¥¼ ì§ì ‘ ì„¤ì •í•˜ì§€ ì•Šê³  ì €ì¥
        self._vector_db = vector_db
        self._k = k
    
    @property
    def vector_db(self):
        return self._vector_db
    
    @property
    def k(self):
        return self._k
    
    @k.setter
    def k(self, value):
        self._k = value
    
    def _get_relevant_documents(self, query: str) -> List[Document]:
        """
        ì¿¼ë¦¬ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            
        Returns:
            LangChain Document ë¦¬ìŠ¤íŠ¸
        """
        try:
            print(f"ğŸ” VectorDBRetriever ê²€ìƒ‰ ì‹œì‘: '{query}', k={self.k}")
            
            # ë©”ì¼ê³¼ íŒŒì¼ ì²­í¬ë¥¼ ëª¨ë‘ ê²€ìƒ‰
            similar_emails = self.vector_db.search_similar_mails(query, n_results=self.k // 2)
            similar_chunks = self.vector_db.search_similar_file_chunks(query, n_results=self.k // 2)
            
            print(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: ë©”ì¼ {len(similar_emails)}ê°œ, íŒŒì¼ ì²­í¬ {len(similar_chunks)}ê°œ")
            
            documents = []
            
            # ë©”ì¼ ê²°ê³¼ë¥¼ Documentë¡œ ë³€í™˜
            for email in similar_emails:
                content = f"Subject: {email.get('subject', '')}\nSender: {email.get('sender', '')}\nContent: {email.get('content', '')}"
                metadata = {
                    "source": "mail",
                    "message_id": email.get("message_id", ""),
                    "subject": email.get("subject", ""),
                    "sender": email.get("sender", ""),
                    "similarity_score": email.get("similarity_score", 0.0)
                }
                documents.append(Document(page_content=content, metadata=metadata))
                print(f"ğŸ“§ ë©”ì¼ ë¬¸ì„œ ì¶”ê°€: {len(content)}ì")
            
            # íŒŒì¼ ì²­í¬ ê²°ê³¼ë¥¼ Documentë¡œ ë³€í™˜
            for chunk in similar_chunks:
                content = chunk.get("content", "")
                metadata = {
                    "source": "file_chunk",
                    "chunk_id": chunk.get("chunk_id", ""),
                    "file_name": chunk.get("file_name", ""),
                    "file_type": chunk.get("file_type", ""),
                    "similarity_score": chunk.get("similarity_score", 0.0)
                }
                documents.append(Document(page_content=content, metadata=metadata))
                print(f"ğŸ“„ íŒŒì¼ ì²­í¬ ë¬¸ì„œ ì¶”ê°€: {len(content)}ì")
            
            print(f"âœ… ì´ {len(documents)}ê°œ ë¬¸ì„œ ìƒì„± ì™„ë£Œ")
            return documents
            
        except Exception as e:
            print(f"âŒ Vector DB ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            return []


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
cohere_rerank_retriever = None

def get_cohere_rerank_retriever() -> CohereRerankRetriever:
    """Cohere Re-ranking ê²€ìƒ‰ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global cohere_rerank_retriever
    if cohere_rerank_retriever is None:
        cohere_rerank_retriever = CohereRerankRetriever()
    return cohere_rerank_retriever


def search_with_cohere_rerank(query: str, k: int = 20) -> List[Dict[str, Any]]:
    """
    Cohere Re-rankingì„ í™œìš©í•œ ê²€ìƒ‰ ì‹¤í–‰ (í¸ì˜ í•¨ìˆ˜)
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        k: 1ì°¨ ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¬ í›„ë³´ ë¬¸ì„œ ìˆ˜
        
    Returns:
        ì¬ìˆœìœ„í™”ëœ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    retriever = get_cohere_rerank_retriever()
    return retriever.search_with_rerank(query, k)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª Cohere Re-ranking ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    
    try:
        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        query = "ì„œë²„ ì ‘ì† ë¶ˆê°€ ë¬¸ì œ"
        results = search_with_cohere_rerank(query, k=10)
        
        print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
        for i, result in enumerate(results, 1):
            print(f"\n{i}. {result['source']}")
            print(f"   ìœ ì‚¬ë„: {result.get('similarity_score', 0.0):.3f}")
            print(f"   ë‚´ìš©: {result['content'][:100]}...")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        print("ğŸ’¡ COHERE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
