#!/usr/bin/env python3
"""
HyDE + ê°€ì¤‘ì¹˜ + file_chunks ë°ì´í„°ë¥¼ í™œìš©í•œ í¬ê´„ì  Golden Set í…ŒìŠ¤íŠ¸
ê¸°ë³¸ ê²€ìƒ‰ vs HyDE vs í•˜ì´ë¸Œë¦¬ë“œ ì„±ëŠ¥ ë¹„êµ í¬í•¨
"""

import os
import sys
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
import chromadb
from chromadb.config import Settings
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ëª¨ë“ˆë“¤ import
from intelligent_chunk_weighting import IntelligentChunkWeighting
from hyde_rag_system_mock import MockHyDEGenerator, HyDEConfig

class ComprehensiveHyDETestSystem:
    """HyDE í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ"""

    def __init__(self, collection_name: str = "file_chunks"):
        """
        ì´ˆê¸°í™”

        Args:
            collection_name: ChromaDB ì»¬ë ‰ì…˜ ì´ë¦„
        """
        self.collection_name = collection_name
        self.config = HyDEConfig()

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.client = None
        self.collection = None
        self.hyde_generator = None
        self.weighting_system = None

        self._init_components()

    def _init_components(self):
        """ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        try:
            # ChromaDB ì—°ê²°
            self.client = chromadb.PersistentClient(
                path='./vector_db',
                settings=Settings(anonymized_telemetry=False, allow_reset=True)
            )
            self.collection = self.client.get_collection(self.collection_name)

            # Mock HyDE ìƒì„±ê¸°
            self.hyde_generator = MockHyDEGenerator(self.config)

            # ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ
            self.weighting_system = IntelligentChunkWeighting()

            print(f"âœ… í¬ê´„ì  HyDE í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ: {self.collection.count()}ê°œ ë¬¸ì„œ")

        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise e

    def basic_search(self, query: str, n_results: int = 10) -> List[Dict[str, Any]]:
        """
        1. ê¸°ë³¸ ê²€ìƒ‰ (ì›ë³¸ ì§ˆë¬¸ë§Œ)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            n_results: ê²°ê³¼ ìˆ˜

        Returns:
            ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            results = self.collection.query(
                query_texts=[query],
                n_results=n_results
            )

            if not results['ids'][0]:
                return []

            # ê¸°ë³¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            basic_results = []
            for i in range(len(results['ids'][0])):
                distance = results['distances'][0][i] if results['distances'][0] else 1.0
                cosine_score = max(0.0, 1.0 - distance)

                result = {
                    'id': results['ids'][0][i],
                    'content': results['documents'][0][i] if results['documents'][0] else "",
                    'score': cosine_score,
                    'raw_score': cosine_score,
                    'method': 'basic',
                    'source': 'basic_search'
                }
                basic_results.append(result)

            return basic_results

        except Exception as e:
            print(f"âŒ ê¸°ë³¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def multi_query_search(self, query: str, n_results: int = 10) -> List[Dict[str, Any]]:
        """
        2. ë©€í‹° ì¿¼ë¦¬ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            n_results: ê²°ê³¼ ìˆ˜

        Returns:
            ë©€í‹° ì¿¼ë¦¬ ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            # ë©€í‹° ì¿¼ë¦¬ ìƒì„±
            multi_queries = self.hyde_generator.generate_multi_queries(query)
            all_texts = [query] + multi_queries

            # ê° ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
            all_results = []
            for i, text in enumerate(all_texts):
                results = self.collection.query(
                    query_texts=[text],
                    n_results=n_results
                )

                if results['ids'][0]:
                    for j in range(len(results['ids'][0])):
                        distance = results['distances'][0][j] if results['distances'][0] else 1.0
                        cosine_score = max(0.0, 1.0 - distance)

                        result = {
                            'id': results['ids'][0][j],
                            'content': results['documents'][0][j] if results['documents'][0] else "",
                            'distance': distance,
                            'cosine_score': cosine_score,
                            'query_type': 'original' if i == 0 else 'multi',
                            'query_index': i,
                            'source_text': text[:50] + "..." if len(text) > 50 else text
                        }
                        all_results.append(result)

            # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ í†µí•©
            unique_results = self._deduplicate_results(all_results)

            # ê°€ì¤‘ì¹˜ ì ìš©
            weighted_results = self._apply_weighting(unique_results)

            return weighted_results[:n_results]

        except Exception as e:
            print(f"âŒ ë©€í‹° ì¿¼ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def hyde_search(self, query: str, n_results: int = 10) -> List[Dict[str, Any]]:
        """
        3. HyDE ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            n_results: ê²°ê³¼ ìˆ˜

        Returns:
            HyDE ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            # HyDE ë¬¸ì„œ ìƒì„±
            hypothetical_doc = self.hyde_generator.generate_hypothetical_document(query)
            all_texts = [query, hypothetical_doc]

            # ê° í…ìŠ¤íŠ¸ë¡œ ê²€ìƒ‰
            all_results = []
            for i, text in enumerate(all_texts):
                results = self.collection.query(
                    query_texts=[text],
                    n_results=n_results
                )

                if results['ids'][0]:
                    for j in range(len(results['ids'][0])):
                        distance = results['distances'][0][j] if results['distances'][0] else 1.0
                        cosine_score = max(0.0, 1.0 - distance)

                        result = {
                            'id': results['ids'][0][j],
                            'content': results['documents'][0][j] if results['documents'][0] else "",
                            'distance': distance,
                            'cosine_score': cosine_score,
                            'query_type': 'original' if i == 0 else 'hyde',
                            'query_index': i,
                            'source_text': text[:100] + "..." if len(text) > 100 else text
                        }
                        all_results.append(result)

            # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ í†µí•©
            unique_results = self._deduplicate_results(all_results)

            # ê°€ì¤‘ì¹˜ ì ìš©
            weighted_results = self._apply_weighting(unique_results)

            return weighted_results[:n_results]

        except Exception as e:
            print(f"âŒ HyDE ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def hybrid_search(self, query: str, n_results: int = 10) -> List[Dict[str, Any]]:
        """
        4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë©€í‹° ì¿¼ë¦¬ + HyDE)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            n_results: ê²°ê³¼ ìˆ˜

        Returns:
            í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            # ë©€í‹° ì¿¼ë¦¬ + HyDE ë¬¸ì„œ ìƒì„±
            multi_queries = self.hyde_generator.generate_multi_queries(query)
            hypothetical_doc = self.hyde_generator.generate_hypothetical_document(query)
            all_texts = [query] + multi_queries + [hypothetical_doc]

            # ê° í…ìŠ¤íŠ¸ë¡œ ê²€ìƒ‰
            all_results = []
            for i, text in enumerate(all_texts):
                results = self.collection.query(
                    query_texts=[text],
                    n_results=self.config.top_k_per_query
                )

                if results['ids'][0]:
                    for j in range(len(results['ids'][0])):
                        distance = results['distances'][0][j] if results['distances'][0] else 1.0
                        cosine_score = max(0.0, 1.0 - distance)

                        # ì¿¼ë¦¬ íƒ€ì… ê²°ì •
                        if i == 0:
                            query_type = 'original'
                        elif i < len(all_texts) - 1:
                            query_type = 'multi'
                        else:
                            query_type = 'hyde'

                        result = {
                            'id': results['ids'][0][j],
                            'content': results['documents'][0][j] if results['documents'][0] else "",
                            'distance': distance,
                            'cosine_score': cosine_score,
                            'query_type': query_type,
                            'query_index': i,
                            'source_text': text[:100] + "..." if len(text) > 100 else text
                        }
                        all_results.append(result)

            # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ í†µí•©
            unique_results = self._deduplicate_results(all_results)

            # ê°€ì¤‘ì¹˜ ì ìš©
            weighted_results = self._apply_weighting(unique_results)

            return weighted_results[:n_results]

        except Exception as e:
            print(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _deduplicate_results(self, all_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ê²°ê³¼ ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ í†µí•©"""
        unique_docs = {}

        for result in all_results:
            doc_id = result['id']
            cosine_score = result['cosine_score']

            if doc_id not in unique_docs:
                unique_docs[doc_id] = {
                    'id': doc_id,
                    'content': result['content'],
                    'scores': [],
                    'query_types': [],
                    'source_texts': []
                }

            unique_docs[doc_id]['scores'].append(cosine_score)
            unique_docs[doc_id]['query_types'].append(result['query_type'])
            unique_docs[doc_id]['source_texts'].append(result['source_text'])

        # ì ìˆ˜ í†µí•© (ìµœëŒ€ê°’ ì‚¬ìš©)
        processed_results = []
        for doc_id, doc_data in unique_docs.items():
            max_score = max(doc_data['scores'])

            processed_result = {
                'id': doc_id,
                'content': doc_data['content'],
                'cosine_score': max_score,
                'query_types': doc_data['query_types'],
                'source_texts': doc_data['source_texts'],
                'scores': doc_data['scores']
            }
            processed_results.append(processed_result)

        return processed_results

    def _apply_weighting(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ê°€ì¤‘ì¹˜ ì ìš©"""
        try:
            # ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            search_results = []
            for result in results:
                chunk_type = self._estimate_chunk_type(result['content'])

                search_result = {
                    'id': result['id'],
                    'content': result['content'],
                    'chunk_type': chunk_type,
                    'cosine_score': result['cosine_score'],
                    'embedding': [],
                    'metadata': {
                        'query_types': result.get('query_types', []),
                        'source_texts': result.get('source_texts', []),
                        'scores': result.get('scores', [])
                    }
                }
                search_results.append(search_result)

            # ê°€ì¤‘ì¹˜ ì ìš©
            mock_query_embedding = np.random.normal(0, 1, 384).tolist()
            weighted_results = self.weighting_system.apply_weighted_scoring(
                search_results, mock_query_embedding
            )

            # ìµœì¢… í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            final_results = []
            for weighted_result in weighted_results:
                result = {
                    'id': weighted_result.id,
                    'content': weighted_result.content,
                    'score': weighted_result.weighted_score,
                    'raw_score': weighted_result.cosine_score,
                    'weight': weighted_result.weight,
                    'chunk_type': weighted_result.chunk_type,
                    'method': 'weighted',
                    'source': 'weighted_search',
                    'metadata': weighted_result.metadata
                }
                final_results.append(result)

            return final_results

        except Exception as e:
            print(f"âŒ ê°€ì¤‘ì¹˜ ì ìš© ì‹¤íŒ¨: {e}")
            return results

    def _estimate_chunk_type(self, content: str) -> str:
        """chunk_type ì¶”ì •"""
        content_lower = content.lower()

        if any(pattern in content_lower for pattern in ['ì œëª©:', 'title:', 'ì´ìŠˆ í‚¤:']):
            return 'title'
        elif any(pattern in content_lower for pattern in ['ìš”ì•½:', 'summary:']):
            return 'summary'
        elif any(pattern in content_lower for pattern in ['ì„¤ëª…:', 'description:']):
            return 'description'
        elif any(pattern in content_lower for pattern in ['ëŒ“ê¸€:', 'comment:']):
            return 'comment'
        elif len(content.strip()) < 30:
            return 'title'
        elif len(content.strip()) < 100:
            return 'summary'
        elif len(content.strip()) > 1000:
            return 'body'
        else:
            return 'description'

    def compare_all_methods(self, query: str, n_results: int = 5) -> Dict[str, Any]:
        """
        ëª¨ë“  ê²€ìƒ‰ ë°©ë²• ë¹„êµ

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            n_results: ê° ë°©ë²•ë³„ ê²°ê³¼ ìˆ˜

        Returns:
            ë¹„êµ ê²°ê³¼
        """
        print(f"\nğŸ”¬ ê²€ìƒ‰ ë°©ë²• ì¢…í•© ë¹„êµ: '{query}'")
        print("="*80)

        # ê° ë°©ë²•ë³„ ê²€ìƒ‰ ìˆ˜í–‰
        methods_results = {}

        # 1. ê¸°ë³¸ ê²€ìƒ‰
        print("1ï¸âƒ£ ê¸°ë³¸ ê²€ìƒ‰ (ì›ë³¸ ì§ˆë¬¸ë§Œ)")
        basic_results = self.basic_search(query, n_results)
        methods_results['basic'] = basic_results
        print(f"   ê²°ê³¼: {len(basic_results)}ê°œ")

        # 2. ë©€í‹° ì¿¼ë¦¬ ê²€ìƒ‰
        print("2ï¸âƒ£ ë©€í‹° ì¿¼ë¦¬ ê²€ìƒ‰")
        multi_results = self.multi_query_search(query, n_results)
        methods_results['multi_query'] = multi_results
        print(f"   ê²°ê³¼: {len(multi_results)}ê°œ")

        # 3. HyDE ê²€ìƒ‰
        print("3ï¸âƒ£ HyDE ê²€ìƒ‰")
        hyde_results = self.hyde_search(query, n_results)
        methods_results['hyde'] = hyde_results
        print(f"   ê²°ê³¼: {len(hyde_results)}ê°œ")

        # 4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        print("4ï¸âƒ£ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë©€í‹° ì¿¼ë¦¬ + HyDE)")
        hybrid_results = self.hybrid_search(query, n_results)
        methods_results['hybrid'] = hybrid_results
        print(f"   ê²°ê³¼: {len(hybrid_results)}ê°œ")

        # ê²°ê³¼ ë¶„ì„
        self._analyze_comparison_results(methods_results, query)

        return methods_results

    def _analyze_comparison_results(self, methods_results: Dict[str, List[Dict[str, Any]]], query: str):
        """ë¹„êµ ê²°ê³¼ ë¶„ì„"""
        print(f"\nğŸ“Š ì„±ëŠ¥ ë¶„ì„:")
        print("-" * 60)

        # 1. ê²°ê³¼ ìˆ˜ ë¹„êµ
        counts = {method: len(results) for method, results in methods_results.items()}
        print(f"ê²°ê³¼ ìˆ˜: ê¸°ë³¸({counts['basic']}) < ë©€í‹°ì¿¼ë¦¬({counts['multi_query']}) < HyDE({counts['hyde']}) < í•˜ì´ë¸Œë¦¬ë“œ({counts['hybrid']})")

        # 2. í‰ê·  ì ìˆ˜ ë¹„êµ
        for method, results in methods_results.items():
            if results:
                avg_score = sum(r.get('score', r.get('raw_score', 0)) for r in results) / len(results)
                max_score = max(r.get('score', r.get('raw_score', 0)) for r in results)
                print(f"{method}: í‰ê·  ì ìˆ˜ {avg_score:.4f}, ìµœê³  ì ìˆ˜ {max_score:.4f}")

        # 3. ìƒìœ„ ê²°ê³¼ ë¹„êµ
        print(f"\nğŸ† ê° ë°©ë²•ë³„ ìµœê³  ì ìˆ˜ ê²°ê³¼:")
        for method, results in methods_results.items():
            if results:
                best_result = max(results, key=lambda x: x.get('score', x.get('raw_score', 0)))
                score = best_result.get('score', best_result.get('raw_score', 0))
                content_preview = best_result['content'][:80].replace('\n', ' ') + "..."
                print(f"  {method}: {score:.4f} - {content_preview}")

        # 4. ê³ ìœ ì„± ë¶„ì„ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì˜ ê²½ìš°)
        if 'hybrid' in methods_results and methods_results['hybrid']:
            hybrid_results = methods_results['hybrid']
            query_type_stats = {}
            for result in hybrid_results:
                if 'metadata' in result and 'query_types' in result['metadata']:
                    query_types = result['metadata']['query_types']
                    for qt in query_types:
                        query_type_stats[qt] = query_type_stats.get(qt, 0) + 1

            if query_type_stats:
                print(f"\nğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬ì„±:")
                for qt, count in query_type_stats.items():
                    print(f"  - {qt}: {count}ê°œ")

def run_comprehensive_hyde_test():
    """í¬ê´„ì  HyDE í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ HyDE í¬ê´„ì  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("="*80)

    try:
        # í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        test_system = ComprehensiveHyDETestSystem()

        # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
        test_questions = [
            "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ê°€ ë³µì¡í•´ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤",
            "ì„œë²„ì— ì ‘ì†í•  ìˆ˜ ì—†ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì‹¶ì–´ìš”",
            "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ìì£¼ ëŠì–´ì§€ëŠ” í˜„ìƒì„ ì¡°ì‚¬í•´ì£¼ì„¸ìš”",
            "API ì‘ë‹µ ì‹œê°„ì´ ë„ˆë¬´ ëŠë ¤ì„œ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤",
            "ëª¨ë°”ì¼ ì•±ì—ì„œ ë¡œê·¸ì¸ì´ ì•ˆ ë˜ëŠ” ë¬¸ì œê°€ ìˆì–´ìš”"
        ]

        # ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        all_test_results = {}

        for i, question in enumerate(test_questions, 1):
            print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ {i}/{len(test_questions)}: {question}")
            print("="*80)

            # ëª¨ë“  ë°©ë²• ë¹„êµ
            comparison_results = test_system.compare_all_methods(question, n_results=3)
            all_test_results[f"test_{i}"] = {
                'question': question,
                'results': comparison_results
            }

            # ê°„ë‹¨í•œ ê²°ê³¼ ìš”ì•½
            print(f"\nâœ… í…ŒìŠ¤íŠ¸ {i} ì™„ë£Œ")

        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ‰ ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("="*80)

        # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f"hyde_comprehensive_test_results_{timestamp}.json"

        # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        serializable_results = {}
        for test_key, test_data in all_test_results.items():
            serializable_results[test_key] = {
                'question': test_data['question'],
                'results': {}
            }

            for method, results in test_data['results'].items():
                serializable_results[test_key]['results'][method] = []
                for result in results:
                    # ì§ë ¬í™” ê°€ëŠ¥í•œ í•„ë“œë§Œ í¬í•¨
                    clean_result = {
                        'id': result.get('id', ''),
                        'content': result.get('content', '')[:200],  # ë‚´ìš© ê¸¸ì´ ì œí•œ
                        'score': result.get('score', result.get('raw_score', 0)),
                        'method': result.get('method', method),
                        'chunk_type': result.get('chunk_type', 'unknown')
                    }
                    serializable_results[test_key]['results'][method].append(clean_result)

        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“„ ìƒì„¸ ê²°ê³¼ ì €ì¥: {results_file}")

        # ì „ì²´ í†µê³„ ìš”ì•½
        print(f"\nğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ í†µê³„:")
        method_totals = {'basic': 0, 'multi_query': 0, 'hyde': 0, 'hybrid': 0}

        for test_data in all_test_results.values():
            for method, results in test_data['results'].items():
                method_totals[method] += len(results)

        for method, total in method_totals.items():
            avg_per_test = total / len(test_questions)
            print(f"  - {method}: ì´ {total}ê°œ ê²°ê³¼ (í‰ê·  {avg_per_test:.1f}ê°œ/í…ŒìŠ¤íŠ¸)")

        return True

    except Exception as e:
        print(f"âŒ í¬ê´„ì  HyDE í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    run_comprehensive_hyde_test()