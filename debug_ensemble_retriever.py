#!/usr/bin/env python3
"""
EnsembleRetriever ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
Vector Retrieverì™€ BM25 Retrieverë¥¼ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ì—¬ ë¬¸ì œë¥¼ ì§„ë‹¨í•©ë‹ˆë‹¤.
"""

import logging
from typing import List, Dict, Any
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from vector_db_models import VectorDBManager
from text_preprocessor import preprocess_for_embedding
from keyword_extractor import KeywordExtractor
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnsembleRetrieverDebugger:
    """EnsembleRetriever ë””ë²„ê¹… í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.vector_db_manager = VectorDBManager()
        self.keyword_extractor = KeywordExtractor()
        self.documents = []
        self.bm25_retriever = None
        self.vector_retriever = None
        
        # ë¬¸ì„œ ìˆ˜ì§‘ ë° ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        self._collect_documents()
        self._setup_retrievers()
    
    def _collect_documents(self):
        """ëª¨ë“  ë¬¸ì„œë¥¼ ìˆ˜ì§‘í•˜ì—¬ Document ê°ì²´ ìƒì„±"""
        try:
            logger.info("ğŸ“š ë¬¸ì„œ ìˆ˜ì§‘ ì‹œì‘...")
            
            # 1. íŒŒì¼ ì²­í¬ ë¬¸ì„œ ìˆ˜ì§‘
            file_chunks_docs = self._get_file_chunks()
            self.documents.extend(file_chunks_docs)
            logger.info(f"âœ… íŒŒì¼ ì²­í¬ ë¬¸ì„œ {len(file_chunks_docs)}ê°œ ìˆ˜ì§‘")
            
            # 2. ë©”ì¼ ë¬¸ì„œ ìˆ˜ì§‘
            mail_docs = self._get_mail_documents()
            self.documents.extend(mail_docs)
            logger.info(f"âœ… ë©”ì¼ ë¬¸ì„œ {len(mail_docs)}ê°œ ìˆ˜ì§‘")
            
            # 3. êµ¬ì¡°ì  ì²­í¬ ë¬¸ì„œ ìˆ˜ì§‘
            structured_docs = self._get_structured_documents()
            self.documents.extend(structured_docs)
            logger.info(f"âœ… êµ¬ì¡°ì  ì²­í¬ ë¬¸ì„œ {len(structured_docs)}ê°œ ìˆ˜ì§‘")
            
            logger.info(f"âœ… ì´ {len(self.documents)}ê°œ ë¬¸ì„œ ìˆ˜ì§‘ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            self.documents = []
    
    def _get_file_chunks(self) -> List[Document]:
        """íŒŒì¼ ì²­í¬ ë¬¸ì„œë“¤ì„ Document ê°ì²´ë¡œ ë³€í™˜"""
        documents = []
        try:
            file_chunks = self.vector_db_manager.get_all_file_chunks()
            for chunk in file_chunks:
                content = chunk.get('content', '')
                if content and len(content.strip()) > 0:
                    metadata = chunk.get('metadata', {})
                    metadata.update({
                        'source_type': 'file_chunk',
                        'chunk_id': chunk.get('chunk_id', ''),
                        'file_name': chunk.get('file_name', '')
                    })
                    documents.append(Document(page_content=content, metadata=metadata))
        except Exception as e:
            logger.error(f"íŒŒì¼ ì²­í¬ ë¬¸ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return documents
    
    def _get_mail_documents(self) -> List[Document]:
        """ë©”ì¼ ë¬¸ì„œë“¤ì„ Document ê°ì²´ë¡œ ë³€í™˜"""
        documents = []
        try:
            mails = self.vector_db_manager.get_all_mails()
            for mail in mails:
                content = mail.get('content', '')
                if content and len(content.strip()) > 0:
                    metadata = mail.get('metadata', {})
                    metadata.update({
                        'source_type': 'mail',
                        'message_id': mail.get('message_id', ''),
                        'subject': mail.get('subject', ''),
                        'sender': mail.get('sender', '')
                    })
                    documents.append(Document(page_content=content, metadata=metadata))
        except Exception as e:
            logger.error(f"ë©”ì¼ ë¬¸ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return documents
    
    def _get_structured_documents(self) -> List[Document]:
        """êµ¬ì¡°ì  ì²­í¬ ë¬¸ì„œë“¤ì„ Document ê°ì²´ë¡œ ë³€í™˜"""
        documents = []
        try:
            structured_chunks = self.vector_db_manager.get_all_structured_chunks()
            for chunk in structured_chunks:
                content = chunk.get('content', '')
                if content and len(content.strip()) > 0:
                    metadata = chunk.get('metadata', {})
                    metadata.update({
                        'source_type': 'structured_chunk',
                        'chunk_id': chunk.get('chunk_id', ''),
                        'ticket_id': chunk.get('ticket_id', ''),
                        'chunk_type': chunk.get('chunk_type', '')
                    })
                    documents.append(Document(page_content=content, metadata=metadata))
        except Exception as e:
            logger.error(f"êµ¬ì¡°ì  ì²­í¬ ë¬¸ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return documents
    
    def _setup_retrievers(self):
        """BM25Retrieverì™€ Vector Retriever ì„¤ì •"""
        try:
            # 1. BM25Retriever ìƒì„±
            if not self.documents:
                logger.warning("âš ï¸ ìˆ˜ì§‘ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            logger.info("ğŸ” BM25Retriever ìƒì„± ì¤‘...")
            self.bm25_retriever = BM25Retriever.from_documents(self.documents, k=10)
            logger.info("âœ… BM25Retriever ìƒì„± ì™„ë£Œ")
            
            # 2. Vector Retriever ìƒì„± (VectorDBManager ê¸°ë°˜)
            logger.info("ğŸ” Vector Retriever ìƒì„± ì¤‘...")
            self.vector_retriever = self._create_vector_retriever()
            logger.info("âœ… Vector Retriever ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ Retriever ì„¤ì • ì‹¤íŒ¨: {e}")
            self.bm25_retriever = None
            self.vector_retriever = None
    
    def _create_vector_retriever(self):
        """VectorDBManagerë¥¼ ìœ„í•œ Vector Retriever ìƒì„±"""
        from multi_query_retriever import ChromaDBRetriever
        return ChromaDBRetriever(
            vector_db_manager=self.vector_db_manager,
            collection_name="file_chunks"
        )
    
    def test_vector_retriever(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """Vector Retriever ë‹¨ë… í…ŒìŠ¤íŠ¸"""
        logger.info(f"ğŸ” Vector Retriever ë‹¨ë… í…ŒìŠ¤íŠ¸: '{query}'")
        
        if not self.vector_retriever:
            logger.error("âŒ Vector Retrieverê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            # ì¿¼ë¦¬ ì „ì²˜ë¦¬
            preprocessed_query = preprocess_for_embedding(query)
            logger.info(f"ğŸ” ì „ì²˜ë¦¬ëœ ì¿¼ë¦¬: '{preprocessed_query}'")
            
            # Vector ê²€ìƒ‰ ìˆ˜í–‰
            documents = self.vector_retriever.get_relevant_documents(preprocessed_query)
            
            # ê²°ê³¼ ë³€í™˜
            results = []
            for i, doc in enumerate(documents[:k]):
                result = {
                    "id": f"vector_{i}",
                    "content": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
                    "metadata": doc.metadata,
                    "similarity_score": doc.metadata.get('similarity_score', 0.0),
                    "source_type": "vector_search"
                }
                results.append(result)
            
            logger.info(f"âœ… Vector Retriever í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            logger.error(f"âŒ Vector Retriever í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return []
    
    def test_bm25_retriever(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """BM25 Retriever ë‹¨ë… í…ŒìŠ¤íŠ¸"""
        logger.info(f"ğŸ” BM25 Retriever ë‹¨ë… í…ŒìŠ¤íŠ¸: '{query}'")
        
        if not self.bm25_retriever:
            logger.error("âŒ BM25 Retrieverê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self.keyword_extractor.extract_keywords(query)
            keyword_query = " ".join(keywords)
            logger.info(f"ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
            logger.info(f"ğŸ” BM25 ê²€ìƒ‰ ì¿¼ë¦¬: '{keyword_query}'")
            
            # ì¿¼ë¦¬ ì „ì²˜ë¦¬
            preprocessed_query = preprocess_for_embedding(keyword_query)
            logger.info(f"ğŸ” ì „ì²˜ë¦¬ëœ BM25 ì¿¼ë¦¬: '{preprocessed_query}'")
            
            # BM25 ê²€ìƒ‰ ìˆ˜í–‰
            documents = self.bm25_retriever.get_relevant_documents(preprocessed_query)
            
            # ê²°ê³¼ ë³€í™˜
            results = []
            for i, doc in enumerate(documents[:k]):
                result = {
                    "id": f"bm25_{i}",
                    "content": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
                    "metadata": doc.metadata,
                    "similarity_score": 0.0,  # BM25ëŠ” ì§ì ‘ì ì¸ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
                    "source_type": "bm25_search",
                    "extracted_keywords": keywords
                }
                results.append(result)
            
            logger.info(f"âœ… BM25 Retriever í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            logger.error(f"âŒ BM25 Retriever í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return []
    
    def analyze_documents(self):
        """ìˆ˜ì§‘ëœ ë¬¸ì„œ ë¶„ì„"""
        logger.info("ğŸ“Š ë¬¸ì„œ ë¶„ì„ ì‹œì‘...")
        
        if not self.documents:
            logger.warning("âš ï¸ ë¶„ì„í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë¬¸ì„œ íƒ€ì…ë³„ í†µê³„
        source_types = {}
        total_content_length = 0
        empty_docs = 0
        
        for doc in self.documents:
            source_type = doc.metadata.get('source_type', 'unknown')
            source_types[source_type] = source_types.get(source_type, 0) + 1
            
            content_length = len(doc.page_content)
            total_content_length += content_length
            
            if content_length == 0:
                empty_docs += 1
        
        logger.info(f"ğŸ“Š ë¬¸ì„œ ë¶„ì„ ê²°ê³¼:")
        logger.info(f"  - ì´ ë¬¸ì„œ ìˆ˜: {len(self.documents)}")
        logger.info(f"  - ë¹ˆ ë¬¸ì„œ ìˆ˜: {empty_docs}")
        logger.info(f"  - í‰ê·  ë‚´ìš© ê¸¸ì´: {total_content_length / len(self.documents):.1f}ì")
        logger.info(f"  - ë¬¸ì„œ íƒ€ì…ë³„ ë¶„í¬:")
        for source_type, count in source_types.items():
            logger.info(f"    * {source_type}: {count}ê°œ")
        
        # ìƒ˜í”Œ ë¬¸ì„œ ë‚´ìš© ì¶œë ¥
        logger.info(f"ğŸ“„ ìƒ˜í”Œ ë¬¸ì„œ ë‚´ìš© (ì²˜ìŒ 3ê°œ):")
        for i, doc in enumerate(self.documents[:3]):
            logger.info(f"  ë¬¸ì„œ {i+1}:")
            logger.info(f"    - íƒ€ì…: {doc.metadata.get('source_type', 'unknown')}")
            logger.info(f"    - ë‚´ìš© ê¸¸ì´: {len(doc.page_content)}ì")
            logger.info(f"    - ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:100]}...")
    
    def run_debug_test(self, test_query: str):
        """ì „ì²´ ë””ë²„ê¹… í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("=" * 80)
        logger.info("ğŸ” EnsembleRetriever ë””ë²„ê¹… í…ŒìŠ¤íŠ¸ ì‹œì‘")
        logger.info("=" * 80)
        
        # 1. ë¬¸ì„œ ë¶„ì„
        self.analyze_documents()
        
        logger.info("\n" + "=" * 80)
        logger.info(f"ğŸ¯ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{test_query}'")
        logger.info("=" * 80)
        
        # 2. Vector Retriever í…ŒìŠ¤íŠ¸
        logger.info("\nğŸ” Vector Retriever ë‹¨ë… í…ŒìŠ¤íŠ¸")
        logger.info("-" * 50)
        vector_results = self.test_vector_retriever(test_query, k=5)
        
        if vector_results:
            logger.info(f"âœ… Vector Retriever ê²°ê³¼ ({len(vector_results)}ê°œ):")
            for i, result in enumerate(vector_results):
                logger.info(f"  {i+1}. ID: {result['id']}")
                logger.info(f"     ë‚´ìš©: {result['content']}")
                logger.info(f"     ìœ ì‚¬ë„: {result['similarity_score']}")
                logger.info(f"     ë©”íƒ€ë°ì´í„°: {result['metadata']}")
                logger.info("")
        else:
            logger.warning("âš ï¸ Vector Retriever ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # 3. BM25 Retriever í…ŒìŠ¤íŠ¸
        logger.info("\nğŸ” BM25 Retriever ë‹¨ë… í…ŒìŠ¤íŠ¸")
        logger.info("-" * 50)
        bm25_results = self.test_bm25_retriever(test_query, k=5)
        
        if bm25_results:
            logger.info(f"âœ… BM25 Retriever ê²°ê³¼ ({len(bm25_results)}ê°œ):")
            for i, result in enumerate(bm25_results):
                logger.info(f"  {i+1}. ID: {result['id']}")
                logger.info(f"     ë‚´ìš©: {result['content']}")
                logger.info(f"     ì¶”ì¶œëœ í‚¤ì›Œë“œ: {result['extracted_keywords']}")
                logger.info(f"     ë©”íƒ€ë°ì´í„°: {result['metadata']}")
                logger.info("")
        else:
            logger.warning("âš ï¸ BM25 Retriever ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # 4. ê²°ê³¼ ë¹„êµ ë° ë¶„ì„
        logger.info("\nğŸ“Š ê²°ê³¼ ë¹„êµ ë° ë¶„ì„")
        logger.info("-" * 50)
        logger.info(f"Vector Retriever ê²°ê³¼ ìˆ˜: {len(vector_results)}")
        logger.info(f"BM25 Retriever ê²°ê³¼ ìˆ˜: {len(bm25_results)}")
        
        if vector_results and bm25_results:
            # ì¤‘ë³µ ë¬¸ì„œ í™•ì¸
            vector_ids = {result['id'] for result in vector_results}
            bm25_ids = {result['id'] for result in bm25_results}
            common_ids = vector_ids.intersection(bm25_ids)
            
            logger.info(f"ê³µí†µ ê²°ê³¼ ìˆ˜: {len(common_ids)}")
            if common_ids:
                logger.info(f"ê³µí†µ ê²°ê³¼ ID: {list(common_ids)}")
        
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ” EnsembleRetriever ë””ë²„ê¹… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        logger.info("=" * 80)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì •ì˜
    test_query = "ì„œë²„ ì ‘ì†ì´ ì•ˆ ë˜ê³  HTTP 500 ì˜¤ë¥˜ê°€ ë‚˜ëŠ” ë¬¸ì œ ìˆë‚˜ìš”?"
    
    # ë””ë²„ê±° ì´ˆê¸°í™” ë° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    debugger = EnsembleRetrieverDebugger()
    debugger.run_debug_test(test_query)

if __name__ == "__main__":
    main()
