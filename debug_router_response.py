#!/usr/bin/env python3
"""
ë¼ìš°í„° ì—ì´ì „íŠ¸ ì‘ë‹µ ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
"""

import os
import logging
from dotenv import load_dotenv
from langchain_openai import AzureChatOpenAI
from router_agent import create_router_agent

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def debug_router_response():
    """ë¼ìš°í„° ì—ì´ì „íŠ¸ ì‘ë‹µ ë””ë²„ê¹…"""
    print("ğŸ” ë¼ìš°í„° ì—ì´ì „íŠ¸ ì‘ë‹µ ë””ë²„ê¹… ì‹œì‘")
    print("=" * 60)
    
    # LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    llm = AzureChatOpenAI(
        azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-4.1"),
        api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-10-21"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        temperature=0.1
    )
    
    # ë¼ìš°í„° ì—ì´ì „íŠ¸ ìƒì„±
    router = create_router_agent(llm)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    query = "ì•ˆ ì½ì€ ë©”ì¼ 3ê°œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”"
    print(f"ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {query}")
    print("-" * 40)
    
    try:
        # ë¼ìš°í„° ì—ì´ì „íŠ¸ ì‹¤í–‰
        result = router.execute(query)
        
        print(f"âœ… ìµœì¢… ì‘ë‹µ: {result}")
        print(f"ğŸ“Š ì‘ë‹µ íƒ€ì…: {type(result)}")
        print(f"ğŸ“ ì‘ë‹µ ê¸¸ì´: {len(str(result))}")
        
        # ì‘ë‹µ ë‚´ìš© ë¶„ì„
        if "OAuth" in result or "ì¸ì¦" in result:
            print("âœ… OAuth ì¸ì¦ ë©”ì‹œì§€ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        elif "í‹°ì¼“" in result:
            print("âŒ í‹°ì¼“ ê´€ë ¨ ë©”ì‹œì§€ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        else:
            print("âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ ë‚´ìš©ì…ë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ë¼ìš°í„° ì—ì´ì „íŠ¸ ì‘ë‹µ ë””ë²„ê¹… ì™„ë£Œ!")

if __name__ == "__main__":
    debug_router_response()
