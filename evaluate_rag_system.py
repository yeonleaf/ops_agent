#!/usr/bin/env python3
"""
RAG ì‹œìŠ¤í…œ ì •í™•ë„ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

test_data.csvì˜ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ RAG ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
- MRR (Mean Reciprocal Rank): ì •ë‹µì´ ë‚˜íƒ€ë‚˜ëŠ” ìœ„ì¹˜ì˜ ì—­ìˆ˜ í‰ê· 
- Hit@K: ìƒìœ„ Kê°œ ê²°ê³¼ì— ì •ë‹µì´ í¬í•¨ë˜ëŠ” ë¹„ìœ¨
- Top-1 Accuracy: 1ìœ„ê°€ ì •ë‹µì¸ ë¹„ìœ¨
"""

import csv
import os
import sys
import logging
from typing import List, Dict, Any, Tuple
from datetime import datetime
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rrf_fusion_rag_system import RRFRAGSystem, RRFConfig

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/rag_evaluation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class RAGEvaluator:
    """RAG ì‹œìŠ¤í…œ í‰ê°€ í´ë˜ìŠ¤"""

    def __init__(self, rag_system: RRFRAGSystem):
        """
        RAG í‰ê°€ê¸° ì´ˆê¸°í™”

        Args:
            rag_system: í‰ê°€í•  RAG ì‹œìŠ¤í…œ
        """
        self.rag_system = rag_system
        self.results = []

    def load_test_data(self, csv_path: str) -> List[Dict[str, Any]]:
        """
        í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ (ì—¬ëŸ¬ ì •ë‹µ ì§€ì›)

        Args:
            csv_path: CSV íŒŒì¼ ê²½ë¡œ

        Returns:
            í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë¦¬ìŠ¤íŠ¸ [{'query': '...', 'answer_ticket_ids': ['...', '...']}, ...]
        """
        test_cases = []
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    # ì„¸ë¯¸ì½œë¡ (;)ìœ¼ë¡œ êµ¬ë¶„ëœ ì—¬ëŸ¬ ì •ë‹µ ì²˜ë¦¬
                    answer_ids = [id.strip() for id in row['answer_ticket_id'].split(';') if id.strip()]
                    # ì¤‘ë³µ ì œê±°
                    answer_ids = list(dict.fromkeys(answer_ids))

                    test_cases.append({
                        'query': row['query'],
                        'answer_ticket_ids': answer_ids  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€ê²½
                    })

            total_answers = sum(len(tc['answer_ticket_ids']) for tc in test_cases)
            logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(test_cases)}ê°œ ì¼€ì´ìŠ¤, {total_answers}ê°œ ì •ë‹µ")
            return test_cases
        except Exception as e:
            logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise e

    def extract_ticket_id(self, metadata: Dict[str, Any]) -> str:
        """
        ë©”íƒ€ë°ì´í„°ì—ì„œ í‹°ì¼“ ID ì¶”ì¶œ

        Args:
            metadata: ë¬¸ì„œ ë©”íƒ€ë°ì´í„°

        Returns:
            í‹°ì¼“ ID (ì˜ˆ: "BTVO-61021")
        """
        # ê°€ëŠ¥í•œ í‚¤ ëª©ë¡
        possible_keys = ['ticket_id', 'ticket_key', 'jira_key', 'issue_key', 'key', 'id']

        for key in possible_keys:
            if key in metadata:
                ticket_id = metadata[key]
                # BTVO-ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (í•„ìš”ì‹œ)
                if isinstance(ticket_id, str):
                    return ticket_id

        # ë©”íƒ€ë°ì´í„° ì „ì²´ ë¡œê¹… (ë””ë²„ê·¸ìš©)
        logger.debug(f"ë©”íƒ€ë°ì´í„°ì—ì„œ ticket_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {metadata}")
        return None

    def find_best_answer_rank(self, search_results: List[Dict[str, Any]],
                              answer_ticket_ids: List[str]) -> Tuple[int, bool, str]:
        """
        ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì—¬ëŸ¬ ì •ë‹µ ì¤‘ ê°€ì¥ ë†’ì€ ìˆœìœ„ ì°¾ê¸°

        Args:
            search_results: RAG ê²€ìƒ‰ ê²°ê³¼
            answer_ticket_ids: ì •ë‹µ í‹°ì¼“ ID ë¦¬ìŠ¤íŠ¸

        Returns:
            (ìˆœìœ„, ë°œê²¬ ì—¬ë¶€, ë°œê²¬ëœ í‹°ì¼“ ID) íŠœí”Œ. ìˆœìœ„ëŠ” 1ë¶€í„° ì‹œì‘, ì—†ìœ¼ë©´ -1
        """
        best_rank = -1
        found_ticket = None

        for rank, result in enumerate(search_results, start=1):
            metadata = result.get('metadata', {})
            ticket_id = self.extract_ticket_id(metadata)

            if ticket_id and ticket_id in answer_ticket_ids:
                # ì²« ë²ˆì§¸ ë°œê²¬ëœ ì •ë‹µ (ê°€ì¥ ë†’ì€ ìˆœìœ„)
                best_rank = rank
                found_ticket = ticket_id
                break

        if best_rank > 0:
            return best_rank, True, found_ticket
        else:
            return -1, False, None

    def evaluate_single_query(self, query: str, answer_ticket_ids: List[str]) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì¿¼ë¦¬ í‰ê°€ (ì—¬ëŸ¬ ì •ë‹µ ì§€ì›)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            answer_ticket_ids: ì •ë‹µ í‹°ì¼“ ID ë¦¬ìŠ¤íŠ¸

        Returns:
            í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            answer_str = ', '.join(answer_ticket_ids)
            logger.info(f"ğŸ” í‰ê°€ ì¤‘: '{query}' (ì •ë‹µ: {answer_str})")

            # RAG ê²€ìƒ‰ ì‹¤í–‰
            search_results = self.rag_system.rrf_search(query)

            if not search_results:
                logger.warning(f"âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: '{query}'")
                return {
                    'query': query,
                    'answer_ticket_ids': answer_ticket_ids,
                    'rank': -1,
                    'found': False,
                    'found_ticket': None,
                    'reciprocal_rank': 0.0,
                    'top_results': []
                }

            # ì—¬ëŸ¬ ì •ë‹µ ì¤‘ ê°€ì¥ ë†’ì€ ìˆœìœ„ ì°¾ê¸°
            rank, found, found_ticket = self.find_best_answer_rank(search_results, answer_ticket_ids)

            # ìƒìœ„ 10ê°œ ê²°ê³¼ (ë””ë²„ê¹…ìš© - ë” ë§ì´ í‘œì‹œ)
            top_results = []
            for i, result in enumerate(search_results[:10], start=1):
                metadata = result.get('metadata', {})
                ticket_id = self.extract_ticket_id(metadata)
                is_answer = ticket_id in answer_ticket_ids if ticket_id else False
                top_results.append({
                    'rank': i,
                    'ticket_id': ticket_id,
                    'is_answer': is_answer,
                    'score': result.get('score', 0.0),
                    'rrf_score': metadata.get('rrf_score', 0.0)
                })

            # Reciprocal Rank ê³„ì‚°
            reciprocal_rank = 1.0 / rank if found else 0.0

            result = {
                'query': query,
                'answer_ticket_ids': answer_ticket_ids,
                'rank': rank,
                'found': found,
                'found_ticket': found_ticket,
                'reciprocal_rank': reciprocal_rank,
                'top_results': top_results
            }

            if found:
                logger.info(f"âœ… ì •ë‹µ ë°œê²¬: {found_ticket} (ìˆœìœ„ {rank})")
            else:
                logger.warning(f"âŒ ì •ë‹µ ë¯¸ë°œê²¬: {answer_str}")

            return result

        except Exception as e:
            logger.error(f"âŒ ì¿¼ë¦¬ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {
                'query': query,
                'answer_ticket_ids': answer_ticket_ids,
                'rank': -1,
                'found': False,
                'found_ticket': None,
                'reciprocal_rank': 0.0,
                'error': str(e),
                'top_results': []
            }

    def evaluate_all(self, test_cases: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ í‰ê°€

        Args:
            test_cases: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë¦¬ìŠ¤íŠ¸

        Returns:
            í‰ê°€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []

        logger.info(f"ğŸš€ ì „ì²´ í‰ê°€ ì‹œì‘: {len(test_cases)}ê°œ ì¼€ì´ìŠ¤")

        for i, test_case in enumerate(test_cases, start=1):
            logger.info(f"\n{'='*60}")
            logger.info(f"ì§„í–‰ë¥ : {i}/{len(test_cases)}")

            result = self.evaluate_single_query(
                test_case['query'],
                test_case['answer_ticket_ids']  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€ê²½
            )
            results.append(result)

        logger.info(f"\n{'='*60}")
        logger.info("âœ… ì „ì²´ í‰ê°€ ì™„ë£Œ")

        self.results = results
        return results

    def calculate_metrics(self, results: List[Dict[str, Any]]) -> Dict[str, float]:
        """
        í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°

        Args:
            results: í‰ê°€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

        Returns:
            ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
        """
        total = len(results)

        if total == 0:
            return {}

        # MRR (Mean Reciprocal Rank)
        mrr = sum(r['reciprocal_rank'] for r in results) / total

        # Hit@K ê³„ì‚°
        def hit_at_k(k: int) -> float:
            hits = sum(1 for r in results if r['found'] and r['rank'] <= k and r['rank'] > 0)
            return hits / total

        hit_at_1 = hit_at_k(1)
        hit_at_3 = hit_at_k(3)
        hit_at_5 = hit_at_k(5)
        hit_at_10 = hit_at_k(10)

        # Top-1 Accuracy (=Hit@1)
        top1_accuracy = hit_at_1

        # ì •ë‹µ ë°œê²¬ìœ¨ (ì „ì²´ ê²°ê³¼ì—ì„œ)
        found_rate = sum(1 for r in results if r['found']) / total

        # í‰ê·  ìˆœìœ„ (ì •ë‹µì´ ë°œê²¬ëœ ê²½ìš°ë§Œ)
        found_results = [r for r in results if r['found']]
        avg_rank = sum(r['rank'] for r in found_results) / len(found_results) if found_results else 0.0

        metrics = {
            'total_queries': total,
            'mrr': mrr,
            'hit@1': hit_at_1,
            'hit@3': hit_at_3,
            'hit@5': hit_at_5,
            'hit@10': hit_at_10,
            'top1_accuracy': top1_accuracy,
            'found_rate': found_rate,
            'avg_rank': avg_rank,
            'found_count': len(found_results)
        }

        return metrics

    def print_metrics(self, metrics: Dict[str, float]):
        """ë©”íŠ¸ë¦­ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š RAG ì‹œìŠ¤í…œ í‰ê°€ ê²°ê³¼")
        print("="*60)
        print(f"ì´ ì¿¼ë¦¬ ìˆ˜: {metrics['total_queries']}")
        print(f"ì •ë‹µ ë°œê²¬ ìˆ˜: {metrics['found_count']}")
        print(f"ì •ë‹µ ë°œê²¬ìœ¨: {metrics['found_rate']:.2%}")
        print()
        print("ğŸ“ˆ ì£¼ìš” ë©”íŠ¸ë¦­:")
        print(f"  MRR (Mean Reciprocal Rank): {metrics['mrr']:.4f}")
        print(f"  Top-1 Accuracy (Hit@1):     {metrics['top1_accuracy']:.2%}")
        print(f"  Hit@3:                      {metrics['hit@3']:.2%}")
        print(f"  Hit@5:                      {metrics['hit@5']:.2%}")
        print(f"  Hit@10:                     {metrics['hit@10']:.2%}")
        print()
        print(f"í‰ê·  ì •ë‹µ ìˆœìœ„ (ë°œê²¬ëœ ê²½ìš°): {metrics['avg_rank']:.2f}")
        print("="*60)

    def save_results(self, results: List[Dict[str, Any]], metrics: Dict[str, float],
                    output_path: str):
        """
        í‰ê°€ ê²°ê³¼ ì €ì¥

        Args:
            results: í‰ê°€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            metrics: ë©”íŠ¸ë¦­
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        try:
            output_data = {
                'timestamp': datetime.now().isoformat(),
                'metrics': metrics,
                'results': results
            }

            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ… í‰ê°€ ê²°ê³¼ ì €ì¥: {output_path}")

        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('logs', exist_ok=True)

        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        logger.info("ğŸ”§ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        rrf_config = RRFConfig(
            rrf_k=60,
            multi_query_results=20,
            hyde_results=20,
            bm25_results=20,
            final_candidates=30,
            enable_bm25=True,
            bm25_tokenizer="korean"
        )

        rag_system = RRFRAGSystem(
            collection_name="jira_chunks",
            rrf_config=rrf_config
        )

        # í‰ê°€ê¸° ì´ˆê¸°í™”
        evaluator = RAGEvaluator(rag_system)

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        test_data_path = "test_data.csv"
        test_cases = evaluator.load_test_data(test_data_path)

        # í‰ê°€ ì‹¤í–‰
        results = evaluator.evaluate_all(test_cases)

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = evaluator.calculate_metrics(results)

        # ê²°ê³¼ ì¶œë ¥
        evaluator.print_metrics(metrics)

        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = f"rag_evaluation_results_{timestamp}.json"
        evaluator.save_results(results, metrics, output_path)

        # ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„
        failed_cases = [r for r in results if not r['found']]
        if failed_cases:
            print("\nâŒ ì •ë‹µì„ ì°¾ì§€ ëª»í•œ ì¼€ì´ìŠ¤:")
            for case in failed_cases[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥
                print(f"  - ì¿¼ë¦¬: {case['query']}")
                answer_str = ', '.join(case['answer_ticket_ids'])
                print(f"    ì •ë‹µ: {answer_str}")
                if case.get('top_results'):
                    print(f"    ìƒìœ„ ê²°ê³¼: {[r['ticket_id'] for r in case['top_results'][:3]]}")

        logger.info("âœ… í‰ê°€ ì™„ë£Œ")

    except Exception as e:
        logger.error(f"âŒ í‰ê°€ ì‹¤íŒ¨: {e}")
        raise e


if __name__ == "__main__":
    main()
