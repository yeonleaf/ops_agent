#!/usr/bin/env python3
"""
RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•œ Golden Set ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (ì‹¤ì œ RAG ê²€ìƒ‰ ì—°ê²°)
ê¸°ì¡´ generate_golden_set.pyë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ RAG ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ ì—°ê²°í•œ ë²„ì „ì…ë‹ˆë‹¤.
"""

import os
import sys
import pandas as pd
import json
from datetime import datetime
from typing import Dict, List, Any
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from generate_golden_set import (
    initialize_azure_openai, 
    generate_question_for_ticket, 
    log_test_case,
    JIRA_CSV_FILE_PATH,
    OUTPUT_LOG_FILE,
    QUESTIONS_PER_TICKET,
    MAX_TICKETS_TO_PROCESS
)

# RAG ê´€ë ¨ ëª¨ë“ˆë“¤ import
from multi_vector_cross_encoder_rag import MultiVectorCrossEncoderRAG

# ==================== í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì •ì˜ ====================

# 1. ì •ë‹µì´ ì—†ëŠ” ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ (Zero-shot & Negative Test)
NEGATIVE_TEST_QUESTIONS = [
    "í™”ì„± íƒì‚¬ì„  ê´€ë ¨ í‹°ì¼“ì´ ìˆë‚˜ìš”?",
    "ì¸ê³µì§€ëŠ¥ ë¡œë´‡ ê°œë°œ í”„ë¡œì íŠ¸ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ê³  ìˆë‚˜ìš”?",
    "ë¸”ë¡ì²´ì¸ ê¸°ìˆ ì„ í™œìš©í•œ ê²°ì œ ì‹œìŠ¤í…œì€ ì–¸ì œ ì¶œì‹œë˜ë‚˜ìš”?",
    "ìš°ì£¼ ì •ê±°ì¥ ê±´ì„¤ ê³„íšì— ëŒ€í•œ ìµœì‹  ìƒí™©ì„ ì•Œë ¤ì£¼ì„¸ìš”",
    "ì–‘ìì»´í“¨íŒ… ì—°êµ¬ í”„ë¡œì íŠ¸ì˜ ì§„í–‰ ìƒí™©ì€ ì–´ë–¤ê°€ìš”?",
    "ê°€ìƒí˜„ì‹¤ í—¤ë“œì…‹ ê´€ë ¨ ê¸°ìˆ  ì´ìŠˆê°€ ìˆë‚˜ìš”?",
    "ììœ¨ì£¼í–‰ ìë™ì°¨ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ í˜„í™©ì€?",
    "í•´ì–‘ ì‹¬ì¸µ íƒì‚¬ ë¡œë´‡ í”„ë¡œì íŠ¸ëŠ” ì–¸ì œ ì™„ë£Œë˜ë‚˜ìš”?",
    "ì¸ê³µìœ„ì„± í†µì‹  ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë‚˜ìš”?",
    "í•µìœµí•© ë°œì „ì†Œ ê±´ì„¤ ê´€ë ¨ ê¸°ìˆ  ë¬¸ì œê°€ ìˆë‚˜ìš”?"
]

# 2. ë‹¤ì–‘ì„± ë° ë‚œì´ë„ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
DIVERSITY_TEST_QUESTIONS = [
    # ìš”ì•½í˜• ì§ˆë¬¸
    "ì„œë²„ ê´€ë ¨ ëª¨ë“  ì´ìŠˆë¥¼ ìš”ì•½í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”",
    "ë°ì´í„°ë² ì´ìŠ¤ ë¬¸ì œë“¤ì˜ ê³µí†µì ê³¼ í•´ê²° ë°©ì•ˆì„ ì •ë¦¬í•´ì£¼ì„¸ìš”",
    "ë°°ì¹˜ ì‘ì—… ì‹¤íŒ¨ ì‚¬ë¡€ë“¤ì˜ íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”",
    
    # ë¹„êµ/ëŒ€ì¡°í˜• ì§ˆë¬¸
    "ì„œë²„ ì ‘ì† ë¬¸ì œì™€ DB ì—°ê²° ë¬¸ì œì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "STG í™˜ê²½ê³¼ PROD í™˜ê²½ì—ì„œ ë°œìƒí•œ ì´ìŠˆë“¤ì„ ë¹„êµí•´ì£¼ì„¸ìš”",
    "ë°°ì¹˜ ì‘ì—…ê³¼ ì‹¤ì‹œê°„ ì‘ì—…ì˜ ì„±ëŠ¥ ì°¨ì´ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
    
    # ì‹œê°„ìˆœ ì§ˆë¬¸
    "ê°€ì¥ ìµœê·¼ì— ì²˜ë¦¬ëœ ë³´ì•ˆ ê´€ë ¨ í‹°ì¼“ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ì´ë²ˆ ì£¼ì— ë°œìƒí•œ ëª¨ë“  ì´ìŠˆë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”",
    "ì˜¤ë˜ëœ ë¯¸í•´ê²° í‹°ì¼“ ì¤‘ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê²ƒì€?",
    
    # ë³µí•© ì¶”ë¡  ì§ˆë¬¸
    "ì„±ëŠ¥ ì €í•˜ì˜ ì›ì¸ì´ ë  ìˆ˜ ìˆëŠ” ëª¨ë“  ìš”ì†Œë“¤ì„ ì°¾ì•„ì£¼ì„¸ìš”",
    "ì‚¬ìš©ì ê²½í—˜ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œ ì´ìŠˆë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”",
    "ë¹„ì¦ˆë‹ˆìŠ¤ ì—°ì†ì„±ì— ìœ„í—˜ì„ ì´ˆë˜í•  ìˆ˜ ìˆëŠ” ë¬¸ì œë“¤ì„ ì‹ë³„í•´ì£¼ì„¸ìš”"
]

# 3. ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
STRESS_TEST_QUESTIONS = [
    # ì¤‘ì˜ì  í‘œí˜„
    "ë°°í¬ê°€ 'ì•ˆ ëœ' ì´ìŠˆ ì¢€ ì°¾ì•„ì¤˜",
    "ì„œë²„ê°€ 'ì•ˆ ë˜ëŠ”' ë¬¸ì œê°€ ìˆë‚˜ìš”?",
    "DBê°€ 'ì•ˆ ëŒì•„ê°€ëŠ”' ìƒí™©ì„ í™•ì¸í•´ì£¼ì„¸ìš”",
    
    # ì˜¤íƒ€ í¬í•¨
    "ì„œë²„ 'ì¡‰ì†'ì´ ì•ˆë¼",
    "ë°ì´í„°ë² ì´ìŠ¤ 'ì—°ê²°' ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”",
    "ë°°ì¹˜ 'ì‘ì—…'ì´ ì‹¤íŒ¨í–ˆë‚˜ìš”?",
    "ë¡œê·¸ì¸ 'ì—ëŸ¬'ê°€ ê³„ì† ë°œìƒí•´ìš”",
    
    # ë§¤ìš° ì§§ì€ ì§ˆë¬¸
    "ì„œë²„",
    "DB",
    "ë°°ì¹˜",
    "ì˜¤ë¥˜",
    "ë¬¸ì œ",
    
    # ë§¤ìš° ê¸´ ì§ˆë¬¸ (ì¥í™©í•œ ìƒí™© ì„¤ëª…)
    "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ê°œë°œíŒ€ì—ì„œ ì¼í•˜ê³  ìˆëŠ”ë°, ì–´ì œë¶€í„° ê³„ì† ì„œë²„ì— ì ‘ì†ì´ ì•ˆ ë˜ê³  ìˆì–´ìš”. ì²˜ìŒì—ëŠ” ê°„í—ì ìœ¼ë¡œ ë°œìƒí–ˆëŠ”ë°, ì˜¤ëŠ˜ ì•„ì¹¨ë¶€í„°ëŠ” ì•„ì˜ˆ ì ‘ì†ì´ ì•ˆ ë˜ë„¤ìš”. ë‹¤ë¥¸ íŒ€ì›ë“¤ë„ ê°™ì€ ë¬¸ì œë¥¼ ê²ªê³  ìˆê³ , ê³ ê°ì‚¬ì—ì„œë„ ë¬¸ì˜ê°€ ë“¤ì–´ì˜¤ê³  ìˆì–´ì„œ ê¸‰í•œ ìƒí™©ì…ë‹ˆë‹¤. í˜¹ì‹œ ê´€ë ¨ëœ ì´ìŠˆë‚˜ í•´ê²° ë°©ë²•ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?",
    
    "ìš°ë¦¬ íšŒì‚¬ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ìƒê¸´ ê²ƒ ê°™ì•„ìš”. ì–´ì œ ì˜¤í›„ë¶€í„° ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ì´ í‰ì†Œë³´ë‹¤ 10ë°° ì´ìƒ ëŠë ¤ì¡Œê³ , ê°„í—ì ìœ¼ë¡œ íƒ€ì„ì•„ì›ƒì´ ë°œìƒí•˜ê³  ìˆì–´ìš”. íŠ¹íˆ ë°°ì¹˜ ì‘ì—…ì´ ì‹¤í–‰ë˜ëŠ” ì‹œê°„ëŒ€ì— ë” ì‹¬í•˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì´ì „ì— ë¹„ìŠ·í•œ ë¬¸ì œê°€ ìˆì—ˆëŠ”ì§€, ê·¸ë¦¬ê³  ì–´ë–¤ í•´ê²°ì±…ì´ ìˆì—ˆëŠ”ì§€ ì•Œê³  ì‹¶ì–´ìš”.",
    
    # ë³µì¡í•œ ì¡°ê±´ë¶€ ì§ˆë¬¸
    "ì„œë²„ ì ‘ì† ë¬¸ì œê°€ ìˆëŠ”ë°, ë‹¨ìˆœí•œ ë„¤íŠ¸ì›Œí¬ ë¬¸ì œê°€ ì•„ë‹ˆë¼ ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ì—ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œì¸ ê²ƒ ê°™ì•„ìš”. ë¡œê·¸ë¥¼ í™•ì¸í•´ë³´ë‹ˆ íŠ¹ì • ì‹œê°„ëŒ€ì—ë§Œ ë°œìƒí•˜ê³  ìˆê³ , íŠ¹íˆ ì‚¬ìš©ìê°€ ë§ì„ ë•Œ ë” ìì£¼ ë°œìƒí•˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì´ëŸ° íŒ¨í„´ì˜ ì´ìŠˆê°€ ì´ì „ì— ìˆì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.",
    
    # ëª¨í˜¸í•œ ì§ˆë¬¸
    "ë­”ê°€ ì´ìƒí•´ìš”",
    "ë¬¸ì œê°€ ìˆì–´ìš”",
    "ë„ì›€ì´ í•„ìš”í•´ìš”",
    "í™•ì¸í•´ì£¼ì„¸ìš”"
]

# ==================== ì‹¤ì œ RAG ê²€ìƒ‰ í•¨ìˆ˜ ====================
def search_rag(query: str) -> List[Dict[str, Any]]:
    """
    Multi-Vector + Cross-Encoder RAG ì‹œìŠ¤í…œì—ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
    
    Returns:
        List[Dict]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (id, content, score í¬í•¨)
    """
    try:
        # Multi-Vector Cross-Encoder RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rag = MultiVectorCrossEncoderRAG()
        
        # ê²€ìƒ‰ ì‹¤í–‰
        similar_content = rag.search(
            query=query,
            n_candidates=50,  # 1ë‹¨ê³„ í›„ë³´ ìˆ˜
            top_k=10         # ìµœì¢… ê²°ê³¼ ìˆ˜
        )
        
        # ê²°ê³¼ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        results = []
        for i, item in enumerate(similar_content):
            # Cross-Encoder ì ìˆ˜ ì‚¬ìš©
            raw_score = item.get('similarity_score', 0.0)
            
            # Cross-Encoder ì ìˆ˜ëŠ” ì´ë¯¸ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”ë¨
            similarity_score = max(0.0, min(1.0, raw_score))
            
            result = {
                "id": item.get("id", f"ITEM-{i}"),
                "content": item.get("content", ""),
                "score": similarity_score,
                "raw_score": raw_score,  # ì›ë³¸ ì ìˆ˜ë„ ë³´ê´€
                "similarity_to_query": similarity_score  # ì§ˆë¬¸ê³¼ì˜ ìœ ì‚¬ë„ ëª…ì‹œ
            }
            
            # Multi-Vector Cross-Encoder ê²€ìƒ‰ ê²°ê³¼ì¸ ê²½ìš°
            if item.get("source") == "multi_vector_cross_encoder":
                content = item.get('content', 'No Content')
                metadata = item.get('metadata', {})
                ticket_id = item.get('id', 'Unknown')
                
                # ë‚´ìš©ì´ ê¸¸ë©´ ì ì ˆíˆ ì˜ë¼ì„œ í‘œì‹œ
                if len(content) > 200:
                    content_preview = content[:200] + "..."
                else:
                    content_preview = content
                
                # Multi-Vector Cross-Encoder ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                result["content"] = f"[Multi-Vector Cross-Encoder] í‹°ì¼“: {ticket_id}\në‚´ìš©: {content_preview}"
            
            # ê¸°íƒ€ ê²°ê³¼ì¸ ê²½ìš° (file_chunk, mail ë“±)
            elif item.get("source") in ["file_chunk", "mail", "structured_chunk"]:
                content = item.get('content', 'No Content')
                metadata = item.get('metadata', {})
                source = item.get('source', 'unknown')
                
                # ë‚´ìš©ì´ ê¸¸ë©´ ì ì ˆíˆ ì˜ë¼ì„œ í‘œì‹œ
                if len(content) > 200:
                    content_preview = content[:200] + "..."
                else:
                    content_preview = content
                
                # ì†ŒìŠ¤ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ í‘œì‹œ í˜•ì‹
                if source == "file_chunk":
                    file_name = metadata.get('file_name', 'Unknown File')
                    result["content"] = f"[íŒŒì¼ ì²­í¬] {file_name}\në‚´ìš©: {content_preview}"
                elif source == "mail":
                    subject = metadata.get('subject', 'No Subject')
                    sender = metadata.get('sender', 'Unknown Sender')
                    result["content"] = f"[ë©”ì¼] {subject}\në°œì‹ ì: {sender}\në‚´ìš©: {content_preview}"
                elif source == "structured_chunk":
                    ticket_id = metadata.get('ticket_id', 'Unknown')
                    chunk_type = metadata.get('chunk_type', 'unknown')
                    field_name = metadata.get('field_name', 'unknown')
                    priority = metadata.get('priority', 3)
                    commenter = metadata.get('commenter', '')
                    
                    # ì²­í¬ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ í‘œì‹œ í˜•ì‹
                    if chunk_type == 'header':
                        result["content"] = f"[í—¤ë” ì²­í¬] {ticket_id} (ìš°ì„ ìˆœìœ„: {priority})\në‚´ìš©: {content_preview}"
                    elif chunk_type == 'comment':
                        commenter_info = f" (ì‘ì„±ì: {commenter})" if commenter else ""
                        result["content"] = f"[ëŒ“ê¸€ ì²­í¬] {ticket_id}{commenter_info} (ìš°ì„ ìˆœìœ„: {priority})\në‚´ìš©: {content_preview}"
                    else:
                        result["content"] = f"[êµ¬ì¡°ì  ì²­í¬] {ticket_id} - {field_name} (ìš°ì„ ìˆœìœ„: {priority})\níƒ€ì…: {chunk_type}\në‚´ìš©: {content_preview}"
                else:
                    # ê¸°íƒ€ ì†ŒìŠ¤ íƒ€ì…
                    result["content"] = f"[{source}] {content_preview}"
            
            # êµ¬ì¡°ì  ì²­í‚¹ ê²°ê³¼ì¸ ê²½ìš° (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
            elif item.get("source") == "structured_chunk":
                content = item.get('content', 'No Content')
                metadata = item.get('metadata', {})
                ticket_id = metadata.get('ticket_id', 'Unknown')
                chunk_type = metadata.get('chunk_type', 'unknown')
                field_name = metadata.get('field_name', 'unknown')
                priority = metadata.get('priority', 3)
                commenter = metadata.get('commenter', '')
                
                # ë‚´ìš©ì´ ê¸¸ë©´ ì ì ˆíˆ ì˜ë¼ì„œ í‘œì‹œ
                if len(content) > 200:
                    content_preview = content[:200] + "..."
                else:
                    content_preview = content
                
                # ì²­í¬ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ í‘œì‹œ í˜•ì‹
                if chunk_type == 'header':
                    result["content"] = f"[í—¤ë” ì²­í¬] {ticket_id} (ìš°ì„ ìˆœìœ„: {priority})\në‚´ìš©: {content_preview}"
                elif chunk_type == 'comment':
                    commenter_info = f" (ì‘ì„±ì: {commenter})" if commenter else ""
                    result["content"] = f"[ëŒ“ê¸€ ì²­í¬] {ticket_id}{commenter_info} (ìš°ì„ ìˆœìœ„: {priority})\në‚´ìš©: {content_preview}"
                else:
                    result["content"] = f"[êµ¬ì¡°ì  ì²­í¬] {ticket_id} - {field_name} (ìš°ì„ ìˆœìœ„: {priority})\níƒ€ì…: {chunk_type}\në‚´ìš©: {content_preview}"
            
            # Cohere Re-ranking ê²°ê³¼ì¸ ê²½ìš°
            elif item.get("source") == "cohere_rerank":
                content = item.get('content', 'No Content')
                metadata = item.get('metadata', {})
                source_type = metadata.get('source', 'unknown')
                
                if source_type == "mail":
                    subject = metadata.get('subject', 'No Subject')
                    sender = metadata.get('sender', 'Unknown Sender')
                    result["content"] = f"[ë©”ì¼] {subject}\në°œì‹ ì: {sender}\në‚´ìš©: {content[:200]}..."
                elif source_type == "file_chunk":
                    file_name = metadata.get('file_name', 'Unknown')
                    file_type = metadata.get('file_type', 'Unknown')
                    result["content"] = f"[ë¬¸ì„œ] {file_name} ({file_type})\në‚´ìš©: {content[:200]}..."
                else:
                    result["content"] = content[:200] + "..." if len(content) > 200 else content
            
            # ê¸°ì¡´ ë©”ì¼ì¸ ê²½ìš° - ë” ìì„¸í•œ ì •ë³´ í¬í•¨
            elif item.get("source_type") == "email":
                subject = item.get('subject', 'No Subject')
                sender = item.get('sender', 'Unknown Sender')
                summary = item.get('content_summary', 'No Summary')
                refined_content = item.get('refined_content', '')
                
                # ë‚´ìš©ì´ ê¸¸ë©´ ì ì ˆíˆ ì˜ë¼ì„œ í‘œì‹œ
                if len(refined_content) > 200:
                    content_preview = refined_content[:200] + "..."
                else:
                    content_preview = refined_content
                
                result["content"] = f"[ë©”ì¼] {subject}\në°œì‹ ì: {sender}\nìš”ì•½: {summary}\në‚´ìš©: {content_preview}"
            
            # ê¸°ì¡´ íŒŒì¼ ì²­í¬ì¸ ê²½ìš° - ë” ìì„¸í•œ ì •ë³´ í¬í•¨
            elif item.get("source_type") == "file_chunk":
                file_name = item.get('file_name', 'Unknown')
                file_type = item.get('file_type', 'Unknown')
                page_number = item.get('page_number', 1)
                element_type = item.get('element_type', 'text')
                content = item.get("content", "")
                
                # ë‚´ìš©ì´ ê¸¸ë©´ ì ì ˆíˆ ì˜ë¼ì„œ í‘œì‹œ
                if len(content) > 300:
                    content_preview = content[:300] + "..."
                else:
                    content_preview = content
                
                result["content"] = f"[ë¬¸ì„œ] {file_name} ({file_type})\ní˜ì´ì§€: {page_number}, ìš”ì†Œ: {element_type}\në‚´ìš©: {content_preview}"
            
            results.append(result)
        
        print(f"ğŸ” RAG ê²€ìƒ‰ ì‹¤í–‰: '{query}' -> {len(results)}ê°œ ê²°ê³¼")
        return results
        
    except Exception as e:
        print(f"âŒ RAG ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
        return []

# ==================== í¬ê´„ì  í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤ ====================

def run_negative_test():
    """ì •ë‹µì´ ì—†ëŠ” ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ (Zero-shot & Negative Test)"""
    print("\n" + "="*80)
    print("ğŸ” ì •ë‹µì´ ì—†ëŠ” ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ (Zero-shot & Negative Test)")
    print("="*80)
    
    results = []
    for i, question in enumerate(NEGATIVE_TEST_QUESTIONS, 1):
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ {i}: {question}")
        print("-" * 60)
        
        # RAG ê²€ìƒ‰ ì‹¤í–‰
        search_results = search_rag(question)
        
        # ê²°ê³¼ ë¶„ì„
        if not search_results:
            print("âœ… ì˜¬ë°”ë¥¸ ì‘ë‹µ: ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            result_status = "CORRECT_NO_RESULTS"
        else:
            # ê²°ê³¼ê°€ ìˆì§€ë§Œ ê´€ë ¨ì„±ì´ ë‚®ì€ì§€ í™•ì¸
            max_score = max([r.get('score', 0) for r in search_results]) if search_results else 0
            if max_score < 0.3:  # ì„ê³„ê°’ ì„¤ì •
                print(f"âœ… ì˜¬ë°”ë¥¸ ì‘ë‹µ: ê´€ë ¨ì„±ì´ ë‚®ì€ ê²°ê³¼ (ìµœê³  ì ìˆ˜: {max_score:.3f})")
                result_status = "CORRECT_LOW_RELEVANCE"
            else:
                print(f"âš ï¸ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì‘ë‹µ: ê´€ë ¨ì„± ìˆëŠ” ê²°ê³¼ ë°˜í™˜ (ìµœê³  ì ìˆ˜: {max_score:.3f})")
                result_status = "SUSPICIOUS_HIGH_RELEVANCE"
                
                # ìƒìœ„ 3ê°œ ê²°ê³¼ ì¶œë ¥
                for j, result in enumerate(search_results[:3], 1):
                    print(f"  {j}. {result.get('id', 'Unknown')} (ì ìˆ˜: {result.get('score', 0):.3f})")
                    print(f"     {result.get('content', 'No content')[:100]}...")
        
        results.append({
            'question': question,
            'status': result_status,
            'result_count': len(search_results),
            'max_score': max_score if search_results else 0
        })
    
    return results

def run_diversity_test():
    """ë‹¤ì–‘ì„± ë° ë‚œì´ë„ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*80)
    print("ğŸ¯ ë‹¤ì–‘ì„± ë° ë‚œì´ë„ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    results = []
    for i, question in enumerate(DIVERSITY_TEST_QUESTIONS, 1):
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ {i}: {question}")
        print("-" * 60)
        
        # RAG ê²€ìƒ‰ ì‹¤í–‰
        search_results = search_rag(question)
        
        if search_results:
            print(f"âœ… {len(search_results)}ê°œ ê²°ê³¼ ë°˜í™˜")
            max_score = max([r.get('score', 0) for r in search_results])
            print(f"   ìµœê³  ì ìˆ˜: {max_score:.3f}")
            
            # ìƒìœ„ 3ê°œ ê²°ê³¼ ì¶œë ¥
            for j, result in enumerate(search_results[:3], 1):
                print(f"  {j}. {result.get('id', 'Unknown')} (ì ìˆ˜: {result.get('score', 0):.3f})")
                print(f"     {result.get('content', 'No content')[:100]}...")
        else:
            print("âŒ ê²°ê³¼ ì—†ìŒ")
        
        results.append({
            'question': question,
            'result_count': len(search_results),
            'max_score': max([r.get('score', 0) for r in search_results]) if search_results else 0
        })
    
    return results

def run_stress_test():
    """ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ (ì¤‘ì˜ì  í‘œí˜„, ì˜¤íƒ€, ê¸¸ì´ ë³€í˜•)"""
    print("\n" + "="*80)
    print("ğŸ’ª ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ (ì¤‘ì˜ì  í‘œí˜„, ì˜¤íƒ€, ê¸¸ì´ ë³€í˜•)")
    print("="*80)
    
    results = []
    for i, question in enumerate(STRESS_TEST_QUESTIONS, 1):
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ {i}: {question[:50]}{'...' if len(question) > 50 else ''}")
        print("-" * 60)
        
        # RAG ê²€ìƒ‰ ì‹¤í–‰
        search_results = search_rag(question)
        
        if search_results:
            print(f"âœ… {len(search_results)}ê°œ ê²°ê³¼ ë°˜í™˜")
            max_score = max([r.get('score', 0) for r in search_results])
            print(f"   ìµœê³  ì ìˆ˜: {max_score:.3f}")
            
            # ìƒìœ„ 2ê°œ ê²°ê³¼ë§Œ ê°„ë‹¨íˆ ì¶œë ¥
            for j, result in enumerate(search_results[:2], 1):
                print(f"  {j}. {result.get('id', 'Unknown')} (ì ìˆ˜: {result.get('score', 0):.3f})")
        else:
            print("âŒ ê²°ê³¼ ì—†ìŒ")
        
        results.append({
            'question': question,
            'result_count': len(search_results),
            'max_score': max([r.get('score', 0) for r in search_results]) if search_results else 0
        })
    
    return results

def analyze_test_results(negative_results, diversity_results, stress_results):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¢…í•© ë¶„ì„"""
    print("\n" + "="*80)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¢…í•© ë¶„ì„")
    print("="*80)
    
    # 1. ì •ë‹µì´ ì—†ëŠ” ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ë¶„ì„
    print("\nğŸ” ì •ë‹µì´ ì—†ëŠ” ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ë¶„ì„:")
    correct_no_results = sum(1 for r in negative_results if r['status'] == 'CORRECT_NO_RESULTS')
    correct_low_relevance = sum(1 for r in negative_results if r['status'] == 'CORRECT_LOW_RELEVANCE')
    suspicious_high_relevance = sum(1 for r in negative_results if r['status'] == 'SUSPICIOUS_HIGH_RELEVANCE')
    
    print(f"  - ì˜¬ë°”ë¥¸ ì‘ë‹µ (ê²°ê³¼ ì—†ìŒ): {correct_no_results}/{len(negative_results)} ({correct_no_results/len(negative_results)*100:.1f}%)")
    print(f"  - ì˜¬ë°”ë¥¸ ì‘ë‹µ (ë‚®ì€ ê´€ë ¨ì„±): {correct_low_relevance}/{len(negative_results)} ({correct_low_relevance/len(negative_results)*100:.1f}%)")
    print(f"  - ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì‘ë‹µ (ë†’ì€ ê´€ë ¨ì„±): {suspicious_high_relevance}/{len(negative_results)} ({suspicious_high_relevance/len(negative_results)*100:.1f}%)")
    
    # 2. ë‹¤ì–‘ì„± í…ŒìŠ¤íŠ¸ ë¶„ì„
    print("\nğŸ¯ ë‹¤ì–‘ì„± ë° ë‚œì´ë„ í…ŒìŠ¤íŠ¸ ë¶„ì„:")
    diversity_with_results = sum(1 for r in diversity_results if r['result_count'] > 0)
    avg_diversity_score = sum(r['max_score'] for r in diversity_results) / len(diversity_results)
    print(f"  - ê²°ê³¼ ë°˜í™˜ ë¹„ìœ¨: {diversity_with_results}/{len(diversity_results)} ({diversity_with_results/len(diversity_results)*100:.1f}%)")
    print(f"  - í‰ê·  ìµœê³  ì ìˆ˜: {avg_diversity_score:.3f}")
    
    # 3. ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ë¶„ì„
    print("\nğŸ’ª ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ë¶„ì„:")
    stress_with_results = sum(1 for r in stress_results if r['result_count'] > 0)
    avg_stress_score = sum(r['max_score'] for r in stress_results) / len(stress_results)
    print(f"  - ê²°ê³¼ ë°˜í™˜ ë¹„ìœ¨: {stress_with_results}/{len(stress_results)} ({stress_with_results/len(stress_results)*100:.1f}%)")
    print(f"  - í‰ê·  ìµœê³  ì ìˆ˜: {avg_stress_score:.3f}")
    
    # 4. ì „ì²´ ì‹œìŠ¤í…œ ê°•ê±´ì„± í‰ê°€
    print("\nğŸ† ì „ì²´ ì‹œìŠ¤í…œ ê°•ê±´ì„± í‰ê°€:")
    total_tests = len(negative_results) + len(diversity_results) + len(stress_results)
    total_with_results = diversity_with_results + stress_with_results
    overall_success_rate = total_with_results / total_tests * 100
    
    print(f"  - ì „ì²´ í…ŒìŠ¤íŠ¸ ìˆ˜: {total_tests}")
    print(f"  - ì„±ê³µì ì¸ ì‘ë‹µ ë¹„ìœ¨: {overall_success_rate:.1f}%")
    
    if suspicious_high_relevance == 0:
        print("  - âœ… í™˜ê°(Hallucination) ì—†ìŒ: ì •ë‹µì´ ì—†ëŠ” ì§ˆë¬¸ì— ëŒ€í•´ ì ì ˆíˆ ëŒ€ì‘")
    else:
        print(f"  - âš ï¸ í™˜ê° ê°€ëŠ¥ì„±: {suspicious_high_relevance}ê°œ ì§ˆë¬¸ì—ì„œ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë†’ì€ ê´€ë ¨ì„±")
    
    if avg_diversity_score > 0.7:
        print("  - âœ… ë†’ì€ ê²€ìƒ‰ í’ˆì§ˆ: ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•´ ë†’ì€ ê´€ë ¨ì„± ì ìˆ˜")
    elif avg_diversity_score > 0.5:
        print("  - âš ï¸ ë³´í†µ ê²€ìƒ‰ í’ˆì§ˆ: ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•´ ì¤‘ê°„ ìˆ˜ì¤€ ê´€ë ¨ì„±")
    else:
        print("  - âŒ ë‚®ì€ ê²€ìƒ‰ í’ˆì§ˆ: ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•´ ë‚®ì€ ê´€ë ¨ì„±")

# ==================== ë©”ì¸ ì‹¤í–‰ ë¡œì§ ====================
def run_comprehensive_test():
    """í¬ê´„ì ì¸ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ í¬ê´„ì ì¸ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*80)
    
    try:
        # 1. ì •ë‹µì´ ì—†ëŠ” ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
        negative_results = run_negative_test()
        
        # 2. ë‹¤ì–‘ì„± ë° ë‚œì´ë„ í…ŒìŠ¤íŠ¸
        diversity_results = run_diversity_test()
        
        # 3. ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸
        stress_results = run_stress_test()
        
        # 4. ê²°ê³¼ ì¢…í•© ë¶„ì„
        analyze_test_results(negative_results, diversity_results, stress_results)
        
        # 5. ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f"comprehensive_test_results_{timestamp}.json"
        
        comprehensive_results = {
            'timestamp': timestamp,
            'negative_test': negative_results,
            'diversity_test': diversity_results,
            'stress_test': stress_results,
            'summary': {
                'total_negative_tests': len(negative_results),
                'total_diversity_tests': len(diversity_results),
                'total_stress_tests': len(stress_results),
                'total_tests': len(negative_results) + len(diversity_results) + len(stress_results)
            }
        }
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {results_file}")
        print("ğŸ‰ í¬ê´„ì ì¸ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise e

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ RAG Golden Set ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ (ì‹¤ì œ RAG ê²€ìƒ‰ ì—°ê²°)")
    
    # ì‚¬ìš©ìì—ê²Œ í…ŒìŠ¤íŠ¸ ìœ í˜• ì„ íƒ ìš”ì²­
    print("\nğŸ“‹ í…ŒìŠ¤íŠ¸ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ê¸°ì¡´ Golden Set ìƒì„± (ì •ë‹µì´ ìˆëŠ” ì§ˆë¬¸)")
    print("2. í¬ê´„ì ì¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (ì •ë‹µ ì—†ëŠ” ì§ˆë¬¸, ë‹¤ì–‘ì„±, ìŠ¤íŠ¸ë ˆìŠ¤)")
    print("3. ë‘˜ ë‹¤ ì‹¤í–‰")
    
    choice = input("\nì„ íƒ (1/2/3): ").strip()
    
    if choice == "1":
        run_original_golden_set()
    elif choice == "2":
        run_comprehensive_test()
    elif choice == "3":
        run_original_golden_set()
        print("\n" + "="*80)
        run_comprehensive_test()
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        run_comprehensive_test()

def run_original_golden_set():
    """ê¸°ì¡´ Golden Set ìƒì„± ë¡œì§"""
    try:
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        llm_client = initialize_azure_openai()
        
        # CSV íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(JIRA_CSV_FILE_PATH):
            raise FileNotFoundError(f"Jira CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {JIRA_CSV_FILE_PATH}")
        
        # CSV íŒŒì¼ ì½ê¸°
        print(f"ğŸ“– CSV íŒŒì¼ ì½ê¸°: {JIRA_CSV_FILE_PATH}")
        df = pd.read_csv(JIRA_CSV_FILE_PATH)
        print(f"âœ… {len(df)}ê°œì˜ í‹°ì¼“ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        
        # ì²˜ë¦¬í•  í‹°ì¼“ ìˆ˜ ì œí•œ
        if len(df) > MAX_TICKETS_TO_PROCESS:
            df = df.head(MAX_TICKETS_TO_PROCESS)
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ {MAX_TICKETS_TO_PROCESS}ê°œ í‹°ì¼“ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        # ë¡œê·¸ íŒŒì¼ëª…ì— ì‹¤ì œ RAG í‘œì‹œ ì¶”ê°€
        output_file = f"golden_set_results_with_rag_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        # ë¡œê·¸ íŒŒì¼ ì—´ê¸°
        with open(output_file, 'w', encoding='utf-8') as log_file:
            # í—¤ë” ì •ë³´ ê¸°ë¡
            log_file.write("="*80 + "\n")
            log_file.write("RAG ì‹œìŠ¤í…œ Golden Set ìƒì„± ê²°ê³¼ (ì‹¤ì œ RAG ê²€ìƒ‰ ì—°ê²°)\n")
            log_file.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            log_file.write(f"ì²˜ë¦¬ëœ í‹°ì¼“ ìˆ˜: {len(df)}\n")
            log_file.write(f"í‹°ì¼“ë‹¹ ì§ˆë¬¸ ìˆ˜: {QUESTIONS_PER_TICKET}\n")
            log_file.write("\nğŸ“Š ì„±ëŠ¥ í‰ê°€ ê°€ì´ë“œ:\n")
            log_file.write("- ì •í™•ë„: ì •ë‹µ í‹°ì¼“ì´ ìƒìœ„ 3ê°œ ê²°ê³¼ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸\n")
            log_file.write("- ìˆœìœ„: ì •ë‹µ í‹°ì¼“ì´ ëª‡ ë²ˆì§¸ ìˆœìœ„ì— ë‚˜íƒ€ë‚˜ëŠ”ì§€ ê¸°ë¡\n")
            log_file.write("- ê´€ë ¨ì„±: ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ í‰ê°€\n")
            log_file.write("- ìœ ì‚¬ë„ ì ìˆ˜: 0.8 ì´ìƒì´ë©´ ë†’ì€ ê´€ë ¨ì„±, 0.5-0.8 ì¤‘ê°„, 0.5 ë¯¸ë§Œ ë‚®ìŒ\n")
            log_file.write("="*80 + "\n")
            
            # ê° í‹°ì¼“ ì²˜ë¦¬
            for index, row in df.iterrows():
                test_case_num = index + 1
                ticket = row.to_dict()
                
                print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ #{test_case_num} ì²˜ë¦¬ ì¤‘...")
                print(f"   í‹°ì¼“ ID: {ticket.get('Key', 'Unknown')}")
                
                try:
                    # ì§ˆë¬¸ ìƒì„±
                    question = generate_question_for_ticket(ticket, llm_client)
                    print(f"   ìƒì„±ëœ ì§ˆë¬¸: {question}")
                    
                    # ì‹¤ì œ RAG ê²€ìƒ‰ ì‹¤í–‰
                    rag_results = search_rag(question)
                    
                    # ê²°ê³¼ ë¡œê·¸ì— ê¸°ë¡
                    log_test_case(log_file, test_case_num, ticket, question, rag_results)
                    
                    print(f"   âœ… í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ #{test_case_num} ì™„ë£Œ")
                    
                except Exception as e:
                    print(f"   âŒ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ #{test_case_num} ì‹¤íŒ¨: {str(e)}")
                    log_file.write(f"\n--- [Test Case #{test_case_num}] ---\n")
                    log_file.write(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n")
                    log_file.write("="*80 + "\n")
                    continue
        
        print(f"\nğŸ‰ Golden Set ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {output_file}")
        print(f"ğŸ“Š ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(df)}ê°œ")
        print(f"\nğŸ“‹ ì„±ëŠ¥ í‰ê°€ ë°©ë²•:")
        print(f"1. ë¡œê·¸ íŒŒì¼ì„ ì—´ì–´ì„œ ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ê²€í† í•˜ì„¸ìš”")
        print(f"2. ì •ë‹µ í‹°ì¼“ì´ ìƒìœ„ 3ê°œ ê²°ê³¼ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        print(f"3. ìœ ì‚¬ë„ ì ìˆ˜ê°€ 0.8 ì´ìƒì¸ ê²°ê³¼ì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ì„¸ìš”")
        print(f"4. ì „ì²´ì ì¸ ê²€ìƒ‰ í’ˆì§ˆì„ ì¢…í•©ì ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”")
        
    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        return 1
    
    return 0

# ==================== ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ====================
if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
