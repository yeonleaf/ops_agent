#!/usr/bin/env python3
"""
RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•œ Golden Set ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (ì‹¤ì œ RAG ê²€ìƒ‰ ì—°ê²°)
ê¸°ì¡´ generate_golden_set.pyë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ RAG ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ ì—°ê²°í•œ ë²„ì „ì…ë‹ˆë‹¤.
"""

import os
import sys
import pandas as pd
import json
from datetime import datetime
from typing import Dict, List, Any
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from generate_golden_set import (
    initialize_azure_openai, 
    generate_question_for_ticket, 
    log_test_case,
    JIRA_CSV_FILE_PATH,
    OUTPUT_LOG_FILE,
    QUESTIONS_PER_TICKET,
    MAX_TICKETS_TO_PROCESS
)

# RAG ê´€ë ¨ ëª¨ë“ˆë“¤ import
from vector_db_models import VectorDBManager
from ticket_ai_recommender import TicketAIRecommender

# ==================== ì‹¤ì œ RAG ê²€ìƒ‰ í•¨ìˆ˜ ====================
def search_rag(query: str) -> List[Dict[str, Any]]:
    """
    ì‹¤ì œ RAG ì‹œìŠ¤í…œì—ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
    
    Returns:
        List[Dict]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (id, content, score í¬í•¨)
    """
    try:
        # VectorDBManager ì´ˆê¸°í™”
        vector_db = VectorDBManager()
        
        # í†µí•© ê²€ìƒ‰ ì‹¤í–‰ (ë©”ì¼ + íŒŒì¼ ì²­í¬)
        recommender = TicketAIRecommender()
        similar_content = recommender.get_integrated_similar_content(
            query, 
            email_limit=2, 
            chunk_limit=1
        )
        
        # ê²°ê³¼ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        results = []
        for i, item in enumerate(similar_content):
            # Retrieve then Re-rank ê²°ê³¼ì¸ ê²½ìš° rerank_score ì‚¬ìš©, ê·¸ ì™¸ì—ëŠ” similarity_score ì‚¬ìš©
            if item.get("source") == "retrieve_rerank_whoosh":
                metadata = item.get('metadata', {})
                score = metadata.get('rerank_score', item.get('similarity_score', 0.0))
            else:
                score = item.get('similarity_score', 0.0)
            
            result = {
                "id": item.get("message_id", item.get("chunk_id", f"ITEM-{i}")),
                "content": "",
                "score": score
            }
            
            # Retrieve then Re-rank ê²€ìƒ‰ ê²°ê³¼ì¸ ê²½ìš° (Vector + Whoosh + CohereRerank)
            if item.get("source") == "retrieve_rerank_whoosh":
                content = item.get('content', 'No Content')
                metadata = item.get('metadata', {})
                source_type = metadata.get('source_type', 'unknown')
                extracted_keywords = item.get('extracted_keywords', [])
                
                # ë‚´ìš©ì´ ê¸¸ë©´ ì ì ˆíˆ ì˜ë¼ì„œ í‘œì‹œ
                if len(content) > 200:
                    content_preview = content[:200] + "..."
                else:
                    content_preview = content
                
                # ì¶”ì¶œëœ í‚¤ì›Œë“œ ì •ë³´ ì¶”ê°€
                keyword_info = f" (í‚¤ì›Œë“œ: {', '.join(extracted_keywords)})" if extracted_keywords else ""
                
                # Retrieve then Re-rank ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                result["content"] = f"[Retrieve then Re-rank Whoosh] {source_type}{keyword_info}\në‚´ìš©: {content_preview}"
            
            # QueryExpansion ê²°ê³¼ì¸ ê²½ìš° (file_chunk, mail ë“±)
            elif item.get("source") in ["file_chunk", "mail", "structured_chunk"]:
                content = item.get('content', 'No Content')
                metadata = item.get('metadata', {})
                source = item.get('source', 'unknown')
                
                # ë‚´ìš©ì´ ê¸¸ë©´ ì ì ˆíˆ ì˜ë¼ì„œ í‘œì‹œ
                if len(content) > 200:
                    content_preview = content[:200] + "..."
                else:
                    content_preview = content
                
                # ì†ŒìŠ¤ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ í‘œì‹œ í˜•ì‹
                if source == "file_chunk":
                    file_name = metadata.get('file_name', 'Unknown File')
                    result["content"] = f"[íŒŒì¼ ì²­í¬] {file_name}\në‚´ìš©: {content_preview}"
                elif source == "mail":
                    subject = metadata.get('subject', 'No Subject')
                    sender = metadata.get('sender', 'Unknown Sender')
                    result["content"] = f"[ë©”ì¼] {subject}\në°œì‹ ì: {sender}\në‚´ìš©: {content_preview}"
                elif source == "structured_chunk":
                    ticket_id = metadata.get('ticket_id', 'Unknown')
                    chunk_type = metadata.get('chunk_type', 'unknown')
                    field_name = metadata.get('field_name', 'unknown')
                    priority = metadata.get('priority', 3)
                    commenter = metadata.get('commenter', '')
                    
                    # ì²­í¬ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ í‘œì‹œ í˜•ì‹
                    if chunk_type == 'header':
                        result["content"] = f"[í—¤ë” ì²­í¬] {ticket_id} (ìš°ì„ ìˆœìœ„: {priority})\në‚´ìš©: {content_preview}"
                    elif chunk_type == 'comment':
                        commenter_info = f" (ì‘ì„±ì: {commenter})" if commenter else ""
                        result["content"] = f"[ëŒ“ê¸€ ì²­í¬] {ticket_id}{commenter_info} (ìš°ì„ ìˆœìœ„: {priority})\në‚´ìš©: {content_preview}"
                    else:
                        result["content"] = f"[êµ¬ì¡°ì  ì²­í¬] {ticket_id} - {field_name} (ìš°ì„ ìˆœìœ„: {priority})\níƒ€ì…: {chunk_type}\në‚´ìš©: {content_preview}"
                else:
                    # ê¸°íƒ€ ì†ŒìŠ¤ íƒ€ì…
                    result["content"] = f"[{source}] {content_preview}"
            
            # êµ¬ì¡°ì  ì²­í‚¹ ê²°ê³¼ì¸ ê²½ìš° (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
            elif item.get("source") == "structured_chunk":
                content = item.get('content', 'No Content')
                metadata = item.get('metadata', {})
                ticket_id = metadata.get('ticket_id', 'Unknown')
                chunk_type = metadata.get('chunk_type', 'unknown')
                field_name = metadata.get('field_name', 'unknown')
                priority = metadata.get('priority', 3)
                commenter = metadata.get('commenter', '')
                
                # ë‚´ìš©ì´ ê¸¸ë©´ ì ì ˆíˆ ì˜ë¼ì„œ í‘œì‹œ
                if len(content) > 200:
                    content_preview = content[:200] + "..."
                else:
                    content_preview = content
                
                # ì²­í¬ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ í‘œì‹œ í˜•ì‹
                if chunk_type == 'header':
                    result["content"] = f"[í—¤ë” ì²­í¬] {ticket_id} (ìš°ì„ ìˆœìœ„: {priority})\në‚´ìš©: {content_preview}"
                elif chunk_type == 'comment':
                    commenter_info = f" (ì‘ì„±ì: {commenter})" if commenter else ""
                    result["content"] = f"[ëŒ“ê¸€ ì²­í¬] {ticket_id}{commenter_info} (ìš°ì„ ìˆœìœ„: {priority})\në‚´ìš©: {content_preview}"
                else:
                    result["content"] = f"[êµ¬ì¡°ì  ì²­í¬] {ticket_id} - {field_name} (ìš°ì„ ìˆœìœ„: {priority})\níƒ€ì…: {chunk_type}\në‚´ìš©: {content_preview}"
            
            # Cohere Re-ranking ê²°ê³¼ì¸ ê²½ìš°
            elif item.get("source") == "cohere_rerank":
                content = item.get('content', 'No Content')
                metadata = item.get('metadata', {})
                source_type = metadata.get('source', 'unknown')
                
                if source_type == "mail":
                    subject = metadata.get('subject', 'No Subject')
                    sender = metadata.get('sender', 'Unknown Sender')
                    result["content"] = f"[ë©”ì¼] {subject}\në°œì‹ ì: {sender}\në‚´ìš©: {content[:200]}..."
                elif source_type == "file_chunk":
                    file_name = metadata.get('file_name', 'Unknown')
                    file_type = metadata.get('file_type', 'Unknown')
                    result["content"] = f"[ë¬¸ì„œ] {file_name} ({file_type})\në‚´ìš©: {content[:200]}..."
                else:
                    result["content"] = content[:200] + "..." if len(content) > 200 else content
            
            # ê¸°ì¡´ ë©”ì¼ì¸ ê²½ìš° - ë” ìì„¸í•œ ì •ë³´ í¬í•¨
            elif item.get("source_type") == "email":
                subject = item.get('subject', 'No Subject')
                sender = item.get('sender', 'Unknown Sender')
                summary = item.get('content_summary', 'No Summary')
                refined_content = item.get('refined_content', '')
                
                # ë‚´ìš©ì´ ê¸¸ë©´ ì ì ˆíˆ ì˜ë¼ì„œ í‘œì‹œ
                if len(refined_content) > 200:
                    content_preview = refined_content[:200] + "..."
                else:
                    content_preview = refined_content
                
                result["content"] = f"[ë©”ì¼] {subject}\në°œì‹ ì: {sender}\nìš”ì•½: {summary}\në‚´ìš©: {content_preview}"
            
            # ê¸°ì¡´ íŒŒì¼ ì²­í¬ì¸ ê²½ìš° - ë” ìì„¸í•œ ì •ë³´ í¬í•¨
            elif item.get("source_type") == "file_chunk":
                file_name = item.get('file_name', 'Unknown')
                file_type = item.get('file_type', 'Unknown')
                page_number = item.get('page_number', 1)
                element_type = item.get('element_type', 'text')
                content = item.get("content", "")
                
                # ë‚´ìš©ì´ ê¸¸ë©´ ì ì ˆíˆ ì˜ë¼ì„œ í‘œì‹œ
                if len(content) > 300:
                    content_preview = content[:300] + "..."
                else:
                    content_preview = content
                
                result["content"] = f"[ë¬¸ì„œ] {file_name} ({file_type})\ní˜ì´ì§€: {page_number}, ìš”ì†Œ: {element_type}\në‚´ìš©: {content_preview}"
            
            results.append(result)
        
        print(f"ğŸ” RAG ê²€ìƒ‰ ì‹¤í–‰: '{query}' -> {len(results)}ê°œ ê²°ê³¼")
        return results
        
    except Exception as e:
        print(f"âŒ RAG ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
        return []

# ==================== ë©”ì¸ ì‹¤í–‰ ë¡œì§ ====================
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ RAG Golden Set ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ (ì‹¤ì œ RAG ê²€ìƒ‰ ì—°ê²°)")
    
    try:
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        llm_client = initialize_azure_openai()
        
        # CSV íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(JIRA_CSV_FILE_PATH):
            raise FileNotFoundError(f"Jira CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {JIRA_CSV_FILE_PATH}")
        
        # CSV íŒŒì¼ ì½ê¸°
        print(f"ğŸ“– CSV íŒŒì¼ ì½ê¸°: {JIRA_CSV_FILE_PATH}")
        df = pd.read_csv(JIRA_CSV_FILE_PATH)
        print(f"âœ… {len(df)}ê°œì˜ í‹°ì¼“ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        
        # ì²˜ë¦¬í•  í‹°ì¼“ ìˆ˜ ì œí•œ
        if len(df) > MAX_TICKETS_TO_PROCESS:
            df = df.head(MAX_TICKETS_TO_PROCESS)
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ {MAX_TICKETS_TO_PROCESS}ê°œ í‹°ì¼“ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        # ë¡œê·¸ íŒŒì¼ëª…ì— ì‹¤ì œ RAG í‘œì‹œ ì¶”ê°€
        output_file = f"golden_set_results_with_rag_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        # ë¡œê·¸ íŒŒì¼ ì—´ê¸°
        with open(output_file, 'w', encoding='utf-8') as log_file:
            # í—¤ë” ì •ë³´ ê¸°ë¡
            log_file.write("="*80 + "\n")
            log_file.write("RAG ì‹œìŠ¤í…œ Golden Set ìƒì„± ê²°ê³¼ (ì‹¤ì œ RAG ê²€ìƒ‰ ì—°ê²°)\n")
            log_file.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            log_file.write(f"ì²˜ë¦¬ëœ í‹°ì¼“ ìˆ˜: {len(df)}\n")
            log_file.write(f"í‹°ì¼“ë‹¹ ì§ˆë¬¸ ìˆ˜: {QUESTIONS_PER_TICKET}\n")
            log_file.write("\nğŸ“Š ì„±ëŠ¥ í‰ê°€ ê°€ì´ë“œ:\n")
            log_file.write("- ì •í™•ë„: ì •ë‹µ í‹°ì¼“ì´ ìƒìœ„ 3ê°œ ê²°ê³¼ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸\n")
            log_file.write("- ìˆœìœ„: ì •ë‹µ í‹°ì¼“ì´ ëª‡ ë²ˆì§¸ ìˆœìœ„ì— ë‚˜íƒ€ë‚˜ëŠ”ì§€ ê¸°ë¡\n")
            log_file.write("- ê´€ë ¨ì„±: ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ í‰ê°€\n")
            log_file.write("- ìœ ì‚¬ë„ ì ìˆ˜: 0.8 ì´ìƒì´ë©´ ë†’ì€ ê´€ë ¨ì„±, 0.5-0.8 ì¤‘ê°„, 0.5 ë¯¸ë§Œ ë‚®ìŒ\n")
            log_file.write("="*80 + "\n")
            
            # ê° í‹°ì¼“ ì²˜ë¦¬
            for index, row in df.iterrows():
                test_case_num = index + 1
                ticket = row.to_dict()
                
                print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ #{test_case_num} ì²˜ë¦¬ ì¤‘...")
                print(f"   í‹°ì¼“ ID: {ticket.get('Key', 'Unknown')}")
                
                try:
                    # ì§ˆë¬¸ ìƒì„±
                    question = generate_question_for_ticket(ticket, llm_client)
                    print(f"   ìƒì„±ëœ ì§ˆë¬¸: {question}")
                    
                    # ì‹¤ì œ RAG ê²€ìƒ‰ ì‹¤í–‰
                    rag_results = search_rag(question)
                    
                    # ê²°ê³¼ ë¡œê·¸ì— ê¸°ë¡
                    log_test_case(log_file, test_case_num, ticket, question, rag_results)
                    
                    print(f"   âœ… í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ #{test_case_num} ì™„ë£Œ")
                    
                except Exception as e:
                    print(f"   âŒ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ #{test_case_num} ì‹¤íŒ¨: {str(e)}")
                    log_file.write(f"\n--- [Test Case #{test_case_num}] ---\n")
                    log_file.write(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n")
                    log_file.write("="*80 + "\n")
                    continue
        
        print(f"\nğŸ‰ Golden Set ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {output_file}")
        print(f"ğŸ“Š ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(df)}ê°œ")
        print(f"\nğŸ“‹ ì„±ëŠ¥ í‰ê°€ ë°©ë²•:")
        print(f"1. ë¡œê·¸ íŒŒì¼ì„ ì—´ì–´ì„œ ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ê²€í† í•˜ì„¸ìš”")
        print(f"2. ì •ë‹µ í‹°ì¼“ì´ ìƒìœ„ 3ê°œ ê²°ê³¼ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        print(f"3. ìœ ì‚¬ë„ ì ìˆ˜ê°€ 0.8 ì´ìƒì¸ ê²°ê³¼ì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ì„¸ìš”")
        print(f"4. ì „ì²´ì ì¸ ê²€ìƒ‰ í’ˆì§ˆì„ ì¢…í•©ì ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”")
        
    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        return 1
    
    return 0

# ==================== ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ====================
if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
