#!/usr/bin/env python3
"""
í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ
BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•œ EnsembleRetriever êµ¬í˜„
"""

import logging
from typing import List, Dict, Any, Optional
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain_core.documents import Document
from vector_db_models import VectorDBManager
from text_preprocessor import preprocess_for_embedding
from keyword_extractor import KeywordExtractor
import os
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

class HybridSearchRetriever:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ
    BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ + ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•œ EnsembleRetriever
    """
    
    def __init__(self, vector_db_manager: VectorDBManager):
        self.vector_db_manager = vector_db_manager
        self.bm25_retriever = None
        self.ensemble_retriever = None
        self.documents = []
        self.keyword_extractor = KeywordExtractor()  # í‚¤ì›Œë“œ ì¶”ì¶œê¸° ì´ˆê¸°í™”
        
        # ë¬¸ì„œ ìˆ˜ì§‘ ë° ì¸ë±ìŠ¤ ìƒì„±
        self._collect_documents()
        self._setup_retrievers()
        
        logger.info("âœ… HybridSearchRetriever ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _collect_documents(self):
        """ëª¨ë“  ë¬¸ì„œë¥¼ ìˆ˜ì§‘í•˜ì—¬ BM25 ì¸ë±ìŠ¤ ìƒì„±ì„ ìœ„í•œ Document ê°ì²´ ìƒì„±"""
        try:
            logger.info("ğŸ“š ë¬¸ì„œ ìˆ˜ì§‘ ì‹œì‘...")
            
            # 1. íŒŒì¼ ì²­í¬ ë¬¸ì„œ ìˆ˜ì§‘
            file_chunks = self._get_file_chunks()
            self.documents.extend(file_chunks)
            
            # 2. ë©”ì¼ ë¬¸ì„œ ìˆ˜ì§‘
            mail_documents = self._get_mail_documents()
            self.documents.extend(mail_documents)
            
            # 3. êµ¬ì¡°ì  ì²­í¬ ë¬¸ì„œ ìˆ˜ì§‘
            structured_documents = self._get_structured_documents()
            self.documents.extend(structured_documents)
            
            logger.info(f"âœ… ì´ {len(self.documents)}ê°œ ë¬¸ì„œ ìˆ˜ì§‘ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            self.documents = []
    
    def _get_file_chunks(self) -> List[Document]:
        """íŒŒì¼ ì²­í¬ ë¬¸ì„œë“¤ì„ Document ê°ì²´ë¡œ ë³€í™˜"""
        documents = []
        try:
            logger.info("ğŸ“„ íŒŒì¼ ì²­í¬ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...")
            
            # VectorDBManagerì—ì„œ ëª¨ë“  íŒŒì¼ ì²­í¬ ê°€ì ¸ì˜¤ê¸°
            file_chunks = self.vector_db_manager.get_all_file_chunks()
            
            for chunk in file_chunks:
                content = chunk.get('content', '')
                if content and len(content.strip()) > 0:
                    metadata = chunk.get('metadata', {})
                    metadata.update({
                        'source_type': 'file_chunk',
                        'chunk_id': chunk.get('chunk_id', ''),
                        'file_name': chunk.get('file_name', '')
                    })
                    documents.append(Document(page_content=content, metadata=metadata))
            
            logger.info(f"âœ… íŒŒì¼ ì²­í¬ ë¬¸ì„œ {len(documents)}ê°œ ì²˜ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì²­í¬ ë¬¸ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return documents
    
    def _get_mail_documents(self) -> List[Document]:
        """ë©”ì¼ ë¬¸ì„œë“¤ì„ Document ê°ì²´ë¡œ ë³€í™˜"""
        documents = []
        try:
            logger.info("ğŸ“§ ë©”ì¼ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...")
            
            # VectorDBManagerì—ì„œ ëª¨ë“  ë©”ì¼ ê°€ì ¸ì˜¤ê¸°
            mails = self.vector_db_manager.get_all_mails()
            
            for mail in mails:
                content = mail.get('content', '')
                if content and len(content.strip()) > 0:
                    metadata = mail.get('metadata', {})
                    metadata.update({
                        'source_type': 'mail',
                        'message_id': mail.get('message_id', ''),
                        'subject': mail.get('subject', ''),
                        'sender': mail.get('sender', '')
                    })
                    documents.append(Document(page_content=content, metadata=metadata))
            
            logger.info(f"âœ… ë©”ì¼ ë¬¸ì„œ {len(documents)}ê°œ ì²˜ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ë©”ì¼ ë¬¸ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return documents
    
    def _get_structured_documents(self) -> List[Document]:
        """êµ¬ì¡°ì  ì²­í¬ ë¬¸ì„œë“¤ì„ Document ê°ì²´ë¡œ ë³€í™˜"""
        documents = []
        try:
            logger.info("ğŸ—ï¸ êµ¬ì¡°ì  ì²­í¬ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...")
            
            # VectorDBManagerì—ì„œ ëª¨ë“  êµ¬ì¡°ì  ì²­í¬ ê°€ì ¸ì˜¤ê¸°
            structured_chunks = self.vector_db_manager.get_all_structured_chunks()
            
            for chunk in structured_chunks:
                content = chunk.get('content', '')
                if content and len(content.strip()) > 0:
                    metadata = chunk.get('metadata', {})
                    metadata.update({
                        'source_type': 'structured_chunk',
                        'chunk_id': chunk.get('chunk_id', ''),
                        'ticket_id': chunk.get('ticket_id', ''),
                        'chunk_type': chunk.get('chunk_type', '')
                    })
                    documents.append(Document(page_content=content, metadata=metadata))
            
            logger.info(f"âœ… êµ¬ì¡°ì  ì²­í¬ ë¬¸ì„œ {len(documents)}ê°œ ì²˜ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"êµ¬ì¡°ì  ì²­í¬ ë¬¸ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return documents
    
    def _setup_retrievers(self):
        """BM25Retrieverì™€ EnsembleRetriever ì„¤ì •"""
        try:
            if not self.documents:
                logger.warning("âš ï¸ ìˆ˜ì§‘ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ BM25Retrieverë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                self.documents = [Document(page_content="", metadata={})]
            
            # 1. BM25Retriever ìƒì„±
            logger.info("ğŸ” BM25Retriever ìƒì„± ì¤‘...")
            self.bm25_retriever = BM25Retriever.from_documents(self.documents)
            self.bm25_retriever.k = 10  # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì„¤ì •
            logger.info("âœ… BM25Retriever ìƒì„± ì™„ë£Œ")
            
            # 2. Vector Retriever ìƒì„± (ê¸°ì¡´ VectorDBManager ê¸°ë°˜)
            logger.info("ğŸ” Vector Retriever ìƒì„± ì¤‘...")
            vector_retriever = self._create_vector_retriever()
            logger.info("âœ… Vector Retriever ìƒì„± ì™„ë£Œ")
            
            # 3. EnsembleRetriever ìƒì„±
            logger.info("ğŸ” EnsembleRetriever ìƒì„± ì¤‘...")
            self.ensemble_retriever = EnsembleRetriever(
                retrievers=[self.bm25_retriever, vector_retriever],
                weights=[0.2, 0.8]  # ì˜ë¯¸ ê²€ìƒ‰(Vector) ìµœìš°ì„ 
            )
            logger.info("âœ… EnsembleRetriever ìƒì„± ì™„ë£Œ (BM25: 0.2, Vector: 0.8)")
            
        except Exception as e:
            logger.error(f"âŒ Retriever ì„¤ì • ì‹¤íŒ¨: {e}")
            self.ensemble_retriever = None
    
    def _create_vector_retriever(self):
        """VectorDBManager ê¸°ë°˜ì˜ Vector Retriever ìƒì„±"""
        from langchain_core.retrievers import BaseRetriever
        
        class VectorDBRetriever(BaseRetriever):
            """VectorDBManagerë¥¼ ìœ„í•œ BaseRetriever êµ¬í˜„"""
            
            vector_db_manager: Any
            k: int
            
            def __init__(self, vector_db_manager, k: int = 10, **kwargs):
                super().__init__(
                    vector_db_manager=vector_db_manager,
                    k=k,
                    **kwargs
                )
            
            def _get_relevant_documents(self, query: str) -> List[Document]:
                """VectorDBManagerì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
                try:
                    # ì¿¼ë¦¬ ì „ì²˜ë¦¬
                    preprocessed_query = preprocess_for_embedding(query)
                    
                    # í†µí•© ê²€ìƒ‰ ìˆ˜í–‰
                    results = []
                    
                    # íŒŒì¼ ì²­í¬ ê²€ìƒ‰
                    file_results = self.vector_db_manager.search_similar_file_chunks(
                        preprocessed_query, n_results=self.k//3
                    )
                    for result in file_results:
                        if isinstance(result, dict):
                            content = result.get('content', '')
                            metadata = result.get('metadata', {})
                            metadata.update({
                                'source': 'file_chunk',
                                'similarity_score': result.get('similarity_score', 0.0)
                            })
                        else:
                            content = getattr(result, 'text_chunk', '')
                            metadata = {
                                'source': 'file_chunk',
                                'file_name': getattr(result, 'file_name', ''),
                                'similarity_score': getattr(result, 'similarity_score', 0.0)
                            }
                        
                        if content:
                            results.append(Document(page_content=content, metadata=metadata))
                    
                    # ë©”ì¼ ê²€ìƒ‰
                    mail_results = self.vector_db_manager.search_similar_mails(
                        preprocessed_query, n_results=self.k//3
                    )
                    for result in mail_results:
                        if isinstance(result, dict):
                            content = result.get('refined_content', '')
                            metadata = result.get('metadata', {})
                            metadata.update({
                                'source': 'mail',
                                'similarity_score': result.get('similarity_score', 0.0)
                            })
                        else:
                            content = getattr(result, 'refined_content', '')
                            metadata = {
                                'source': 'mail',
                                'subject': getattr(result, 'subject', ''),
                                'sender': getattr(result, 'sender', ''),
                                'similarity_score': getattr(result, 'similarity_score', 0.0)
                            }
                        
                        if content:
                            results.append(Document(page_content=content, metadata=metadata))
                    
                    # êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰
                    structured_results = self.vector_db_manager.search_structured_chunks(
                        preprocessed_query, n_results=self.k//3
                    )
                    for result in structured_results:
                        if isinstance(result, dict):
                            content = result.get('content', '')
                            metadata = result.get('metadata', {})
                            metadata.update({
                                'source': 'structured_chunk',
                                'similarity_score': result.get('similarity_score', 0.0)
                            })
                        else:
                            content = getattr(result, 'content', '')
                            metadata = {
                                'source': 'structured_chunk',
                                'ticket_id': getattr(result, 'ticket_id', ''),
                                'chunk_type': getattr(result, 'chunk_type', ''),
                                'similarity_score': getattr(result, 'similarity_score', 0.0)
                            }
                        
                        if content:
                            results.append(Document(page_content=content, metadata=metadata))
                    
                    return results[:self.k]
                    
                except Exception as e:
                    logger.error(f"Vector ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    return []
        
        return VectorDBRetriever(self.vector_db_manager, k=10)
    
    def _perform_separated_search(self, vector_query: str, bm25_query: str) -> List[Document]:
        """
        ê°œì„ ëœ ë¶„ë¦¬ëœ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        ë²¡í„° ê²€ìƒ‰ì€ ì›ë³¸ ì¿¼ë¦¬ë¡œ, BM25 ê²€ìƒ‰ì€ ì¶”ì¶œëœ í‚¤ì›Œë“œë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        try:
            # 1. ë²¡í„° ê²€ìƒ‰ (ì›ë³¸ ì¿¼ë¦¬)
            vector_retriever = self._create_vector_retriever()
            vector_docs = vector_retriever.get_relevant_documents(vector_query)
            
            # 2. BM25 ê²€ìƒ‰ (ì¶”ì¶œëœ í‚¤ì›Œë“œ)
            bm25_docs = self.bm25_retriever.get_relevant_documents(bm25_query)
            
            # 3. ê°œì„ ëœ ê²°ê³¼ í†µí•© ë° ì ìˆ˜ ì •ê·œí™”
            combined_docs = []
            
            # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
            vector_results = []
            for i, doc in enumerate(vector_docs):
                # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì— ì •ê·œí™”ëœ ì ìˆ˜ ë¶€ì—¬
                vector_score = doc.metadata.get('similarity_score', 0.0)
                normalized_vector_score = min(vector_score * 0.8, 0.8)  # ìµœëŒ€ 0.8ë¡œ ì œí•œ
                
                doc.metadata.update({
                    'search_weight': normalized_vector_score,
                    'search_type': 'vector',
                    'original_score': vector_score,
                    'rank': i + 1
                })
                vector_results.append(doc)
            
            # BM25 ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
            bm25_results = []
            for i, doc in enumerate(bm25_docs):
                # BM25 ê²€ìƒ‰ ê²°ê³¼ì— ì •ê·œí™”ëœ ì ìˆ˜ ë¶€ì—¬ (ìˆœìœ„ ê¸°ë°˜)
                bm25_score = max(0.1, 0.2 - (i * 0.02))  # ìˆœìœ„ì— ë”°ë¼ ì ìˆ˜ ê°ì†Œ, ìµœì†Œ 0.1
                
                doc.metadata.update({
                    'search_weight': bm25_score,
                    'search_type': 'bm25',
                    'original_score': bm25_score,
                    'rank': i + 1
                })
                bm25_results.append(doc)
            
            # 4. ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ ì¡°ì •
            unique_docs = {}
            
            # ë²¡í„° ê²°ê³¼ ë¨¼ì € ì¶”ê°€
            for doc in vector_results:
                doc_id = doc.metadata.get('chunk_id', doc.metadata.get('message_id', str(hash(doc.page_content))))
                unique_docs[doc_id] = doc
            
            # BM25 ê²°ê³¼ ì¶”ê°€ (ì¤‘ë³µ ì‹œ ì ìˆ˜ ì¡°ì •)
            for doc in bm25_results:
                doc_id = doc.metadata.get('chunk_id', doc.metadata.get('message_id', str(hash(doc.page_content))))
                
                if doc_id in unique_docs:
                    # ì¤‘ë³µ ë¬¸ì„œì¸ ê²½ìš° ì ìˆ˜ ì¡°ì •
                    existing_doc = unique_docs[doc_id]
                    existing_weight = existing_doc.metadata.get('search_weight', 0)
                    bm25_weight = doc.metadata.get('search_weight', 0)
                    
                    # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
                    hybrid_score = (existing_weight * 0.7) + (bm25_weight * 0.3)
                    
                    existing_doc.metadata.update({
                        'search_weight': hybrid_score,
                        'search_type': 'hybrid',
                        'vector_score': existing_weight,
                        'bm25_score': bm25_weight
                    })
                else:
                    # ìƒˆë¡œìš´ ë¬¸ì„œì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì¶”ê°€
                    unique_docs[doc_id] = doc
            
            # 5. ìµœì¢… ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            final_docs = list(unique_docs.values())
            final_docs.sort(key=lambda x: x.metadata.get('search_weight', 0), reverse=True)
            
            # 6. ë¡œê¹… ê°œì„ 
            vector_count = len(vector_results)
            bm25_count = len(bm25_results)
            hybrid_count = len([d for d in final_docs if d.metadata.get('search_type') == 'hybrid'])
            
            logger.info(f"âœ… ê°œì„ ëœ ë¶„ë¦¬ëœ ê²€ìƒ‰ ì™„ë£Œ:")
            logger.info(f"  - ë²¡í„° ê²€ìƒ‰: {vector_count}ê°œ")
            logger.info(f"  - BM25 ê²€ìƒ‰: {bm25_count}ê°œ")
            logger.info(f"  - í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼: {hybrid_count}ê°œ")
            logger.info(f"  - ìµœì¢… í†µí•©: {len(final_docs)}ê°œ")
            
            # ìƒìœ„ 3ê°œ ê²°ê³¼ì˜ ì ìˆ˜ ë¡œê¹…
            for i, doc in enumerate(final_docs[:3]):
                score = doc.metadata.get('search_weight', 0)
                search_type = doc.metadata.get('search_type', 'unknown')
                logger.info(f"  - ê²°ê³¼ {i+1}: {search_type} (ì ìˆ˜: {score:.3f})")
            
            return final_docs
            
        except Exception as e:
            logger.error(f"âŒ ê°œì„ ëœ ë¶„ë¦¬ëœ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def search(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        í‚¤ì›Œë“œ ì¶”ì¶œì„ í†µí•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            if not self.ensemble_retriever:
                logger.warning("âš ï¸ EnsembleRetrieverê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return []
            
            logger.info(f"ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘: '{query}'")
            
            # 1. í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self.keyword_extractor.extract_keywords(query)
            keyword_query = " ".join(keywords)
            logger.info(f"ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
            
            # 2. ë¶„ë¦¬ëœ ê²€ìƒ‰ ì‹¤í–‰
            # ë²¡í„° ê²€ìƒ‰: ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©
            vector_query = preprocess_for_embedding(query)
            
            # BM25 ê²€ìƒ‰: ì¶”ì¶œëœ í‚¤ì›Œë“œ ì‚¬ìš©
            bm25_query = preprocess_for_embedding(keyword_query)
            
            logger.info(f"ğŸ” ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬: '{vector_query}'")
            logger.info(f"ğŸ” BM25 ê²€ìƒ‰ ì¿¼ë¦¬: '{bm25_query}'")
            
            # 3. ë¶„ë¦¬ëœ ê²€ìƒ‰ ì‹¤í–‰
            documents = self._perform_separated_search(vector_query, bm25_query)
            
            # ê²°ê³¼ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            results = []
            for i, doc in enumerate(documents[:k]):
                result = {
                    "id": f"hybrid_{i}",
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "similarity_score": doc.metadata.get("similarity_score", 0.0),
                    "source": "hybrid_search",
                    "extracted_keywords": keywords  # ì¶”ì¶œëœ í‚¤ì›Œë“œ ì •ë³´ ì¶”ê°€
                }
                results.append(result)
            
            logger.info(f"âœ… í‚¤ì›Œë“œ ì¶”ì¶œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            logger.error(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def get_search_info(self) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì‹œìŠ¤í…œ ì •ë³´ ë°˜í™˜"""
        return {
            "total_documents": len(self.documents),
            "bm25_retriever_ready": self.bm25_retriever is not None,
            "ensemble_retriever_ready": self.ensemble_retriever is not None,
            "weights": [0.2, 0.8] if self.ensemble_retriever else None,  # BM25: 0.2, Vector: 0.8
            "weight_description": "BM25(í‚¤ì›Œë“œ): 20%, Vector(ì˜ë¯¸): 80%" if self.ensemble_retriever else None
        }

def create_hybrid_search_retriever(vector_db_manager: VectorDBManager) -> HybridSearchRetriever:
    """HybridSearchRetriever ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return HybridSearchRetriever(vector_db_manager)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    try:
        vector_db = VectorDBManager()
        hybrid_retriever = create_hybrid_search_retriever(vector_db)
        
        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        results = hybrid_retriever.search("ì„œë²„ ì ‘ì† ë¬¸ì œ", k=3)
        
        print(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
        for i, result in enumerate(results):
            print(f"{i+1}. {result['content'][:100]}...")
            print(f"   ì†ŒìŠ¤: {result['metadata'].get('source', 'unknown')}")
            print(f"   ìœ ì‚¬ë„: {result['similarity_score']}")
            print()
        
        # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
        info = hybrid_retriever.get_search_info()
        print(f"ì‹œìŠ¤í…œ ì •ë³´: {info}")
        
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
