#!/usr/bin/env python3
"""
HyDE (Hypothetical Document Embeddings) ê¸°ë°˜ RAG ì‹œìŠ¤í…œ
ë©€í‹° ì¿¼ë¦¬ì™€ HyDEë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì „ëµ êµ¬í˜„
"""

import os
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import chromadb
from chromadb.config import Settings
from dotenv import load_dotenv
import numpy as np

# Azure OpenAI ì„¤ì •
load_dotenv()

try:
    from openai import AzureOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from setup_korean_embedding import KoreanEmbeddingFunction
from intelligent_chunk_weighting import IntelligentChunkWeighting

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class HyDEConfig:
    """HyDE ì‹œìŠ¤í…œ ì„¤ì •"""
    # LLM ì„¤ì •
    azure_openai_api_key: str = os.getenv("AZURE_OPENAI_API_KEY", "")
    azure_openai_endpoint: str = os.getenv("AZURE_OPENAI_ENDPOINT", "")
    azure_openai_api_version: str = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
    azure_openai_deployment_name: str = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "")

    # ê²€ìƒ‰ ì„¤ì •
    multi_query_count: int = 3  # ë©€í‹° ì¿¼ë¦¬ ê°œìˆ˜
    hyde_document_count: int = 1  # HyDE ë¬¸ì„œ ê°œìˆ˜
    top_k_per_query: int = 15  # ì¿¼ë¦¬ë‹¹ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
    final_candidates: int = 50  # ìµœì¢… í›„ë³´ ìˆ˜

class HyDEPromptTemplate:
    """HyDE í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬ í´ë˜ìŠ¤"""

    # ê¸°ë³¸ HyDE í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    HYDE_PROMPT_TEMPLATE = """ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´, ê°€ì¥ ì™„ë²½í•˜ê³  ì´ìƒì ì¸ ë‹µë³€ì„ Jira í‹°ì¼“ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.
ì‹¤ì œ ì •ë³´ê°€ ì—†ì–´ë„ ê´œì°®ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê°€ìƒì˜ ë¬¸ì„œë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.
ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: "{question}"

ê°€ìƒì˜ ë‹µë³€ (Jira í‹°ì¼“ ë‚´ìš©):
"""

    # ë©€í‹° ì¿¼ë¦¬ ìƒì„± í”„ë¡¬í”„íŠ¸
    MULTI_QUERY_PROMPT_TEMPLATE = """ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ, ì˜ë¯¸ëŠ” ìœ ì‚¬í•˜ì§€ë§Œ ë‹¤ë¥¸ í‘œí˜„ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ê° ì¿¼ë¦¬ëŠ” ì›ë³¸ ì§ˆë¬¸ê³¼ ê°™ì€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆì§€ë§Œ, ë‹¤ë¥¸ í‚¤ì›Œë“œë‚˜ í‘œí˜„ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

ì›ë³¸ ì§ˆë¬¸: "{question}"

ê²€ìƒ‰ ì¿¼ë¦¬ 1:
ê²€ìƒ‰ ì¿¼ë¦¬ 2:
ê²€ìƒ‰ ì¿¼ë¦¬ 3:
"""

    @classmethod
    def create_hyde_prompt(cls, question: str) -> str:
        """HyDE ë¬¸ì„œ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return cls.HYDE_PROMPT_TEMPLATE.format(question=question)

    @classmethod
    def create_multi_query_prompt(cls, question: str) -> str:
        """ë©€í‹° ì¿¼ë¦¬ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return cls.MULTI_QUERY_PROMPT_TEMPLATE.format(question=question)

class HyDEDocumentGenerator:
    """HyDE ê°€ìƒ ë¬¸ì„œ ìƒì„±ê¸°"""

    def __init__(self, config: HyDEConfig):
        """
        HyDE ë¬¸ì„œ ìƒì„±ê¸° ì´ˆê¸°í™”

        Args:
            config: HyDE ì„¤ì •
        """
        self.config = config
        self.llm_client = None
        self._init_llm_client()

    def _init_llm_client(self):
        """Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not OPENAI_AVAILABLE:
            raise ImportError("openai ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        if not all([
            self.config.azure_openai_api_key,
            self.config.azure_openai_endpoint,
            self.config.azure_openai_deployment_name
        ]):
            raise ValueError("Azure OpenAI í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.llm_client = AzureOpenAI(
            api_key=self.config.azure_openai_api_key,
            api_version=self.config.azure_openai_api_version,
            azure_endpoint=self.config.azure_openai_endpoint
        )

        logger.info("âœ… Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

    def generate_hypothetical_document(self, question: str) -> str:
        """
        HyDE ê°€ìƒ ë¬¸ì„œ ìƒì„±

        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸

        Returns:
            ìƒì„±ëœ ê°€ìƒ ë¬¸ì„œ
        """
        try:
            prompt = HyDEPromptTemplate.create_hyde_prompt(question)

            response = self.llm_client.chat.completions.create(
                model=self.config.azure_openai_deployment_name,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ Jira í‹°ì¼“ ë‚´ìš©ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê°€ì¥ ì´ìƒì ì¸ ë‹µë³€ì„ ë‹´ì€ ê°€ìƒì˜ ë¬¸ì„œë¥¼ ìƒì„±í•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=300
            )

            hypothetical_doc = response.choices[0].message.content.strip()

            logger.info(f"âœ… HyDE ë¬¸ì„œ ìƒì„± ì™„ë£Œ: {len(hypothetical_doc)}ì")
            return hypothetical_doc

        except Exception as e:
            logger.error(f"âŒ HyDE ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•œ ê°€ìƒ ë¬¸ì„œ ìƒì„±
            return f"ì§ˆë¬¸ '{question}'ì— ëŒ€í•œ í•´ê²° ë°©ë²•ê³¼ ìƒì„¸í•œ ì„¤ëª…ì´ í¬í•¨ëœ ë¬¸ì„œì…ë‹ˆë‹¤."

    def generate_multi_queries(self, question: str) -> List[str]:
        """
        ë©€í‹° ì¿¼ë¦¬ ìƒì„±

        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸

        Returns:
            ìƒì„±ëœ ë©€í‹° ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        try:
            prompt = HyDEPromptTemplate.create_multi_query_prompt(question)

            response = self.llm_client.chat.completions.create(
                model=self.config.azure_openai_deployment_name,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ ë‹¤ë¥¸ í‘œí˜„ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.8,
                max_tokens=200
            )

            response_text = response.choices[0].message.content.strip()

            # ì‘ë‹µì—ì„œ ì¿¼ë¦¬ ì¶”ì¶œ
            queries = []
            lines = response_text.split('\n')
            for line in lines:
                line = line.strip()
                if line and ('ê²€ìƒ‰ ì¿¼ë¦¬' in line or line.startswith(('1.', '2.', '3.', '-', '*'))):
                    # ë²ˆí˜¸ë‚˜ ê¸°í˜¸ ì œê±°
                    clean_query = line.split(':', 1)[-1].strip()
                    if clean_query and len(clean_query) > 5:  # ë„ˆë¬´ ì§§ì€ ì¿¼ë¦¬ ì œì™¸
                        queries.append(clean_query)

            # 3ê°œ ë¯¸ë§Œì´ë©´ ì›ë³¸ ì§ˆë¬¸ ë³€í˜•ìœ¼ë¡œ ë³´ì™„
            while len(queries) < self.config.multi_query_count:
                if len(queries) == 0:
                    queries.append(f"{question} ë¬¸ì œ")
                elif len(queries) == 1:
                    queries.append(f"{question} í•´ê²°")
                elif len(queries) == 2:
                    queries.append(f"{question} ë°©ë²•")

            queries = queries[:self.config.multi_query_count]

            logger.info(f"âœ… ë©€í‹° ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ: {len(queries)}ê°œ")
            return queries

        except Exception as e:
            logger.error(f"âŒ ë©€í‹° ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ë³€í˜• ì¿¼ë¦¬ ìƒì„±
            return [
                f"{question} ë¬¸ì œ",
                f"{question} í•´ê²°",
                f"{question} ë°©ë²•"
            ]

class HyDERAGSystem:
    """HyDE ê¸°ë°˜ RAG ì‹œìŠ¤í…œ"""

    def __init__(self, collection_name: str = "file_chunks", config: Optional[HyDEConfig] = None):
        """
        HyDE RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”

        Args:
            collection_name: ChromaDB ì»¬ë ‰ì…˜ ì´ë¦„
            config: HyDE ì„¤ì •
        """
        self.collection_name = collection_name
        self.config = config or HyDEConfig()

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.client = None
        self.collection = None
        self.embedding_function = None
        self.hyde_generator = None
        self.weighting_system = None

        self._init_components()

    def _init_components(self):
        """ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        try:
            # ChromaDB ì—°ê²°
            self.client = chromadb.PersistentClient(
                path='./vector_db',
                settings=Settings(anonymized_telemetry=False, allow_reset=True)
            )
            self.collection = self.client.get_collection(self.collection_name)

            # í•œêµ­ì–´ ì„ë² ë”© í•¨ìˆ˜ (ê¸°ì¡´ ì»¬ë ‰ì…˜ê³¼ í˜¸í™˜ë˜ë„ë¡ 384ì°¨ì› ì‚¬ìš©)
            self.embedding_function = KoreanEmbeddingFunction()

            # HyDE ë¬¸ì„œ ìƒì„±ê¸°
            self.hyde_generator = HyDEDocumentGenerator(self.config)

            # ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ
            self.weighting_system = IntelligentChunkWeighting()

            logger.info(f"âœ… HyDE RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ: {self.collection.count()}ê°œ ë¬¸ì„œ")

        except Exception as e:
            logger.error(f"âŒ HyDE RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise e

    def search(self, query: str, use_hyde: bool = True, use_multi_query: bool = True) -> List[Dict[str, Any]]:
        """
        HyDE ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            use_hyde: HyDE ì‚¬ìš© ì—¬ë¶€
            use_multi_query: ë©€í‹° ì¿¼ë¦¬ ì‚¬ìš© ì—¬ë¶€

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            logger.info(f"ğŸš€ HyDE RAG ê²€ìƒ‰ ì‹œì‘: '{query}'")

            # 1. ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„
            texts_to_embed = [query]  # ì›ë³¸ ì§ˆë¬¸ì€ í•­ìƒ í¬í•¨

            # 2. ë©€í‹° ì¿¼ë¦¬ ìƒì„± (ì˜µì…˜)
            if use_multi_query:
                multi_queries = self.hyde_generator.generate_multi_queries(query)
                texts_to_embed.extend(multi_queries)
                logger.info(f"ğŸ“ ë©€í‹° ì¿¼ë¦¬: {multi_queries}")

            # 3. HyDE ë¬¸ì„œ ìƒì„± (ì˜µì…˜)
            if use_hyde:
                hypothetical_doc = self.hyde_generator.generate_hypothetical_document(query)
                texts_to_embed.append(hypothetical_doc)
                logger.info(f"ğŸ¯ HyDE ë¬¸ì„œ: {hypothetical_doc[:100]}...")

            logger.info(f"ğŸ” ì´ {len(texts_to_embed)}ê°œ í…ìŠ¤íŠ¸ë¡œ ê²€ìƒ‰ ìˆ˜í–‰")

            # 4. ê° í…ìŠ¤íŠ¸ë¡œ ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
            all_results = []
            for i, text in enumerate(texts_to_embed):
                try:
                    # ê²€ìƒ‰ ìˆ˜í–‰ (ê¸°ì¡´ ì»¬ë ‰ì…˜ì˜ ì„ë² ë”© í•¨ìˆ˜ ì‚¬ìš©)
                    results = self.collection.query(
                        query_texts=[text],
                        n_results=self.config.top_k_per_query
                    )

                    # ê²°ê³¼ ì²˜ë¦¬
                    if results['ids'][0]:
                        for j in range(len(results['ids'][0])):
                            result = {
                                'id': results['ids'][0][j],
                                'content': results['documents'][0][j] if results['documents'][0] else "",
                                'distance': results['distances'][0][j] if results['distances'][0] else 1.0,
                                'metadata': results['metadatas'][0][j] if results['metadatas'][0] else {},
                                'query_type': 'original' if i == 0 else ('multi' if i < len(texts_to_embed) - (1 if use_hyde else 0) else 'hyde'),
                                'query_index': i,
                                'source_text': text[:100] + "..." if len(text) > 100 else text
                            }
                            all_results.append(result)

                    logger.info(f"   ì¿¼ë¦¬ {i+1}: {len(results['ids'][0]) if results['ids'][0] else 0}ê°œ ê²°ê³¼")

                except Exception as e:
                    logger.error(f"âŒ ì¿¼ë¦¬ {i+1} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue

            # 5. ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±°
            unique_results = self._process_and_deduplicate(all_results, query)

            logger.info(f"âœ… HyDE RAG ê²€ìƒ‰ ì™„ë£Œ: {len(unique_results)}ê°œ ê³ ìœ  ê²°ê³¼")
            return unique_results

        except Exception as e:
            logger.error(f"âŒ HyDE RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _process_and_deduplicate(self, all_results: List[Dict[str, Any]], original_query: str) -> List[Dict[str, Any]]:
        """
        ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ë° ì¤‘ë³µ ì œê±°

        Args:
            all_results: ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼
            original_query: ì›ë³¸ ì§ˆë¬¸

        Returns:
            ì¤‘ë³µ ì œê±°ëœ ìµœì¢… ê²°ê³¼
        """
        try:
            # 1. ID ê¸°ë°˜ ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ í†µí•©
            unique_docs = {}

            for result in all_results:
                doc_id = result['id']
                distance = result['distance']
                cosine_score = max(0.0, 1.0 - distance)

                if doc_id not in unique_docs:
                    unique_docs[doc_id] = {
                        'id': doc_id,
                        'content': result['content'],
                        'metadata': result['metadata'],
                        'scores': [],
                        'query_types': [],
                        'source_texts': []
                    }

                unique_docs[doc_id]['scores'].append(cosine_score)
                unique_docs[doc_id]['query_types'].append(result['query_type'])
                unique_docs[doc_id]['source_texts'].append(result['source_text'])

            # 2. ì ìˆ˜ í†µí•© (ìµœëŒ€ê°’ ì‚¬ìš©)
            processed_results = []
            for doc_id, doc_data in unique_docs.items():
                max_score = max(doc_data['scores'])

                # chunk_type ì¶”ì •
                chunk_type = self._estimate_chunk_type(doc_data['metadata'], doc_data['content'])

                # ê°€ì¤‘ì¹˜ ì ìš©ì„ ìœ„í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                search_result = {
                    'id': doc_id,
                    'content': doc_data['content'],
                    'chunk_type': chunk_type,
                    'cosine_score': max_score,
                    'embedding': [],
                    'metadata': {
                        **doc_data['metadata'],
                        'query_types': doc_data['query_types'],
                        'source_texts': doc_data['source_texts'],
                        'scores': doc_data['scores'],
                        'max_score': max_score,
                        'hyde_enhanced': True
                    }
                }
                processed_results.append(search_result)

            # 3. ê°€ì¤‘ì¹˜ ì ìš©
            mock_query_embedding = np.random.normal(0, 1, 384).tolist()
            weighted_results = self.weighting_system.apply_weighted_scoring(
                processed_results, mock_query_embedding
            )

            # 4. ìµœì¢… í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            final_results = []
            for weighted_result in weighted_results[:self.config.final_candidates]:
                result = {
                    "id": weighted_result.id,
                    "content": weighted_result.content,
                    "score": weighted_result.weighted_score,
                    "raw_score": weighted_result.cosine_score,
                    "weight": weighted_result.weight,
                    "chunk_type": weighted_result.chunk_type,
                    "source": "hyde_rag_system",
                    "metadata": {
                        **weighted_result.metadata,
                        "hyde_enhanced": True,
                        "weight_applied": True
                    }
                }
                final_results.append(result)

            return final_results

        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return []

    def _estimate_chunk_type(self, metadata: Dict[str, Any], content: str) -> str:
        """chunk_type ì¶”ì •"""
        content_lower = content.lower()

        if any(pattern in content_lower for pattern in ['ì œëª©:', 'title:', 'ì´ìŠˆ í‚¤:']):
            return 'title'
        elif any(pattern in content_lower for pattern in ['ìš”ì•½:', 'summary:']):
            return 'summary'
        elif any(pattern in content_lower for pattern in ['ì„¤ëª…:', 'description:']):
            return 'description'
        elif any(pattern in content_lower for pattern in ['ëŒ“ê¸€:', 'comment:']):
            return 'comment'
        elif len(content.strip()) < 30:
            return 'title'
        elif len(content.strip()) < 100:
            return 'summary'
        elif len(content.strip()) > 1000:
            return 'body'
        else:
            return 'description'

def test_hyde_system():
    """HyDE ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ HyDE RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("="*80)

    try:
        # HyDE ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        hyde_rag = HyDERAGSystem(collection_name="file_chunks")

        # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
        test_questions = [
            "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ê°€ ë³µì¡í•´ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤",
            "ì„œë²„ì— ì ‘ì†í•  ìˆ˜ ì—†ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì‹¶ì–´ìš”",
            "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ìì£¼ ëŠì–´ì§€ëŠ” í˜„ìƒì„ ì¡°ì‚¬í•´ì£¼ì„¸ìš”",
            "API ì‘ë‹µ ì‹œê°„ì´ ë„ˆë¬´ ëŠë ¤ì„œ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤"
        ]

        for i, question in enumerate(test_questions, 1):
            print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ {i}: {question}")
            print("-" * 60)

            # HyDE ê²€ìƒ‰ ìˆ˜í–‰
            results = hyde_rag.search(question)

            if results:
                print(f"âœ… {len(results)}ê°œ ê²°ê³¼ (HyDE + ë©€í‹°ì¿¼ë¦¬ + ê°€ì¤‘ì¹˜)")

                # ìƒìœ„ 3ê°œ ê²°ê³¼ í‘œì‹œ
                for j, result in enumerate(results[:3], 1):
                    score = result.get('score', 0)
                    raw_score = result.get('raw_score', 0)
                    weight = result.get('weight', 1.0)
                    chunk_type = result.get('chunk_type', 'unknown')

                    print(f"  {j}. [{chunk_type.upper()}] (ê°€ì¤‘ì¹˜: {weight:.1f})")
                    print(f"     ì ìˆ˜: {raw_score:.4f} â†’ {score:.4f}")

                    # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                    content = result.get('content', '')
                    preview = content[:100].replace('\n', ' ') + "..."
                    print(f"     ë‚´ìš©: {preview}")

                    # HyDE ì •ë³´
                    metadata = result.get('metadata', {})
                    if metadata.get('query_types'):
                        query_types = set(metadata['query_types'])
                        print(f"     ê²€ìƒ‰ íƒ€ì…: {', '.join(query_types)}")
                    print()
            else:
                print("âŒ ê²°ê³¼ ì—†ìŒ")

        return True

    except Exception as e:
        print(f"âŒ HyDE ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_hyde_system()