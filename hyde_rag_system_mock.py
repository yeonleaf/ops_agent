#!/usr/bin/env python3
"""
HyDE RAG ì‹œìŠ¤í…œ (Mock LLM ë²„ì „)
OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ Mock ë°ì´í„°ë¡œ HyDE ê°œë… ê²€ì¦
"""

import os
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import chromadb
from chromadb.config import Settings
import numpy as np
import random

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from intelligent_chunk_weighting import IntelligentChunkWeighting

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class HyDEConfig:
    """HyDE ì‹œìŠ¤í…œ ì„¤ì •"""
    multi_query_count: int = 3
    hyde_document_count: int = 1
    top_k_per_query: int = 15
    final_candidates: int = 50

class MockHyDEGenerator:
    """Mock HyDE ë¬¸ì„œ ìƒì„±ê¸° (OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ í…ŒìŠ¤íŠ¸ìš©)"""

    def __init__(self, config: HyDEConfig):
        self.config = config
        logger.info("âœ… Mock HyDE ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

    def generate_hypothetical_document(self, question: str) -> str:
        """Mock HyDE ë¬¸ì„œ ìƒì„±"""
        # ì§ˆë¬¸ì— ë”°ë¥¸ Mock ê°€ìƒ ë¬¸ì„œ ìƒì„±
        mock_documents = {
            "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤": "ì œëª©: UI ê°œì„  í”„ë¡œì íŠ¸\nìš”ì•½: ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ì˜ ì§ê´€ì„±ì„ ë†’ì´ê³  ì‚¬ìš©ì ê²½í—˜ì„ ê°œì„ í•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.\nì„¤ëª…: ê¸°ì¡´ UIì˜ ë³µì¡í•œ ë©”ë‰´ êµ¬ì¡°ë¥¼ ë‹¨ìˆœí™”í•˜ê³ , ì£¼ìš” ê¸°ëŠ¥ì— ëŒ€í•œ ì ‘ê·¼ì„±ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ë²„íŠ¼ ë°°ì¹˜ë¥¼ ìµœì í™”í•˜ê³  ìƒ‰ìƒ ëŒ€ë¹„ë¥¼ ê°œì„ í–ˆìŠµë‹ˆë‹¤.",

            "ì„œë²„ ì ‘ì†": "ì œëª©: ì„œë²„ ì ‘ì† ë¬¸ì œ í•´ê²°\nìš”ì•½: ì„œë²„ ì—°ê²° ì‹¤íŒ¨ ë¬¸ì œì˜ ì›ì¸ ë¶„ì„ ë° í•´ê²° ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤.\nì„¤ëª…: ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸, ë°©í™”ë²½ ì„¤ì • ì ê²€, í¬íŠ¸ ìƒíƒœ í™•ì¸ ë“±ì˜ ë‹¨ê³„ì  í•´ê²° ë°©ë²•ì„ í†µí•´ ì„œë²„ ì ‘ì† ë¬¸ì œë¥¼ í•´ê²°í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ ë¶„ì„ ê²°ê³¼ íƒ€ì„ì•„ì›ƒ ì„¤ì •ì´ ì›ì¸ì´ì—ˆìœ¼ë©°, ì„¤ì • ë³€ê²½ í›„ ì •ìƒ ë™ì‘ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.",

            "ë°ì´í„°ë² ì´ìŠ¤": "ì œëª©: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì•ˆì •ì„± ê°œì„ \nìš”ì•½: DB ì—°ê²° ëŠê¹€ í˜„ìƒì˜ ì›ì¸ ì¡°ì‚¬ ë° ì•ˆì •ì„± í–¥ìƒ ë°©ì•ˆì…ë‹ˆë‹¤.\nì„¤ëª…: ì—°ê²° í’€ ì„¤ì • ìµœì í™”, ì¿¼ë¦¬ ì„±ëŠ¥ íŠœë‹, ì¸ë±ìŠ¤ ì¬êµ¬ì„±ì„ í†µí•´ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì˜ ì•ˆì •ì„±ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ ë„ì…í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ DB ìƒíƒœë¥¼ ì¶”ì í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.",

            "API ì„±ëŠ¥": "ì œëª©: API ì‘ë‹µ ì‹œê°„ ìµœì í™”\nìš”ì•½: API ì„±ëŠ¥ ê°œì„ ì„ í†µí•œ ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.\nì„¤ëª…: ìºì‹± ì „ëµ ë„ì…, ì¿¼ë¦¬ ìµœì í™”, CDN í™œìš©ì„ í†µí•´ API ì‘ë‹µ ì‹œê°„ì„ 50% ë‹¨ì¶•í–ˆìŠµë‹ˆë‹¤. ë¹„ë™ê¸° ì²˜ë¦¬ ë„ì…ìœ¼ë¡œ ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥ë„ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤."
        }

        # ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ Mock ë¬¸ì„œ ì„ íƒ
        for keyword, doc in mock_documents.items():
            if keyword in question:
                logger.info(f"âœ… HyDE ë¬¸ì„œ ìƒì„± (í‚¤ì›Œë“œ: {keyword})")
                return doc

        # ê¸°ë³¸ Mock ë¬¸ì„œ
        default_doc = f"ì œëª©: {question} í•´ê²° ë°©ì•ˆ\nìš”ì•½: {question}ì— ëŒ€í•œ ìƒì„¸í•œ ë¶„ì„ê³¼ í•´ê²° ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.\nì„¤ëª…: ë¬¸ì œì˜ ì›ì¸ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ë‹¨ê³„ë³„ í•´ê²° ë°©ì•ˆì„ í†µí•´ íš¨ê³¼ì ì¸ ë¬¸ì œ í•´ê²°ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤."
        logger.info("âœ… HyDE ë¬¸ì„œ ìƒì„± (ê¸°ë³¸ í…œí”Œë¦¿)")
        return default_doc

    def generate_multi_queries(self, question: str) -> List[str]:
        """
        NCMS ì‹œìŠ¤í…œ íŠ¹í™” ë©€í‹° ì¿¼ë¦¬ ìƒì„±

        ê·œì¹™:
        1. ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ë¥¼ íŒŒì•…
        2. ê¸°ìˆ ì  ë™ì˜ì–´ì™€ êµ¬ì²´ì ì¸ íŒŒì¼ëª…/ìš©ì–´ í¬í•¨
        3. í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±
        """
        question_lower = question.lower()

        # ê¸°ìˆ  ìš©ì–´ ë™ì˜ì–´ ë§¤í•‘ (NCMS/JIRA ì‹œìŠ¤í…œ íŠ¹í™”)
        tech_synonyms = {
            "config": ["application.properties", "yml", "ì„¤ì • íŒŒì¼", "í™˜ê²½ë³€ìˆ˜", "configuration"],
            "ë°°ì¹˜": ["Batch", "Job", "Quartz", "ìŠ¤ì¼€ì¤„ëŸ¬", "ì •ê¸° ì‘ì—…"],
            "db": ["Oracle", "Tibero", "ë°ì´í„°ë² ì´ìŠ¤", "Database", "RDB"],
            "api": ["REST API", "ì—”ë“œí¬ì¸íŠ¸", "ì¸í„°í˜ì´ìŠ¤", "ì›¹ì„œë¹„ìŠ¤"],
            "vm": ["ê°€ìƒë¨¸ì‹ ", "Virtual Machine", "ì„œë²„", "ì¸ìŠ¤í„´ìŠ¤"],
            "exception": ["ì—ëŸ¬", "ì˜¤ë¥˜", "Error", "ì¥ì• ", "ì˜ˆì™¸"],
            "ë§ˆì´ê·¸ë ˆì´ì…˜": ["migration", "ì´ê´€", "ì „í™˜", "ë°ì´í„° ì´ë™"],
            "ecdn": ["CDN", "ì½˜í…ì¸  ì „ì†¡ ë„¤íŠ¸ì›Œí¬", "ìºì‹œ ì„œë²„"],
            "sequence": ["ì‹œí€€ìŠ¤", "ìˆœë²ˆ", "ì¼ë ¨ë²ˆí˜¸"],
            "preprd": ["Pre-Production", "ì‚¬ì „ìš´ì˜", "ìŠ¤í…Œì´ì§•"],
            "stg": ["Staging", "ìŠ¤í…Œì´ì§•", "í…ŒìŠ¤íŠ¸ í™˜ê²½"],
            "lcms": ["Legacy CMS", "êµ¬ CMS", "ì´ì „ ì‹œìŠ¤í…œ"],
            "cpì‚¬": ["CP", "ì½˜í…ì¸  ì œê³µì", "Content Provider", "ì œíœ´ì‚¬"],
            "ì´ë¯¸ì§€": ["image", "img", "ì‚¬ì§„", "ê·¸ë¦¼ íŒŒì¼"],
            "ë™ì˜ìƒ": ["video", "VOD", "ì˜ìƒ", "ë¯¸ë””ì–´"],
            "ë‹¤ìš´ë¡œë“œ": ["download", "ë°›ê¸°", "ì „ì†¡"],
            "ë©”íƒ€": ["metadata", "ë©”íƒ€ë°ì´í„°", "ì •ë³´"],
            "í": ["queue", "ëŒ€ê¸°ì—´", "ë©”ì‹œì§€í"]
        }

        # NCMS ì‹œìŠ¤í…œ íŠ¹í™” ë©€í‹° ì¿¼ë¦¬ ë§¤í•‘
        multi_queries_map = {
            # Config ê´€ë ¨
            ("config", "ì„¤ì •", "yml", "properties"): [
                "application.properties ë˜ëŠ” yml ì„¤ì • íŒŒì¼ì„ êµì²´í•˜ê±°ë‚˜ ìˆ˜ì •í•œ ì´ë ¥",
                "í™˜ê²½ë³€ìˆ˜ ì„¤ì • ë³€ê²½ìœ¼ë¡œ ì¸í•œ ë¬¸ì œ í•´ê²°",
                "configuration ì˜¤ë¥˜ë¡œ config íŒŒì¼ì„ êµì²´í•œ ì¼€ì´ìŠ¤"
            ],

            # ë°°ì¹˜ ê´€ë ¨
            ("ë°°ì¹˜", "batch", "job", "quartz"): [
                "Batch Jobì´ë‚˜ Quartz ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì¬ê¸°ë™í•œ ì´ë ¥",
                "ì •ê¸° ì‘ì—…ì´ë‚˜ ë°°ì¹˜ í”„ë¡œì„¸ìŠ¤ ì¬ì‹œì‘ ì¼€ì´ìŠ¤",
                "ë°°ì¹˜ ì¢…ë£Œë˜ì§€ ì•Šì•„ì„œ ê°•ì œ ì¤‘ë‹¨ ë° ì¬ê¸°ë™"
            ],

            # DB ê´€ë ¨
            ("db", "database", "ë°ì´í„°ë² ì´ìŠ¤", "oracle", "tibero", "ë§ˆì´ê·¸ë ˆì´ì…˜"): [
                "Oracle ë˜ëŠ” Tibero ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ì† ì‘ì—…",
                "DB ì´ê´€ ë° ì „í™˜ ì‘ì—… ì´í›„ ì¡°ì¹˜ì‚¬í•­",
                "ë°ì´í„°ë² ì´ìŠ¤ migration ê´€ë ¨ í‹°ì¼“"
            ],

            # API ê´€ë ¨
            ("api", "rest", "ì—”ë“œí¬ì¸íŠ¸"): [
                "REST API ì—”ë“œí¬ì¸íŠ¸ë‚˜ ì›¹ì„œë¹„ìŠ¤ ì¸í„°í˜ì´ìŠ¤ ë¬¸ì œ",
                "API í˜¸ì¶œ ì˜¤ë¥˜ ë° ì‘ë‹µ ì´ìƒ",
                "API í•„ë“œ ì¡°ê±´ì´ë‚˜ ìŠ¤í™ ë¬¸ì˜"
            ],

            # Exception/ì˜¤ë¥˜ ê´€ë ¨
            ("exception", "error", "ì˜¤ë¥˜", "ì—ëŸ¬", "ì¥ì• "): [
                "VMì´ë‚˜ ì„œë²„ì—ì„œ ë°œìƒí•œ Exception ë° ì—ëŸ¬ ë¡œê·¸",
                "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ì¥ì•  ëŒ€ì‘",
                "ì˜ˆì™¸ ìƒí™© ë°œìƒ ì‹œ ì¡°ì¹˜ ì´ë ¥"
            ],

            # í™˜ê²½ ê´€ë ¨
            ("preprd", "stg", "staging", "í™˜ê²½"): [
                "PrePRDë‚˜ Staging í™˜ê²½ ì„¤ì • ë° ì´ˆê¸° ì„¸íŒ…",
                "ì‚¬ì „ìš´ì˜ ë˜ëŠ” í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶•",
                "í™˜ê²½ë³„ ì´ë¯¸ì§€ ECDN ê²½ë¡œ ì„¤ì •"
            ],

            # ì´ë¯¸ì§€/ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ
            ("ì´ë¯¸ì§€", "ë™ì˜ìƒ", "ë‹¤ìš´ë¡œë“œ", "image", "video"): [
                "ì´ë¯¸ì§€ë‚˜ ë™ì˜ìƒ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜",
                "ë¯¸ë””ì–´ ì „ì†¡ ë° ë°›ê¸° ì§€ì—° ë¬¸ì œ",
                "img, video íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì¼€ì´ìŠ¤"
            ],

            # Sequence ê´€ë ¨
            ("sequence", "ì‹œí€€ìŠ¤", "ìˆœë²ˆ"): [
                "sequence number ë¶ˆì¼ì¹˜ ì‹œ ì¡°ì¹˜ì‚¬í•­",
                "ì‹œí€€ìŠ¤ ìˆœë²ˆì´ ë§ì§€ ì•Šì„ ë•Œ ëŒ€ì‘ ë°©ë²•",
                "ì¼ë ¨ë²ˆí˜¸ ì˜¤ë¥˜ í•´ê²°"
            ],

            # CPì‚¬/ì½˜í…ì¸  ê´€ë ¨
            ("cp", "cpì‚¬", "ì½˜í…ì¸ ", "ë§Œë£Œ", "ì´ê´€"): [
                "CPì‚¬ ë˜ëŠ” ì½˜í…ì¸  ì œê³µì ì´ê´€ ì‘ì—…",
                "ë°©ì†¡ì‚¬ ì½˜í…ì¸  ë§Œë£Œ ì²˜ë¦¬ ì ˆì°¨",
                "ì œíœ´ì‚¬ Content Provider ì „í™˜"
            ],

            # ë©”íƒ€/í ê´€ë ¨
            ("ë©”íƒ€", "metadata", "í", "queue"): [
                "ì™¸ë¶€ ë©”íƒ€ë°ì´í„° í ë°œì†¡ ë¬¸ì œ",
                "ë©”íƒ€ ì •ë³´ ì „ë‹¬ queue ì˜¤ë¥˜",
                "ë©”ì‹œì§€í ëŒ€ê¸°ì—´ ì´ìƒ"
            ],

            # LCMS ë ˆê±°ì‹œ
            ("lcms", "ë ˆê±°ì‹œ", "êµ¬ ì‹œìŠ¤í…œ"): [
                "LCMS ì‹œì ˆ ìƒì„±ëœ Legacy ë°ì´í„°",
                "êµ¬ CMSë‚˜ ì´ì „ ì‹œìŠ¤í…œì—ì„œ ë°œìƒí•œ ë¬¸ì œ",
                "ë ˆê±°ì‹œ ë°ì´í„° ì •ë¦¬ ì´ë ¥"
            ],

            # í…Œì´ë¸”/DB ì‘ì—…
            ("í…Œì´ë¸”", "table", "ì‚­ì œ", "drop"): [
                "ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì‚­ì œ ë˜ëŠ” drop ì´ë ¥",
                "DB table ì œê±° ì‘ì—…",
                "í…Œì´ë¸” ì •ë¦¬ ë° ì‚­ì œ ì¼€ì´ìŠ¤"
            ],

            # ì ‘ì† ë¬¸ì œ
            ("ì ‘ì†", "ì—°ê²°", "connection"): [
                "DBë‚˜ ì„œë²„ ì ‘ì† ë¶ˆê°€ ë¬¸ì œ",
                "ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜ ëŒ€ì‘",
                "connection ì‹¤íŒ¨ ì‹œ ì¡°ì¹˜ì‚¬í•­"
            ]
        }

        # í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ íŠ¹í™” ì¿¼ë¦¬ ì„ íƒ
        for keywords, queries in multi_queries_map.items():
            if any(keyword in question_lower for keyword in keywords):
                logger.info(f"âœ… ë©€í‹° ì¿¼ë¦¬ ìƒì„± (í‚¤ì›Œë“œ: {keywords[0]})")
                return queries

        # ê¸°ë³¸ ë©€í‹° ì¿¼ë¦¬ (ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ)
        # ì§ˆë¬¸ì—ì„œ í•µì‹¬ ìš©ì–´ ì¶”ì¶œ ì‹œë„
        default_queries = [
            f"{question} í•´ê²° ë°©ë²•ì´ë‚˜ ì¡°ì¹˜ì‚¬í•­",
            f"{question}ì™€ ê´€ë ¨ëœ ì´ë ¥ì´ë‚˜ ì¼€ì´ìŠ¤",
            f"{question} ë¬¸ì œ ëŒ€ì‘ ë° ì²˜ë¦¬"
        ]
        logger.info("âœ… ë©€í‹° ì¿¼ë¦¬ ìƒì„± (ê¸°ë³¸ í…œí”Œë¦¿)")
        return default_queries

class HyDERAGSystemMock:
    """Mock HyDE RAG ì‹œìŠ¤í…œ"""

    def __init__(self, collection_name: str = "file_chunks", config: Optional[HyDEConfig] = None):
        self.collection_name = collection_name
        self.config = config or HyDEConfig()
        self._init_components()

    def _init_components(self):
        """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        try:
            # ChromaDB ì—°ê²°
            self.client = chromadb.PersistentClient(
                path='./vector_db',
                settings=Settings(anonymized_telemetry=False, allow_reset=True)
            )
            self.collection = self.client.get_collection(self.collection_name)

            # Mock HyDE ìƒì„±ê¸°
            self.hyde_generator = MockHyDEGenerator(self.config)

            # ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ
            self.weighting_system = IntelligentChunkWeighting()

            logger.info(f"âœ… Mock HyDE RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ: {self.collection.count()}ê°œ ë¬¸ì„œ")

        except Exception as e:
            logger.error(f"âŒ Mock HyDE RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise e

    def search(self, query: str, use_hyde: bool = True, use_multi_query: bool = True) -> List[Dict[str, Any]]:
        """HyDE ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
        try:
            logger.info(f"ğŸš€ Mock HyDE RAG ê²€ìƒ‰ ì‹œì‘: '{query}'")

            # 1. ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„
            texts_to_embed = [query]

            # 2. ë©€í‹° ì¿¼ë¦¬ ìƒì„±
            if use_multi_query:
                multi_queries = self.hyde_generator.generate_multi_queries(query)
                texts_to_embed.extend(multi_queries)
                logger.info(f"ğŸ“ ë©€í‹° ì¿¼ë¦¬: {multi_queries}")

            # 3. HyDE ë¬¸ì„œ ìƒì„±
            if use_hyde:
                hypothetical_doc = self.hyde_generator.generate_hypothetical_document(query)
                texts_to_embed.append(hypothetical_doc)
                logger.info(f"ğŸ¯ HyDE ë¬¸ì„œ: {hypothetical_doc[:100]}...")

            logger.info(f"ğŸ” ì´ {len(texts_to_embed)}ê°œ í…ìŠ¤íŠ¸ë¡œ ê²€ìƒ‰ ìˆ˜í–‰")

            # 4. ê° í…ìŠ¤íŠ¸ë¡œ ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
            all_results = []
            for i, text in enumerate(texts_to_embed):
                try:
                    results = self.collection.query(
                        query_texts=[text],
                        n_results=self.config.top_k_per_query
                    )

                    if results['ids'][0]:
                        for j in range(len(results['ids'][0])):
                            result = {
                                'id': results['ids'][0][j],
                                'content': results['documents'][0][j] if results['documents'][0] else "",
                                'distance': results['distances'][0][j] if results['distances'][0] else 1.0,
                                'metadata': results['metadatas'][0][j] if results['metadatas'][0] else {},
                                'query_type': 'original' if i == 0 else ('multi' if i < len(texts_to_embed) - (1 if use_hyde else 0) else 'hyde'),
                                'query_index': i,
                                'source_text': text[:50] + "..." if len(text) > 50 else text
                            }
                            all_results.append(result)

                    logger.info(f"   ì¿¼ë¦¬ {i+1}: {len(results['ids'][0]) if results['ids'][0] else 0}ê°œ ê²°ê³¼")

                except Exception as e:
                    logger.error(f"âŒ ì¿¼ë¦¬ {i+1} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue

            # 5. ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±°
            unique_results = self._process_and_deduplicate(all_results, query)

            logger.info(f"âœ… Mock HyDE RAG ê²€ìƒ‰ ì™„ë£Œ: {len(unique_results)}ê°œ ê³ ìœ  ê²°ê³¼")
            return unique_results

        except Exception as e:
            logger.error(f"âŒ Mock HyDE RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _process_and_deduplicate(self, all_results: List[Dict[str, Any]], original_query: str) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ë° ì¤‘ë³µ ì œê±°"""
        try:
            # 1. ID ê¸°ë°˜ ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ í†µí•©
            unique_docs = {}

            for result in all_results:
                doc_id = result['id']
                distance = result['distance']
                cosine_score = max(0.0, 1.0 - distance)

                if doc_id not in unique_docs:
                    unique_docs[doc_id] = {
                        'id': doc_id,
                        'content': result['content'],
                        'metadata': result['metadata'],
                        'scores': [],
                        'query_types': [],
                        'source_texts': []
                    }

                unique_docs[doc_id]['scores'].append(cosine_score)
                unique_docs[doc_id]['query_types'].append(result['query_type'])
                unique_docs[doc_id]['source_texts'].append(result['source_text'])

            # 2. ì ìˆ˜ í†µí•© (ìµœëŒ€ê°’ ì‚¬ìš©)
            processed_results = []
            for doc_id, doc_data in unique_docs.items():
                max_score = max(doc_data['scores'])

                # chunk_type ì¶”ì •
                chunk_type = self._estimate_chunk_type(doc_data['metadata'], doc_data['content'])

                search_result = {
                    'id': doc_id,
                    'content': doc_data['content'],
                    'chunk_type': chunk_type,
                    'cosine_score': max_score,
                    'embedding': [],
                    'metadata': {
                        **doc_data['metadata'],
                        'query_types': doc_data['query_types'],
                        'source_texts': doc_data['source_texts'],
                        'scores': doc_data['scores'],
                        'max_score': max_score,
                        'hyde_enhanced': True
                    }
                }
                processed_results.append(search_result)

            # 3. ê°€ì¤‘ì¹˜ ì ìš©
            mock_query_embedding = np.random.normal(0, 1, 384).tolist()
            weighted_results = self.weighting_system.apply_weighted_scoring(
                processed_results, mock_query_embedding
            )

            # 4. ìµœì¢… í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            final_results = []
            for weighted_result in weighted_results[:self.config.final_candidates]:
                result = {
                    "id": weighted_result.id,
                    "content": weighted_result.content,
                    "score": weighted_result.weighted_score,
                    "raw_score": weighted_result.cosine_score,
                    "weight": weighted_result.weight,
                    "chunk_type": weighted_result.chunk_type,
                    "source": "mock_hyde_rag_system",
                    "metadata": {
                        **weighted_result.metadata,
                        "hyde_enhanced": True,
                        "weight_applied": True
                    }
                }
                final_results.append(result)

            return final_results

        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return []

    def _estimate_chunk_type(self, metadata: Dict[str, Any], content: str) -> str:
        """chunk_type ì¶”ì •"""
        content_lower = content.lower()

        if any(pattern in content_lower for pattern in ['ì œëª©:', 'title:', 'ì´ìŠˆ í‚¤:']):
            return 'title'
        elif any(pattern in content_lower for pattern in ['ìš”ì•½:', 'summary:']):
            return 'summary'
        elif any(pattern in content_lower for pattern in ['ì„¤ëª…:', 'description:']):
            return 'description'
        elif any(pattern in content_lower for pattern in ['ëŒ“ê¸€:', 'comment:']):
            return 'comment'
        elif len(content.strip()) < 30:
            return 'title'
        elif len(content.strip()) < 100:
            return 'summary'
        elif len(content.strip()) > 1000:
            return 'body'
        else:
            return 'description'

    def compare_search_methods(self, query: str) -> Dict[str, List[Dict[str, Any]]]:
        """ê²€ìƒ‰ ë°©ë²•ë³„ ì„±ëŠ¥ ë¹„êµ"""
        print(f"\nğŸ”¬ ê²€ìƒ‰ ë°©ë²•ë³„ ì„±ëŠ¥ ë¹„êµ: '{query}'")
        print("="*80)

        # 1. ê¸°ë³¸ ê²€ìƒ‰ (ì›ë³¸ ì§ˆë¬¸ë§Œ)
        print("1ï¸âƒ£ ê¸°ë³¸ ê²€ìƒ‰ (ì›ë³¸ ì§ˆë¬¸ë§Œ)")
        basic_results = self.search(query, use_hyde=False, use_multi_query=False)
        print(f"   ê²°ê³¼: {len(basic_results)}ê°œ")

        # 2. ë©€í‹° ì¿¼ë¦¬ ê²€ìƒ‰
        print("2ï¸âƒ£ ë©€í‹° ì¿¼ë¦¬ ê²€ìƒ‰")
        multi_results = self.search(query, use_hyde=False, use_multi_query=True)
        print(f"   ê²°ê³¼: {len(multi_results)}ê°œ")

        # 3. HyDE ê²€ìƒ‰
        print("3ï¸âƒ£ HyDE ê²€ìƒ‰")
        hyde_results = self.search(query, use_hyde=True, use_multi_query=False)
        print(f"   ê²°ê³¼: {len(hyde_results)}ê°œ")

        # 4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë©€í‹° ì¿¼ë¦¬ + HyDE)
        print("4ï¸âƒ£ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë©€í‹° ì¿¼ë¦¬ + HyDE)")
        hybrid_results = self.search(query, use_hyde=True, use_multi_query=True)
        print(f"   ê²°ê³¼: {len(hybrid_results)}ê°œ")

        # ê²°ê³¼ ë¶„ì„
        print(f"\nğŸ“Š ê²°ê³¼ ê°œìˆ˜ ë¹„êµ:")
        print(f"   ê¸°ë³¸: {len(basic_results)}, ë©€í‹°ì¿¼ë¦¬: {len(multi_results)}, HyDE: {len(hyde_results)}, í•˜ì´ë¸Œë¦¬ë“œ: {len(hybrid_results)}")

        return {
            'basic': basic_results,
            'multi_query': multi_results,
            'hyde': hyde_results,
            'hybrid': hybrid_results
        }

def test_mock_hyde_system():
    """Mock HyDE ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ Mock HyDE RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("="*80)

    try:
        # Mock HyDE ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        hyde_rag = HyDERAGSystemMock(collection_name="file_chunks")

        # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
        test_questions = [
            "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ê°€ ë³µì¡í•´ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤",
            "ì„œë²„ì— ì ‘ì†í•  ìˆ˜ ì—†ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì‹¶ì–´ìš”",
            "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ìì£¼ ëŠì–´ì§€ëŠ” í˜„ìƒì„ ì¡°ì‚¬í•´ì£¼ì„¸ìš”",
            "API ì‘ë‹µ ì‹œê°„ì´ ë„ˆë¬´ ëŠë ¤ì„œ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤"
        ]

        for i, question in enumerate(test_questions, 1):
            print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ {i}: {question}")
            print("-" * 60)

            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
            results = hyde_rag.search(question)

            if results:
                print(f"âœ… {len(results)}ê°œ ê²°ê³¼ (HyDE + ë©€í‹°ì¿¼ë¦¬ + ê°€ì¤‘ì¹˜)")

                # ìƒìœ„ 3ê°œ ê²°ê³¼ í‘œì‹œ
                for j, result in enumerate(results[:3], 1):
                    score = result.get('score', 0)
                    raw_score = result.get('raw_score', 0)
                    weight = result.get('weight', 1.0)
                    chunk_type = result.get('chunk_type', 'unknown')

                    print(f"  {j}. [{chunk_type.upper()}] (ê°€ì¤‘ì¹˜: {weight:.1f})")
                    print(f"     ì ìˆ˜: {raw_score:.4f} â†’ {score:.4f}")

                    # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                    content = result.get('content', '')
                    preview = content[:100].replace('\n', ' ') + "..."
                    print(f"     ë‚´ìš©: {preview}")

                    # HyDE ì •ë³´
                    metadata = result.get('metadata', {})
                    if metadata.get('query_types'):
                        query_types = set(metadata['query_types'])
                        print(f"     ê²€ìƒ‰ íƒ€ì…: {', '.join(query_types)}")
                    print()

                # ê²€ìƒ‰ ë°©ë²•ë³„ ë¹„êµ (ì²« ë²ˆì§¸ ì§ˆë¬¸ë§Œ)
                if i == 1:
                    hyde_rag.compare_search_methods(question)

            else:
                print("âŒ ê²°ê³¼ ì—†ìŒ")

        return True

    except Exception as e:
        print(f"âŒ Mock HyDE ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_mock_hyde_system()