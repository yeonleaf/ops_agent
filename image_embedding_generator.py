#!/usr/bin/env python3
"""
ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±ê¸°
Azure Vision API ë˜ëŠ” CLIP ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ë²¡í„° ì„ë² ë”©ì„ ìƒì„±
"""

import os
import base64
import io
import logging
from typing import List, Dict, Optional, Union
from PIL import Image
import requests
import json

logger = logging.getLogger(__name__)

class ImageEmbeddingGenerator:
    """ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±ê¸°"""
    
    def __init__(self, use_azure_vision: bool = True):
        """
        ì´ˆê¸°í™”
        
        Args:
            use_azure_vision: Azure Vision API ì‚¬ìš© ì—¬ë¶€ (Falseë©´ CLIP ì‚¬ìš©)
        """
        self.use_azure_vision = use_azure_vision
        
        if use_azure_vision:
            self._init_azure_vision()
        else:
            self._init_clip()
    
    def _init_azure_vision(self):
        """Azure Vision API ì´ˆê¸°í™”"""
        try:
            self.azure_endpoint = os.getenv("AZURE_VISION_ENDPOINT")
            self.azure_key = os.getenv("AZURE_VISION_KEY")
            
            if not self.azure_endpoint or not self.azure_key:
                raise ValueError("Azure Vision API ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤ (AZURE_VISION_ENDPOINT, AZURE_VISION_KEY)")
            
            logger.info("âœ… Azure Vision API ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ Azure Vision API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _init_clip(self):
        """CLIP ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            import torch
            from transformers import CLIPProcessor, CLIPModel
            
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            self.model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(self.device)
            self.processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
            
            logger.info(f"âœ… CLIP ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ (device: {self.device})")
            
        except Exception as e:
            logger.error(f"âŒ CLIP ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def generate_embedding(self, image_data: Union[str, bytes, Image.Image], 
                          image_id: str = None) -> Dict[str, any]:
        """
        ì´ë¯¸ì§€ì—ì„œ ì„ë² ë”© ìƒì„±
        
        Args:
            image_data: ì´ë¯¸ì§€ ë°ì´í„° (íŒŒì¼ ê²½ë¡œ, bytes, PIL Image)
            image_id: ì´ë¯¸ì§€ ì‹ë³„ì
            
        Returns:
            ì„ë² ë”© ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬
            if isinstance(image_data, str):
                # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
                if os.path.exists(image_data):
                    with open(image_data, 'rb') as f:
                        image_bytes = f.read()
                    image = Image.open(io.BytesIO(image_bytes))
                else:
                    # Base64 ë°ì´í„°ì¸ ê²½ìš°
                    if image_data.startswith('data:image'):
                        image_data = image_data.split(',')[1]
                    image_bytes = base64.b64decode(image_data)
                    image = Image.open(io.BytesIO(image_bytes))
            elif isinstance(image_data, bytes):
                image_bytes = image_data
                image = Image.open(io.BytesIO(image_bytes))
            elif isinstance(image_data, Image.Image):
                image = image_data
                # PIL Imageë¥¼ bytesë¡œ ë³€í™˜
                img_byte_arr = io.BytesIO()
                image.save(img_byte_arr, format='PNG')
                image_bytes = img_byte_arr.getvalue()
            else:
                raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ ë°ì´í„° íƒ€ì…ì…ë‹ˆë‹¤")
            
            # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            metadata = {
                'image_id': image_id or f"img_{hash(image_bytes) % 1000000}",
                'width': image.width,
                'height': image.height,
                'format': image.format,
                'mode': image.mode,
                'size_bytes': len(image_bytes)
            }
            
            # ì„ë² ë”© ìƒì„±
            if self.use_azure_vision:
                embedding = self._generate_azure_embedding(image_bytes)
            else:
                embedding = self._generate_clip_embedding(image)
            
            return {
                'embedding': embedding,
                'metadata': metadata,
                'method': 'azure_vision' if self.use_azure_vision else 'clip'
            }
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _generate_azure_embedding(self, image_bytes: bytes) -> List[float]:
        """Azure Vision APIë¡œ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±"""
        try:
            # Azure Vision API v4.0ì˜ ì´ë¯¸ì§€ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
            url = f"{self.azure_endpoint}/vision/v4.0/analyze"
            
            headers = {
                'Ocp-Apim-Subscription-Key': self.azure_key,
                'Content-Type': 'application/octet-stream'
            }
            
            params = {
                'visualFeatures': 'Description,Tags,Objects,Faces,ImageType,Color,Adult',
                'details': 'Landmarks,Celebrities',
                'language': 'en'
            }
            
            response = requests.post(url, headers=headers, params=params, data=image_bytes)
            response.raise_for_status()
            
            result = response.json()
            
            # ì´ë¯¸ì§€ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            description = result.get('description', {}).get('captions', [{}])[0].get('text', '')
            tags = ', '.join([tag['name'] for tag in result.get('tags', [])])
            
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì„ë² ë”© ìƒì„± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• í•„ìš”)
            text_content = f"{description} {tags}".strip()
            
            # OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            return self._generate_text_embedding(text_content)
            
        except Exception as e:
            logger.error(f"âŒ Azure Vision API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            # í´ë°±: ì´ë¯¸ì§€ í•´ì‹œ ê¸°ë°˜ ì„ë² ë”©
            return self._generate_hash_embedding(image_bytes)
    
    def _generate_clip_embedding(self, image: Image.Image) -> List[float]:
        """CLIP ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±"""
        try:
            import torch
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (CLIPì€ 224x224ë¥¼ ê¸°ëŒ€í•¨)
            if image.size != (224, 224):
                image = image.resize((224, 224), Image.Resampling.LANCZOS)
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            inputs = self.processor(images=image, return_tensors="pt").to(self.device)
            
            # ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
            with torch.no_grad():
                image_features = self.model.get_image_features(**inputs)
                # ì •ê·œí™”
                image_features = image_features / image_features.norm(dim=-1, keepdim=True)
            
            return image_features.cpu().numpy().flatten().tolist()
            
        except Exception as e:
            logger.error(f"âŒ CLIP ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: í•´ì‹œ ê¸°ë°˜ ì„ë² ë”©
            return self._generate_hash_embedding(image.tobytes())
    
    def _generate_text_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì„ë² ë”© ìƒì„± (OpenAI API ì‚¬ìš©)"""
        try:
            import openai
            
            # OpenAI API í‚¤ í™•ì¸
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                # Azure OpenAI ì‚¬ìš©
                api_key = os.getenv("AZURE_OPENAI_API_KEY")
                if not api_key:
                    raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            openai.api_key = api_key
            
            # ì„ë² ë”© ìƒì„±
            response = openai.embeddings.create(
                model="text-embedding-ada-002",
                input=text
            )
            
            return response.data[0].embedding
            
        except Exception as e:
            logger.error(f"âŒ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ ì„ë² ë”©
            return self._generate_hash_embedding(text.encode())
    
    def _generate_hash_embedding(self, data: bytes) -> List[float]:
        """í•´ì‹œ ê¸°ë°˜ ê°„ë‹¨í•œ ì„ë² ë”© ìƒì„± (í´ë°±ìš©)"""
        import hashlib
        
        # SHA256 í•´ì‹œ ìƒì„±
        hash_obj = hashlib.sha256(data)
        hash_bytes = hash_obj.digest()
        
        # 1536ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜ (OpenAI ì„ë² ë”©ê³¼ ë™ì¼í•œ ì°¨ì›)
        embedding = []
        for i in range(0, len(hash_bytes), 2):
            if i + 1 < len(hash_bytes):
                # 2ë°”ì´íŠ¸ë¥¼ 0-1 ë²”ìœ„ì˜ floatë¡œ ë³€í™˜
                value = (hash_bytes[i] * 256 + hash_bytes[i + 1]) / 65535.0
                embedding.append(value)
        
        # 1536ì°¨ì›ì´ ë˜ë„ë¡ íŒ¨ë”© ë˜ëŠ” ìë¥´ê¸°
        while len(embedding) < 1536:
            embedding.append(0.0)
        
        return embedding[:1536]
    
    def batch_generate_embeddings(self, image_data_list: List[Union[str, bytes, Image.Image]], 
                                 image_ids: List[str] = None) -> List[Dict[str, any]]:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ì˜ ì„ë² ë”©ì„ ë°°ì¹˜ë¡œ ìƒì„±
        
        Args:
            image_data_list: ì´ë¯¸ì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            image_ids: ì´ë¯¸ì§€ ID ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì„ë² ë”© ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for i, image_data in enumerate(image_data_list):
            try:
                image_id = image_ids[i] if image_ids and i < len(image_ids) else None
                result = self.generate_embedding(image_data, image_id)
                results.append(result)
                
            except Exception as e:
                logger.error(f"âŒ ì´ë¯¸ì§€ {i} ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
                results.append({
                    'embedding': None,
                    'metadata': {'error': str(e)},
                    'method': 'failed'
                })
        
        return results


def test_image_embedding():
    """ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ”§ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸...")
    
    try:
        # ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™”
        generator = ImageEmbeddingGenerator(use_azure_vision=True)
        
        # í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ìƒì„±
        from PIL import Image, ImageDraw, ImageFont
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        img = Image.new('RGB', (200, 100), color='white')
        draw = ImageDraw.Draw(img)
        draw.text((10, 40), "Test Image", fill='black')
        
        # ì„ë² ë”© ìƒì„±
        result = generator.generate_embedding(img, "test_image_1")
        
        logger.info(f"âœ… ì„ë² ë”© ìƒì„± ì„±ê³µ:")
        logger.info(f"   - ì´ë¯¸ì§€ ID: {result['metadata']['image_id']}")
        logger.info(f"   - ì°¨ì›: {len(result['embedding'])}")
        logger.info(f"   - ë°©ë²•: {result['method']}")
        logger.info(f"   - ì´ë¯¸ì§€ í¬ê¸°: {result['metadata']['width']}x{result['metadata']['height']}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    test_image_embedding()
