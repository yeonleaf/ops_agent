#!/usr/bin/env python3
"""
í†µí•© ë©”ì¼ ë¶„ë¥˜ê¸°
4ê°œì˜ ê¸°ì¡´ ë¶„ë¥˜ê¸°ë¥¼ ì¡°í•©í•˜ê³  LMì´ ìµœì¢… íŒë‹¨ì„ ë‚´ë¦¬ëŠ” ì‹œìŠ¤í…œ
"""

import os
import re
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from enum import Enum
import streamlit as st

# ê¸°ì¡´ ë¶„ë¥˜ê¸°ë“¤ ì„í¬íŠ¸
from email_domain_classifier import EmailDomainClassifier, EmailType
from enhanced_content_extractor import EnhancedContentExtractor
from simple_mail_processor import SimpleMailProcessor

# LangChain ì„í¬íŠ¸
try:
    from langchain.schema import HumanMessage, SystemMessage
    from langchain_openai import AzureChatOpenAI
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    st.warning("LangChainì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶„ë¥˜ ë¡œì§ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")

class MailCategory(str, Enum):
    """ë©”ì¼ ì¹´í…Œê³ ë¦¬"""
    WORK_URGENT = "work_urgent"      # ê¸´ê¸‰ ì—…ë¬´
    WORK_NORMAL = "work_normal"       # ì¼ë°˜ ì—…ë¬´
    WORK_LOW = "work_low"            # ë‚®ì€ ìš°ì„ ìˆœìœ„ ì—…ë¬´
    PERSONAL = "personal"             # ê°œì¸ ë©”ì¼
    NOTIFICATION = "notification"     # ì•Œë¦¼/ê³µì§€
    SPAM = "spam"                    # ìŠ¤íŒ¸
    UNKNOWN = "unknown"              # ë¯¸ë¶„ë¥˜

class MailPriority(str, Enum):
    """ë©”ì¼ ìš°ì„ ìˆœìœ„"""
    CRITICAL = "critical"            # ê¸´ê¸‰
    HIGH = "high"                    # ë†’ìŒ
    MEDIUM = "medium"                # ë³´í†µ
    LOW = "low"                      # ë‚®ìŒ

class TicketCreationStatus(str, Enum):
    """í‹°ì¼“ ìƒì„± ìƒíƒœ"""
    SHOULD_CREATE = "should_create"      # í‹°ì¼“ ìƒì„±í•´ì•¼ í•¨
    ALREADY_EXISTS = "already_exists"    # ì´ë¯¸ í‹°ì¼“ì´ ì¡´ì¬í•¨
    NO_TICKET_NEEDED = "no_ticket_needed"  # í‹°ì¼“ ìƒì„± ë¶ˆí•„ìš”

class IntegratedMailClassifier:
    """í†µí•© ë©”ì¼ ë¶„ë¥˜ê¸°"""
    
    def __init__(self, use_lm: bool = True):
        """ì´ˆê¸°í™”"""
        self.use_lm = use_lm and LANGCHAIN_AVAILABLE
        
        # ê¸°ì¡´ ë¶„ë¥˜ê¸°ë“¤ ì´ˆê¸°í™”
        self.domain_classifier = EmailDomainClassifier(
            internal_domains=["@skcc.com", "@sk.com", "@skbroadband.com"],
            external_domains=["@gmail.com", "@naver.com", "@daum.net"]
        )
        self.content_extractor = EnhancedContentExtractor()
        self.mail_processor = SimpleMailProcessor()
        
        # LM ëª¨ë¸ ì´ˆê¸°í™” (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        self.llm = None
        if self.use_lm:
            self._initialize_llm()
        
        # ë¶„ë¥˜ ê²°ê³¼ ìºì‹œ
        self.classification_cache = {}
    
    def _initialize_llm(self):
        """LLM ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # Azure OpenAI ì„¤ì • í™•ì¸
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            azure_api_key = os.getenv("AZURE_OPENAI_API_KEY")
            azure_deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
            azure_api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-10-21")
            
            # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
            st.error(f"ğŸ”§ Azure OpenAI ì„¤ì • í™•ì¸:")
            st.error(f"   - Endpoint: {azure_endpoint}")
            st.error(f"   - API Key: {'ì„¤ì •ë¨' if azure_api_key else 'ì„¤ì • ì•ˆë¨'}")
            st.error(f"   - Deployment: {azure_deployment}")
            st.error(f"   - API Version: {azure_api_version}")
            
            if all([azure_endpoint, azure_api_key, azure_deployment]):
                # í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (LangChainì´ ìë™ìœ¼ë¡œ ì½ë„ë¡)
                os.environ["OPENAI_API_KEY"] = azure_api_key
                os.environ["OPENAI_API_BASE"] = azure_endpoint
                os.environ["OPENAI_API_VERSION"] = azure_api_version
                
                # Azure OpenAI ì „ìš© í™˜ê²½ ë³€ìˆ˜ë„ ì„¤ì •
                os.environ["AZURE_OPENAI_API_KEY"] = azure_api_key
                os.environ["AZURE_OPENAI_ENDPOINT"] = azure_endpoint
                os.environ["AZURE_OPENAI_API_VERSION"] = azure_api_version
                
                st.error(f"   ğŸ”§ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ:")
                st.error(f"      - OPENAI_API_KEY: {'ì„¤ì •ë¨' if os.getenv('OPENAI_API_KEY') else 'ì„¤ì • ì•ˆë¨'}")
                st.error(f"      - OPENAI_API_BASE: {'ì„¤ì •ë¨' if os.getenv('OPENAI_API_BASE') else 'ì„¤ì • ì•ˆë¨'}")
                st.error(f"      - OPENAI_API_VERSION: {'ì„¤ì •ë¨' if os.getenv('OPENAI_API_VERSION') else 'ì„¤ì • ì•ˆë¨'}")
                
                # URL êµ¬ì„± í™•ì¸
                st.error(f"   ğŸŒ URL êµ¬ì„± í™•ì¸:")
                st.error(f"      - ì›ë³¸ Endpoint: {azure_endpoint}")
                st.error(f"      - Deployment: {azure_deployment}")
                st.error(f"      - ì˜ˆìƒ API URL: {azure_endpoint}/openai/deployments/{azure_deployment}/chat/completions?api-version={azure_api_version}")
                
                # URL ì •ë¦¬ (trailing slash ì œê±°)
                clean_endpoint = azure_endpoint.rstrip('/')
                st.error(f"      - ì •ë¦¬ëœ Endpoint: {clean_endpoint}")
                st.error(f"      - ì •ë¦¬ëœ API URL: {clean_endpoint}/openai/deployments/{azure_deployment}/chat/completions?api-version={azure_api_version}")
                
                try:
                    # AzureChatOpenAI ì‚¬ìš© (Azure OpenAI APIì— ìµœì í™”)
                    clean_endpoint = azure_endpoint.rstrip('/')
                    self.llm = AzureChatOpenAI(
                        deployment_name=azure_deployment,
                        azure_endpoint=clean_endpoint,
                        api_key=azure_api_key,
                        api_version=azure_api_version,
                        temperature=0.1
                    )
                    st.success("âœ… LLM ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ (AzureChatOpenAI)")
                    self.use_lm = True
                except Exception as e:
                    st.error(f"âŒ LLM ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                    st.error("ğŸ’¡ í•´ê²° ë°©ë²•:")
                    st.error("   1. Azure OpenAI ë¦¬ì†ŒìŠ¤ê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
                    st.error("   2. Deployment ì´ë¦„ì´ ì •í™•í•œì§€ í™•ì¸")
                    st.error("   3. Endpoint URLì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
                    st.error("   4. API í‚¤ê°€ ìœ íš¨í•œì§€ í™•ì¸")
                    self.use_lm = False
                    self.llm = None
            else:
                st.warning("âš ï¸ Azure OpenAI ì„¤ì •ì´ ë¶ˆì™„ì „í•˜ì—¬ LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                self.use_lm = False
                self.llm = None
                
        except Exception as e:
            st.error(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.use_lm = False
            self.llm = None
    
    def is_llm_available(self) -> bool:
        """LLM ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return self.use_lm and self.llm is not None
    
    def get_llm_status(self) -> Dict[str, Any]:
        """LLM ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            'use_lm': self.use_lm,
            'llm_available': self.llm is not None,
            'llm_type': type(self.llm).__name__ if self.llm else None
        }
    
    def should_create_ticket(self, email_data: Dict[str, Any], user_query: str = "") -> Tuple[TicketCreationStatus, str, Dict[str, Any]]:
        """
        LMì„ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ ë©”ì¼ì´ í‹°ì¼“ ìƒì„± ëŒ€ìƒì¸ì§€ íŒë‹¨
        
        Args:
            email_data: ë©”ì¼ ë°ì´í„°
            user_query: ì‚¬ìš©ì ì¿¼ë¦¬
            
        Returns:
            (í‹°ì¼“ìƒì„±ìƒíƒœ, ì´ìœ , ì¶”ê°€ì •ë³´) íŠœí”Œ
        """
        if not self.is_llm_available():
            st.error("âŒ LMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Azure OpenAI ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            # LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ê·œì¹™ ì ìš©
            return self._should_create_ticket_fallback(email_data, user_query)
        
        try:
            st.info(f"ğŸ§  LM ê¸°ë°˜ í‹°ì¼“ ìƒì„± íŒë‹¨ ì‹œì‘:")
            st.info(f"   - ì‚¬ìš©ì ì¿¼ë¦¬: '{user_query}'")
            st.info(f"   - ë©”ì¼ ì œëª©: '{email_data.get('subject', '')}'")
            
            # LM í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ê°œë³„ ë©”ì¼ ë‚´ìš© ê¸°ë°˜ íŒë‹¨)
            system_prompt = """ë‹¹ì‹ ì€ ë©”ì¼ ê´€ë¦¬ ì‹œìŠ¤í…œì˜ í‹°ì¼“ ìƒì„± íŒë‹¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ê°œë³„ ë©”ì¼ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì—…ë¬´ ê´€ë ¨ í‹°ì¼“ ìƒì„±ì´ í•„ìš”í•œì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

í‹°ì¼“ ìƒì„±ì´ í•„ìš”í•œ ë©”ì¼:
- ì—…ë¬´ ê´€ë ¨ ìš”ì²­ì´ë‚˜ ì§€ì‹œì‚¬í•­
- í”„ë¡œì íŠ¸ ê´€ë ¨ ì´ìŠˆë‚˜ ì‘ì—… ìš”ì²­
- ë²„ê·¸ ë¦¬í¬íŠ¸ë‚˜ ê¸°ìˆ ì  ë¬¸ì œ
- ìŠ¹ì¸ì´ í•„ìš”í•œ ì—…ë¬´ í”„ë¡œì„¸ìŠ¤
- íšŒì˜ ìš”ì²­ì´ë‚˜ ì¼ì • ì¡°ìœ¨
- ê³ ê° ì§€ì› ìš”ì²­
- ì‹œìŠ¤í…œ ì¥ì• ë‚˜ ë¬¸ì œ ë³´ê³ 
- ì—…ë¬´ í˜‘ì—…ì´ë‚˜ ë¦¬ë·° ìš”ì²­

í‹°ì¼“ ìƒì„±ì´ ë¶ˆí•„ìš”í•œ ë©”ì¼:
- ê°œì¸ì ì¸ ì•ˆë¶€ë‚˜ ì¸ì‚¬
- ë‹¨ìˆœ ì •ë³´ ê³µìœ  (ë‰´ìŠ¤ë ˆí„°, ê³µì§€ì‚¬í•­)
- ìŠ¤íŒ¸ì´ë‚˜ ê´‘ê³  ë©”ì¼
- ìë™ ì•Œë¦¼ ë©”ì¼ (ë‹¨ìˆœ í™•ì¸ìš©)
- ê°œì¸ì ì¸ ëŒ€í™”ë‚˜ ì¡ë‹´

íŒë‹¨ ê¸°ì¤€:
1. ë©”ì¼ ë‚´ìš©ì´ ì—…ë¬´ì™€ ê´€ë ¨ì´ ìˆëŠ”ê°€?
2. ì•¡ì…˜ì´ë‚˜ ì‘ë‹µì´ í•„ìš”í•œ ë‚´ìš©ì¸ê°€?
3. ì¶”ì í•˜ê³  ê´€ë¦¬í•´ì•¼ í•  ì‘ì—…ì¸ê°€?

ì‚¬ìš©ìê°€ "í‹°ì¼“ ëª©ë¡", "ì—…ë¬´ ë©”ì¼" ë“±ì„ ìš”ì²­í–ˆë‹¤ë©´, ì—…ë¬´ ê´€ë ¨ ë©”ì¼ì€ í‹°ì¼“ìœ¼ë¡œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{
    "should_create_ticket": true/false,
    "reasoning": "íŒë‹¨ ê·¼ê±°ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…",
    "confidence": 0.0-1.0,
    "detected_intent": "ticket_creation|mail_query|information_request|other",
    "ticket_type": "jira|general|project|issue|other"
}"""

            user_prompt = f"""ë©”ì¼ ì •ë³´:
ì œëª©: {email_data.get('subject', '')}
ë°œì‹ ì: {email_data.get('sender', '')}
ë‚´ìš©: {email_data.get('body', '')[:500]}...

ì‚¬ìš©ì ìš”ì²­: "{user_query}"

ì´ ë©”ì¼ ë‚´ìš©ì´ ì—…ë¬´ ê´€ë ¨ì´ê³  í‹°ì¼“ ìƒì„±ì´ í•„ìš”í•œ ë‚´ìš©ì¸ê°€ìš”?
ì‚¬ìš©ìê°€ í‹°ì¼“/ì—…ë¬´ ê´€ë ¨ ìš”ì²­ì„ í–ˆê³ , ì´ ë©”ì¼ì´ ì—…ë¬´ ê´€ë ¨ì´ë¼ë©´ í‹°ì¼“ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤."""
            
            # LLM í˜¸ì¶œ
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
            current_response = ""
            final_response = None
            
            for chunk in self.llm.stream(messages):
                if hasattr(chunk, 'content'):
                    current_response += chunk.content
                    final_response = chunk
            
            response_content = final_response.content if final_response else ""
            
            # JSON íŒŒì‹±
            import json
            try:
                lm_result = json.loads(response_content)
                
                should_create = lm_result.get('should_create_ticket', False)
                reasoning = lm_result.get('reasoning', '')
                confidence = lm_result.get('confidence', 0.5)
                detected_intent = lm_result.get('detected_intent', 'other')
                ticket_type = lm_result.get('ticket_type', 'general')
                
                st.success(f"   ğŸ§  LM íŒë‹¨ ê²°ê³¼:")
                st.success(f"      - í‹°ì¼“ ìƒì„± í•„ìš”: {should_create}")
                st.success(f"      - íŒë‹¨ ê·¼ê±°: {reasoning}")
                st.success(f"      - ì‹ ë¢°ë„: {confidence}")
                st.success(f"      - ê°ì§€ëœ ì˜ë„: {detected_intent}")
                st.success(f"      - í‹°ì¼“ íƒ€ì…: {ticket_type}")
                
                if should_create:
                    # ğŸ¯ LLMì´ "í‹°ì¼“ ìƒì„± í•„ìš”"ë¼ê³  íŒë‹¨í•œ ê²½ìš°, LLM íŒë‹¨ì„ ì ˆëŒ€ì ìœ¼ë¡œ ìš°ì„ ì‹œ
                    # í‚¤ì›Œë“œ ê²€ì¦ì€ ë³´ì¡° ì •ë³´ë¡œë§Œ ì‚¬ìš© (íŒë‹¨ ê¸°ì¤€ì´ ì•„ë‹˜)
                    email_has_ticket_keywords = self._check_ticket_keywords_in_email(email_data)
                    
                    # Vector DB í™•ì¸ (ì¤‘ë³µ í‹°ì¼“ ë°©ì§€ìš©)
                    email_id_exists = self._check_email_id_in_vector_db(email_data.get('id', ''))
                    
                    if email_id_exists:
                        return TicketCreationStatus.ALREADY_EXISTS, f"LM íŒë‹¨: {reasoning} (ì´ë¯¸ Vector DBì— ì¡´ì¬)", {
                            'lm_reasoning': reasoning,
                            'confidence': confidence,
                            'detected_intent': detected_intent,
                            'ticket_type': ticket_type,
                            'email_keywords': email_has_ticket_keywords,
                            'vector_db_status': 'exists'
                        }
                    else:
                        # âœ… LLM íŒë‹¨ì„ ì‹ ë¢°í•˜ê³  í‹°ì¼“ ìƒì„± (í‚¤ì›Œë“œ ê²€ì¦ ê²°ê³¼ì™€ ë¬´ê´€)
                        return TicketCreationStatus.SHOULD_CREATE, f"LM íŒë‹¨: {reasoning}", {
                            'lm_reasoning': reasoning,
                            'confidence': confidence,
                            'detected_intent': detected_intent,
                            'ticket_type': ticket_type,
                            'email_keywords': email_has_ticket_keywords,  # ë³´ì¡° ì •ë³´
                            'vector_db_status': 'not_found'
                        }
                else:
                    return TicketCreationStatus.NO_TICKET_NEEDED, f"LM íŒë‹¨: {reasoning}", {
                        'lm_reasoning': reasoning,
                        'confidence': confidence,
                        'detected_intent': detected_intent,
                        'ticket_type': ticket_type
                    }
                
            except json.JSONDecodeError:
                st.error(f"   âŒ LM ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨")
                return self._should_create_ticket_fallback(email_data, user_query)
                
        except Exception as e:
            st.error(f"   âŒ LM í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return self._should_create_ticket_fallback(email_data, user_query)
    
    def _should_create_ticket_fallback(self, email_data: Dict[str, Any], user_query: str = "") -> Tuple[TicketCreationStatus, str, Dict[str, Any]]:
        """LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì„ ë•Œì˜ fallback ë¡œì§"""
        # ê²½ê³  ë©”ì‹œì§€ëŠ” í•œ ë²ˆë§Œ í‘œì‹œ (ì²« ë²ˆì§¸ í˜¸ì¶œ ì‹œì—ë§Œ)
        if not hasattr(self, '_fallback_warning_shown'):
            st.warning("âš ï¸ LMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ê·œì¹™ì„ ì ìš©í•©ë‹ˆë‹¤.")
            self._fallback_warning_shown = True
        
        # 1ë‹¨ê³„: ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ëª…ì‹œì  í‹°ì¼“ ìƒì„± ì˜ë„ í™•ì¸
        query_lower = user_query.lower()
        explicit_ticket_keywords = ['í‹°ì¼“', 'ì¼ê°', 'ì‘ì—…', 'í• ì¼', 'ì¼ì •', 'ìŠ¤ì¼€ì¤„', 'í”„ë¡œì íŠ¸', 'ì´ìŠˆ', 'ë²„ê·¸']
        
        has_explicit_intent = any(keyword in query_lower for keyword in explicit_ticket_keywords)
        
        if not has_explicit_intent:
            # ì •ë³´ ë©”ì‹œì§€ë„ í•œ ë²ˆë§Œ í‘œì‹œ
            if not hasattr(self, '_no_intent_info_shown'):
                st.info("â„¹ï¸ ì‚¬ìš©ì ì¿¼ë¦¬ì— ëª…ì‹œì  í‹°ì¼“ ìƒì„± ì˜ë„ê°€ ì—†ìŠµë‹ˆë‹¤.")
                self._no_intent_info_shown = True
                
            return TicketCreationStatus.NO_TICKET_NEEDED, "ê¸°ë³¸ ê·œì¹™: ëª…ì‹œì  í‹°ì¼“ ìƒì„± ì˜ë„ ì—†ìŒ", {
                'fallback_reason': 'LM ì‚¬ìš© ë¶ˆê°€ + ëª…ì‹œì  ì˜ë„ ì—†ìŒ',
                'query_analysis': 'ë‹¨ìˆœ ë©”ì¼ ì¡°íšŒë¡œ íŒë‹¨'
            }
        
        # 2ë‹¨ê³„: ì‚¬ìš©ìê°€ ëª…ì‹œì  í‹°ì¼“ ìƒì„± ì˜ë„ë¥¼ ë³´ì˜€ë‹¤ë©´, í‚¤ì›Œë“œ ê²€ì¦ê³¼ ë¬´ê´€í•˜ê²Œ í‹°ì¼“ ìƒì„±
        # (LLM ìš°ì„ ì‹œ ì›ì¹™ê³¼ ì¼ì¹˜)
        email_has_keywords = self._check_ticket_keywords_in_email(email_data)
        
        # ì‚¬ìš©ìê°€ ëª…ì‹œì  ì˜ë„ë¥¼ ë³´ì˜€ë‹¤ë©´, í‚¤ì›Œë“œ ê²€ì¦ ê²°ê³¼ì™€ ë¬´ê´€í•˜ê²Œ í‹°ì¼“ ìƒì„±
        return TicketCreationStatus.SHOULD_CREATE, "ê¸°ë³¸ ê·œì¹™: ëª…ì‹œì  í‹°ì¼“ ìƒì„± ì˜ë„ ë°œê²¬ (LLM ìš°ì„ ì‹œ ì›ì¹™)", {
            'fallback_reason': 'LM ì‚¬ìš© ë¶ˆê°€ + ëª…ì‹œì  ì˜ë„',
            'explicit_intent': True,
            'email_keywords': email_has_keywords,  # ë³´ì¡° ì •ë³´
            'llm_priority_principle': 'ì‚¬ìš©ì ì˜ë„ ìš°ì„ ì‹œ'
        }
    
    def _check_ticket_keywords_in_email(self, email_data: Dict[str, Any]) -> List[str]:
        """ë©”ì¼ ë‚´ìš©ì—ì„œ í‹°ì¼“ í‚¤ì›Œë“œ í™•ì¸ (LM íŒë‹¨ì„ ìœ„í•œ ë³´ì¡° ì •ë³´)"""
        subject = email_data.get('subject', '')
        body = email_data.get('body', '')
        
        found_keywords = []
        content_lower = (subject + " " + body).lower()
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ (LM íŒë‹¨ì„ ìœ„í•œ ì°¸ê³ ìš©)
        simple_keywords = [
            # ì˜ì–´ í‚¤ì›Œë“œ
            'urgent', 'important', 'deadline', 'meeting', 'project', 'task',
            'issue', 'bug', 'error', 'request', 'approve', 'review', 'feedback',
            'action', 'required', 'schedule', 'appointment', 'conference', 'call',
            'report', 'document', 'proposal', 'contract', 'invoice', 'payment',
            'support', 'help', 'problem', 'solution', 'update', 'status',
            
            # í•œêµ­ì–´ í‚¤ì›Œë“œ (ë³´ì¡° ì •ë³´ìš©)
            'ì„œë²„', 'ì ‘ì†', 'ë¶ˆê°€', 'ê¸°ëŠ¥', 'ì œì•ˆ', 'ìë£Œ', 'ìš”ì²­', 'í”„ë¡œì íŠ¸',
            'ë¬¸ì œ', 'ì˜¤ë¥˜', 'ë²„ê·¸', 'ê°œë°œ', 'ì‘ì—…', 'ì¼ì •', 'íšŒì˜', 'ìŠ¹ì¸',
            'ê²€í† ', 'í”¼ë“œë°±', 'ì§€ì›', 'ë„ì›€', 'í•´ê²°', 'ì—…ë°ì´íŠ¸', 'ìƒíƒœ',
            'ì‹œìŠ¤í…œ', 'ì¥ì• ', 'ë³µêµ¬', 'ì„¤ì •', 'ë³€ê²½', 'ìˆ˜ì •', 'ê°œì„ ',
            'í…ŒìŠ¤íŠ¸', 'ë°°í¬', 'ìš´ì˜', 'ëª¨ë‹ˆí„°ë§', 'ë¡œê·¸', 'ë°±ì—…', 'ë³´ì•ˆ'
        ]
        
        for keyword in simple_keywords:
            if keyword in content_lower:
                found_keywords.append(keyword)
        
        return found_keywords
    
    def _generate_labels_for_ticket(self, email_data: Dict[str, Any], classification: Dict[str, Any]) -> List[str]:
        """í‹°ì¼“ìš© ë ˆì´ë¸” ìƒì„±"""
        try:
            labels = []
            
            # 1. ë©”ì¼ ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ê¸°ë°˜ ë ˆì´ë¸”
            subject = email_data.get('subject', '').lower()
            body = email_data.get('body', '').lower()
            content = f"{subject} {body}"
            
            # ìš°ì„ ìˆœìœ„ë³„ ë ˆì´ë¸” ë§¤í•‘
            priority_labels = {
                'urgent': ['ê¸´ê¸‰', 'ê¸´ê¸‰ì‚¬í•­'],
                'high': ['ë†’ìŒ', 'ì¤‘ìš”'],
                'medium': ['ë³´í†µ', 'ì¼ë°˜'],
                'low': ['ë‚®ìŒ', 'ë‚®ì€ìš°ì„ ìˆœìœ„']
            }
            
            # ìš°ì„ ìˆœìœ„ ë ˆì´ë¸” ì¶”ê°€
            priority = classification.get('priority', 'medium').lower()
            if priority in priority_labels:
                labels.extend(priority_labels[priority])
            
            # 2. ë©”ì¼ íƒ€ì…ë³„ ë ˆì´ë¸”
            ticket_type = classification.get('ticket_type', 'general')
            type_labels = {
                'bug_fix': ['ë²„ê·¸', 'ì˜¤ë¥˜', 'ìˆ˜ì •'],
                'feature': ['ê¸°ëŠ¥', 'ê°œë°œ', 'ì‹ ê·œ'],
                'improvement': ['ê°œì„ ', 'í–¥ìƒ'],
                'task': ['ì‘ì—…', 'ì¼ë°˜'],
                'issue': ['ì´ìŠˆ', 'ë¬¸ì œ'],
                'project': ['í”„ë¡œì íŠ¸', 'ê³„íš']
            }
            
            if ticket_type in type_labels:
                labels.extend(type_labels[ticket_type])
            
            # 3. ì½˜í…ì¸  ê¸°ë°˜ ë ˆì´ë¸”
            content_keywords = {
                'ì„œë²„': ['ì„œë²„', 'ì‹œìŠ¤í…œ'],
                'ì ‘ì†': ['ì ‘ì†', 'ì—°ê²°', 'ë„¤íŠ¸ì›Œí¬'],
                'ë¶ˆê°€': ['ì¥ì• ', 'ì˜¤ë¥˜', 'ë¬¸ì œ'],
                'ê¸°ëŠ¥': ['ê¸°ëŠ¥', 'ê°œë°œ', 'ìš”ì²­'],
                'ì œì•ˆ': ['ì œì•ˆ', 'ì•„ì´ë””ì–´', 'ê°œì„ '],
                'ìë£Œ': ['ìë£Œ', 'ë¬¸ì„œ', 'ì •ë³´'],
                'ìš”ì²­': ['ìš”ì²­', 'ìš”êµ¬ì‚¬í•­', 'í•„ìš”'],
                'í”„ë¡œì íŠ¸': ['í”„ë¡œì íŠ¸', 'ê³„íš', 'ì¼ì •'],
                'íšŒì˜': ['íšŒì˜', 'ë¯¸íŒ…', 'ì¼ì •'],
                'ìŠ¹ì¸': ['ìŠ¹ì¸', 'ê²€í† ', 'ê²°ì¬'],
                'ì§€ì›': ['ì§€ì›', 'ë„ì›€', 'ë¬¸ì˜']
            }
            
            for keyword, label_list in content_keywords.items():
                if keyword in content:
                    labels.extend(label_list)
                    break  # ì²« ë²ˆì§¸ ë§¤ì¹­ë§Œ ì‚¬ìš©
            
            # 4. ë„ë©”ì¸ ê¸°ë°˜ ë ˆì´ë¸”
            domain_type = classification.get('domain_type', 'external')
            if domain_type == 'internal':
                labels.append('ë‚´ë¶€')
            else:
                labels.append('ì™¸ë¶€')
            
            # 5. ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
            unique_labels = list(set(labels))
            
            # 6. ê¸°ë³¸ ë ˆì´ë¸”ì´ ì—†ìœ¼ë©´ ì¶”ê°€
            if not unique_labels:
                unique_labels = ['ì¼ë°˜', 'ì—…ë¬´']
            
            return unique_labels[:5]  # ìµœëŒ€ 5ê°œ ë ˆì´ë¸”
            
        except Exception as e:
            st.warning(f"ë ˆì´ë¸” ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return ['ì¼ë°˜', 'ì—…ë¬´']  # ê¸°ë³¸ê°’
    
    def _check_email_id_in_vector_db(self, email_id: str) -> bool:
        """Vector DBì—ì„œ ë©”ì¼ ID ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        try:
            # Vector DB ì—°ê²° ë° ê²€ìƒ‰ ë¡œì§
            # í˜„ì¬ëŠ” ê°„ë‹¨í•œ êµ¬í˜„ìœ¼ë¡œ ëŒ€ì²´
            # TODO: ì‹¤ì œ Vector DB ì—°ë™ êµ¬í˜„
            
            # ì„ì‹œë¡œ í•­ìƒ False ë°˜í™˜ (Vector DBì— ì—†ë‹¤ê³  ê°€ì •)
            return False
            
        except Exception as e:
            st.warning(f"Vector DB í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def create_ticket_from_email(self, email_data: Dict[str, Any], user_query: str = "") -> Dict[str, Any]:
        """
        ë©”ì¼ì„ í‹°ì¼“ìœ¼ë¡œ ë³€í™˜ (ë³€í™˜ â†’ ì„ë² ë”© â†’ í‹°ì¼“ ìƒì„±)
        
        Args:
            email_data: ë©”ì¼ ë°ì´í„°
            user_query: ì‚¬ìš©ì ì¿¼ë¦¬
            
        Returns:
            í‹°ì¼“ ë°ì´í„°
        """
        try:
            # 1ë‹¨ê³„: ë©”ì¼ ë¶„ë¥˜
            classification = self.classify_email(email_data)
            
            # 2ë‹¨ê³„: ì„ë² ë”© ìƒì„±
            embedding = self._create_embedding(email_data, classification)
            
            # 3ë‹¨ê³„: VectorDBì— ë©”ì¼ ì €ì¥ (pending ìƒíƒœ)
            try:
                from vector_db_models import VectorDBManager, Mail
                vector_db = VectorDBManager()
                
                mail = Mail(
                    message_id=email_data.get('id', ''),
                    original_content=email_data.get('body', ''),
                    refined_content=email_data.get('body', '')[:500],
                    sender=email_data.get('sender', ''),
                    status='pending',  # í‹°ì¼“ ìƒì„± ì‹œ pending ìƒíƒœ
                    subject=email_data.get('subject', ''),
                    received_datetime=email_data.get('received_date', datetime.now()).isoformat() if hasattr(email_data.get('received_date', datetime.now()), 'isoformat') else datetime.now().isoformat(),
                    content_type='text',
                    has_attachment=False,
                    extraction_method='ticket_creation',
                    content_summary=email_data.get('body', '')[:200],
                    key_points=[],
                    created_at=datetime.now().isoformat()
                )
                
                vector_db.save_mail(mail)
                st.success(f"âœ… VectorDBì— ë©”ì¼ ì €ì¥ ì™„ë£Œ (ìƒíƒœ: pending)")
                
            except Exception as e:
                st.error(f"VectorDB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            
            # 4ë‹¨ê³„: í‹°ì¼“ ìƒì„±
            ticket = self._create_ticket_data(email_data, classification, embedding, user_query)
            
            return ticket
            
        except Exception as e:
            st.error(f"í‹°ì¼“ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def _create_embedding(self, email_data: Dict[str, Any], classification: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”ì¼ ë‚´ìš©ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        try:
            # ë©”ì¼ ë‚´ìš©ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
            # í˜„ì¬ëŠ” ê°„ë‹¨í•œ êµ¬í˜„ìœ¼ë¡œ ëŒ€ì²´
            # TODO: ì‹¤ì œ ì„ë² ë”© ëª¨ë¸ ì—°ë™ êµ¬í˜„
            
            content = f"{email_data.get('subject', '')} {email_data.get('body', '')}"
            
            # ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ ì„ë² ë”© (ì‹¤ì œë¡œëŠ” OpenAI Embedding API ë“± ì‚¬ìš©)
            import hashlib
            embedding_hash = hashlib.md5(content.encode()).hexdigest()
            
            return {
                'content': content,
                'embedding_hash': embedding_hash,
                'vector_dimension': 128,  # ì„ì‹œ ê°’
                'created_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            st.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def _create_ticket_data(self, email_data: Dict[str, Any], classification: Dict[str, Any], embedding: Dict[str, Any], user_query: str) -> Dict[str, Any]:
        """í‹°ì¼“ ë°ì´í„° ìƒì„±"""
        try:
            # ê¸°ë³¸ í‹°ì¼“ ì •ë³´
            ticket = {
                'ticket_id': f"T{datetime.now().strftime('%Y%m%d%H%M%S')}",
                'original_message_id': email_data.get('id', ''),  # ë©”ì¼ ID ì¶”ê°€
                'title': email_data.get('subject', 'ì œëª© ì—†ìŒ'),
                'description': email_data.get('body', 'ë‚´ìš© ì—†ìŒ'),
                'status': 'pending',
                'priority': classification.get('priority', 'medium'),
                'type': 'email_ticket',
                'reporter': email_data.get('sender', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                'labels': self._generate_labels_for_ticket(email_data, classification),  # ë ˆì´ë¸” ìƒì„±
                'created_at': datetime.now().isoformat(),
                'email_data': {
                    'id': email_data.get('id'),
                    'sender': email_data.get('sender'),
                    'subject': email_data.get('subject'),
                    'received_date': email_data.get('received_date'),
                    'message_id': email_data.get('message_id')
                },
                'classification': classification,
                'embedding': embedding,
                'user_query': user_query,
                'ticket_creation_method': 'ai_classifier_workflow'
            }
            
            return ticket
            
        except Exception as e:
            st.error(f"í‹°ì¼“ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def classify_email(self, email_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ë©”ì¼ì„ í†µí•© ë¶„ë¥˜
        
        Args:
            email_data: ë©”ì¼ ë°ì´í„° (EmailMessage í˜•ì‹)
            
        Returns:
            ë¶„ë¥˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ìºì‹œ í™•ì¸
        email_id = email_data.get('id', '')
        if email_id in self.classification_cache:
            return self.classification_cache[email_id]
        
        # 1ë‹¨ê³„: ë„ë©”ì¸ ë¶„ë¥˜
        domain_result = self._classify_by_domain(email_data)
        
        # 2ë‹¨ê³„: ì½˜í…ì¸  ë¶„ì„
        content_result = self._analyze_content(email_data)
        
        # 3ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ë¶„ì„
        metadata_result = self._analyze_metadata(email_data)
        
        # 4ë‹¨ê³„: í†µí•© ë¶„ì„
        combined_result = self._combine_classifications(
            domain_result, content_result, metadata_result
        )
        
        # 5ë‹¨ê³„: LM ìµœì¢… íŒë‹¨ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if self.use_lm and self.is_llm_available():
            final_result = self._get_lm_final_decision(
                email_data, combined_result
            )
        else:
            if self.use_lm:
                st.warning("âš ï¸ LMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            final_result = combined_result
        
        # ê²°ê³¼ ìºì‹œì— ì €ì¥
        self.classification_cache[email_id] = final_result
        
        return final_result
    
    def _classify_by_domain(self, email_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë„ë©”ì¸ ê¸°ë°˜ ë¶„ë¥˜"""
        sender = email_data.get('sender', '')
        
        try:
            should_create, email_type, domain = self.domain_classifier.should_create_ticket(
                sender, interactive=False
            )
            
            return {
                'domain_type': email_type,
                'domain': domain,
                'should_create_ticket': should_create,
                'is_internal': email_type == 'internal',
                'confidence': 0.9 if domain else 0.5
            }
        except Exception as e:
            return {
                'domain_type': 'unknown',
                'domain': '',
                'should_create_ticket': True,
                'is_internal': False,
                'confidence': 0.3
            }
    
    def _analyze_content(self, email_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì½˜í…ì¸  ë¶„ì„"""
        body = email_data.get('body', '')
        subject = email_data.get('subject', '')
        
        try:
            # ì½˜í…ì¸  ì¶”ì¶œ
            if body:
                extracted = self.content_extractor.extract_clean_content(body, 'text')
                key_points = extracted.get('key_points', [])
                summary = extracted.get('summary', '')
            else:
                key_points = []
                summary = ''
            
            # ì—…ë¬´ ê´€ë ¨ í‚¤ì›Œë“œ ë¶„ì„
            work_keywords = self._detect_work_keywords(subject + " " + summary)
            
            # ê¸´ê¸‰ì„± ë¶„ì„
            urgency_score = self._analyze_urgency(subject + " " + summary)
            
            return {
                'key_points': key_points,
                'summary': summary,
                'work_keywords': work_keywords,
                'urgency_score': urgency_score,
                'has_work_content': len(work_keywords) > 0,
                'confidence': 0.8
            }
        except Exception as e:
            return {
                'key_points': [],
                'summary': '',
                'work_keywords': [],
                'urgency_score': 0.0,
                'has_work_content': False,
                'confidence': 0.3
            }
    
    def _analyze_metadata(self, email_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ë¶„ì„"""
        try:
            # ì¤‘ìš”ë„ ë¶„ì„
            priority = email_data.get('priority', 'normal')
            priority_map = {
                'high': 0.8,
                'normal': 0.5,
                'low': 0.2
            }
            priority_score = priority_map.get(priority, 0.5)
            
            # ì²¨ë¶€íŒŒì¼ ë¶„ì„
            has_attachments = email_data.get('has_attachments', False)
            attachment_count = email_data.get('attachment_count', 0)
            
            # ì½ìŒ ìƒíƒœ
            is_read = email_data.get('is_read', False)
            
            # ë‚ ì§œ ë¶„ì„
            received_date = email_data.get('received_date')
            if received_date:
                if isinstance(received_date, str):
                    try:
                        received_date = datetime.fromisoformat(received_date.replace('Z', '+00:00'))
                    except:
                        received_date = datetime.now()
                
                # ìµœê·¼ ë©”ì¼ì¸ì§€ í™•ì¸ (24ì‹œê°„ ì´ë‚´)
                time_diff = datetime.now() - received_date
                is_recent = time_diff.total_seconds() < 24 * 3600
            else:
                is_recent = False
            
            return {
                'priority_score': priority_score,
                'has_attachments': has_attachments,
                'attachment_count': attachment_count,
                'is_read': is_read,
                'is_recent': is_recent,
                'confidence': 0.9
            }
        except Exception as e:
            return {
                'priority_score': 0.5,
                'has_attachments': False,
                'attachment_count': 0,
                'is_read': False,
                'is_recent': False,
                'confidence': 0.3
            }
    
    def _combine_classifications(self, domain_result: Dict, content_result: Dict, metadata_result: Dict) -> Dict[str, Any]:
        """ë¶„ë¥˜ ê²°ê³¼ í†µí•©"""
        try:
            # ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ ê²°ì •
            if domain_result.get('is_internal', False):
                category = MailCategory.PERSONAL
                priority = MailPriority.LOW
            elif content_result.get('has_work_content', False):
                urgency = content_result.get('urgency_score', 0.0)
                if urgency > 0.7:
                    category = MailCategory.WORK_URGENT
                    priority = MailPriority.CRITICAL
                elif urgency > 0.4:
                    category = MailCategory.WORK_NORMAL
                    priority = MailPriority.HIGH
                else:
                    category = MailCategory.WORK_LOW
                    priority = MailPriority.MEDIUM
            else:
                category = MailCategory.NOTIFICATION
                priority = MailPriority.LOW
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = (
                domain_result.get('confidence', 0.5) * 0.3 +
                content_result.get('confidence', 0.5) * 0.4 +
                metadata_result.get('confidence', 0.5) * 0.3
            )
            
            return {
                'category': category.value,
                'priority': priority.value,
                'confidence': confidence,
                'domain_result': domain_result,
                'content_result': content_result,
                'metadata_result': metadata_result,
                'classification_method': 'rule_based'
            }
        except Exception as e:
            return {
                'category': MailCategory.UNKNOWN.value,
                'priority': MailPriority.MEDIUM.value,
                'confidence': 0.3,
                'classification_method': 'fallback',
                'error': str(e)
            }
    
    def _get_lm_final_decision(self, email_data: Dict[str, Any], combined_result: Dict[str, Any]) -> Dict[str, Any]:
        """LMì„ ì‚¬ìš©í•œ ìµœì¢… íŒë‹¨"""
        try:
            # LLM ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            if not self.llm:
                st.warning("âš ï¸ LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                combined_result['classification_method'] = 'lm_unavailable'
                return combined_result
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = """ë‹¹ì‹ ì€ ë©”ì¼ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë©”ì¼ì˜ ìµœì¢… ì¹´í…Œê³ ë¦¬ì™€ ìš°ì„ ìˆœìœ„ë¥¼ ê²°ì •í•´ì£¼ì„¸ìš”.

ë©”ì¼ ì •ë³´:
- ì œëª©: {subject}
- ë°œì‹ ì: {sender}
- ë„ë©”ì¸ ë¶„ë¥˜: {domain_type} ({domain})
- ì—…ë¬´ í‚¤ì›Œë“œ: {work_keywords}
- ê¸´ê¸‰ì„± ì ìˆ˜: {urgency_score}
- ì¤‘ìš”ë„: {priority}
- ì²¨ë¶€íŒŒì¼: {has_attachments}

í˜„ì¬ ë¶„ë¥˜ ê²°ê³¼:
- ì¹´í…Œê³ ë¦¬: {current_category}
- ìš°ì„ ìˆœìœ„: {current_priority}
- ì‹ ë¢°ë„: {confidence}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "category": "work_urgent|work_normal|work_low|personal|notification|spam|unknown",
    "priority": "critical|high|medium|low",
    "reasoning": "ë¶„ë¥˜ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…",
    "confidence": 0.0-1.0,
    "requires_action": true/false,
    "estimated_response_time": "1ì‹œê°„|1ì¼|1ì£¼ì¼|ë¬´ì‹œ"
}}"""

            user_prompt = system_prompt.format(
                subject=email_data.get('subject', ''),
                sender=email_data.get('sender', ''),
                domain_type=combined_result.get('domain_result', {}).get('domain_type', ''),
                domain=combined_result.get('domain_result', {}).get('domain', ''),
                work_keywords=', '.join(combined_result.get('content_result', {}).get('work_keywords', [])),
                urgency_score=combined_result.get('content_result', {}).get('urgency_score', 0.0),
                priority=combined_result.get('priority', ''),
                has_attachments=combined_result.get('metadata_result', {}).get('has_attachments', False),
                current_category=combined_result.get('category', ''),
                current_priority=combined_result.get('priority', ''),
                confidence=combined_result.get('confidence', 0.0)
            )
            
            # LLM í˜¸ì¶œ
            messages = [
                SystemMessage(content="ë‹¹ì‹ ì€ ë©”ì¼ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."),
                HumanMessage(content=user_prompt)
            ]
            
            # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
            current_response = ""
            final_response = None
            
            for chunk in self.llm.stream(messages):
                if hasattr(chunk, 'content'):
                    current_response += chunk.content
                    final_response = chunk
            
            response_content = final_response.content if final_response else ""
            
            # JSON íŒŒì‹±
            import json
            try:
                lm_result = json.loads(response_content)
                
                # ê²°ê³¼ í†µí•©
                final_result = combined_result.copy()
                final_result.update({
                    'category': lm_result.get('category', combined_result.get('category')),
                    'priority': lm_result.get('priority', combined_result.get('priority')),
                    'confidence': lm_result.get('confidence', combined_result.get('confidence')),
                    'reasoning': lm_result.get('reasoning', ''),
                    'requires_action': lm_result.get('requires_action', False),
                    'estimated_response_time': lm_result.get('estimated_response_time', ''),
                    'classification_method': 'lm_enhanced'
                })
                
                return final_result
                
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ê²°ê³¼ ë°˜í™˜
                combined_result['classification_method'] = 'lm_failed'
                return combined_result
                
        except Exception as e:
            # LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ê²°ê³¼ ë°˜í™˜
            st.warning(f"âš ï¸ LM ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
            combined_result['classification_method'] = 'lm_error'
            combined_result['error'] = str(e)
            return combined_result
    
    def _detect_work_keywords(self, text: str) -> List[str]:
        """ì—…ë¬´ ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"""
        work_keywords = [
            'urgent', 'important', 'deadline', 'meeting', 'project', 'task',
            'issue', 'bug', 'error', 'request', 'approve', 'review', 'feedback',
            'action', 'required', 'schedule', 'appointment', 'conference', 'call',
            'report', 'document', 'proposal', 'contract', 'invoice', 'payment',
            'support', 'help', 'problem', 'solution', 'update', 'status'
        ]
        
        detected = []
        text_lower = text.lower()
        for keyword in work_keywords:
            if keyword in text_lower:
                detected.append(keyword)
        
        return detected
    
    def _analyze_urgency(self, text: str) -> float:
        """ê¸´ê¸‰ì„± ì ìˆ˜ ê³„ì‚°"""
        urgency_keywords = {
            'urgent': 0.9,
            'asap': 0.8,
            'immediate': 0.8,
            'critical': 0.9,
            'emergency': 1.0,
            'deadline': 0.7,
            'today': 0.6,
            'now': 0.7,
            'quick': 0.5,
            'fast': 0.5
        }
        
        text_lower = text.lower()
        max_score = 0.0
        
        for keyword, score in urgency_keywords.items():
            if keyword in text_lower:
                max_score = max(max_score, score)
        
        return max_score
    
    def classify_multiple_emails(self, emails: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ ë©”ì¼ì„ ì¼ê´„ ë¶„ë¥˜"""
        results = []
        for email in emails:
            result = self.classify_email(email)
            results.append(result)
        return results
    
    def get_classification_summary(self, classifications: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½"""
        if not classifications:
            return {}
        
        category_counts = {}
        priority_counts = {}
        total_confidence = 0.0
        
        for classification in classifications:
            category = classification.get('category', 'unknown')
            priority = classification.get('priority', 'medium')
            confidence = classification.get('confidence', 0.0)
            
            category_counts[category] = category_counts.get(category, 0) + 1
            priority_counts[priority] = priority_counts.get(priority, 0) + 1
            total_confidence += confidence
        
        avg_confidence = total_confidence / len(classifications) if classifications else 0.0
        
        return {
            'total_emails': len(classifications),
            'category_distribution': category_counts,
            'priority_distribution': priority_counts,
            'average_confidence': avg_confidence,
            'work_emails': category_counts.get('work_urgent', 0) + category_counts.get('work_normal', 0) + category_counts.get('work_low', 0),
            'personal_emails': category_counts.get('personal', 0),
            'urgent_emails': priority_counts.get('critical', 0) + priority_counts.get('high', 0)
        } 