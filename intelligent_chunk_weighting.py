#!/usr/bin/env python3
"""
ì§€ëŠ¥í˜• ì²­í¬ ê°€ì¤‘ì¹˜ ë¶€ì—¬ ì‹œìŠ¤í…œ (Intelligent Chunk Weighting)
chunk_typeë³„ë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•˜ì—¬ ê²€ìƒ‰ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
"""

import numpy as np
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
import logging
from sklearn.metrics.pairwise import cosine_similarity

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ChunkData:
    """ì²­í¬ ë°ì´í„° êµ¬ì¡°"""
    id: str
    content: str
    chunk_type: str
    embedding: List[float]
    metadata: Dict[str, Any] = None

@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼ êµ¬ì¡°"""
    id: str
    content: str
    chunk_type: str
    cosine_score: float
    weight: float
    weighted_score: float
    metadata: Dict[str, Any] = None

class ChunkWeightingConfig:
    """ì²­í¬ íƒ€ì…ë³„ ê°€ì¤‘ì¹˜ ì„¤ì •"""

    # ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì„¤ì • (chunk_type -> weight)
    DEFAULT_WEIGHTS = {
        'title': 1.5,        # ì œëª©: ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜
        'summary': 1.3,      # ìš”ì•½: ë†’ì€ ê°€ì¤‘ì¹˜
        'description': 1.2,  # ì„¤ëª…: ì¤‘ê°„-ë†’ì€ ê°€ì¤‘ì¹˜
        'header': 1.1,       # í—¤ë”: ì¤‘ê°„ ê°€ì¤‘ì¹˜
        'body': 1.0,         # ë³¸ë¬¸: ê¸°ë³¸ ê°€ì¤‘ì¹˜
        'comment': 0.8,      # ëŒ“ê¸€: ë‚®ì€ ê°€ì¤‘ì¹˜
        'attachment': 0.6,   # ì²¨ë¶€íŒŒì¼: ê°€ì¥ ë‚®ì€ ê°€ì¤‘ì¹˜
        'metadata': 0.7      # ë©”íƒ€ë°ì´í„°: ë‚®ì€ ê°€ì¤‘ì¹˜
    }

    @classmethod
    def get_weight(cls, chunk_type: str) -> float:
        """chunk_typeì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ë°˜í™˜"""
        return cls.DEFAULT_WEIGHTS.get(chunk_type.lower(), 1.0)

    @classmethod
    def update_weights(cls, custom_weights: Dict[str, float]):
        """ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸"""
        cls.DEFAULT_WEIGHTS.update(custom_weights)
        logger.info(f"ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ë¨: {custom_weights}")

class IntelligentChunkWeighting:
    """ì§€ëŠ¥í˜• ì²­í¬ ê°€ì¤‘ì¹˜ ë¶€ì—¬ ì‹œìŠ¤í…œ"""

    def __init__(self, config: ChunkWeightingConfig = None):
        """
        ì´ˆê¸°í™”

        Args:
            config: ê°€ì¤‘ì¹˜ ì„¤ì • (ê¸°ë³¸ê°’: ChunkWeightingConfig)
        """
        self.config = config or ChunkWeightingConfig()
        logger.info("ğŸ”§ ì§€ëŠ¥í˜• ì²­í¬ ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def add_chunks_with_weights(self, chunks: List[ChunkData]) -> List[ChunkData]:
        """
        1. ë©”íƒ€ë°ì´í„° í™•ì¥: chunk_typeì— ë”°ë¥¸ weight í•„ë“œ ì¶”ê°€

        Args:
            chunks: ì›ë³¸ ì²­í¬ ë°ì´í„° ë¦¬ìŠ¤íŠ¸

        Returns:
            ê°€ì¤‘ì¹˜ê°€ ì¶”ê°€ëœ ì²­í¬ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        weighted_chunks = []

        for chunk in chunks:
            # ê°€ì¤‘ì¹˜ ê³„ì‚°
            weight = self.config.get_weight(chunk.chunk_type)

            # ë©”íƒ€ë°ì´í„°ì— weight ì¶”ê°€
            if chunk.metadata is None:
                chunk.metadata = {}
            chunk.metadata['weight'] = weight
            chunk.metadata['original_chunk_type'] = chunk.chunk_type

            weighted_chunks.append(chunk)

        logger.info(f"âœ… {len(chunks)}ê°œ ì²­í¬ì— ê°€ì¤‘ì¹˜ ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì™„ë£Œ")
        return weighted_chunks

    def apply_weighted_scoring(self, search_results: List[Dict[str, Any]],
                             query_embedding: List[float]) -> List[SearchResult]:
        """
        2. 1ë‹¨ê³„ ê²€ìƒ‰ ê²°ê³¼ ë³´ì •: cosine_scoreì— weightë¥¼ ì ìš©í•˜ì—¬ ì¬ì ìˆ˜í™”

        Args:
            search_results: ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ (id, content, chunk_type, embedding í¬í•¨)
            query_embedding: ì¿¼ë¦¬ ì„ë² ë”©

        Returns:
            ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ë¨)
        """
        weighted_results = []

        for result in search_results:
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            chunk_id = result.get('id', '')
            content = result.get('content', '')
            chunk_type = result.get('chunk_type', 'body')
            embedding = result.get('embedding', [])
            metadata = result.get('metadata', {})

            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            if embedding and query_embedding:
                cosine_score = cosine_similarity([query_embedding], [embedding])[0][0]
            else:
                cosine_score = result.get('cosine_score', 0.0)

            # ê°€ì¤‘ì¹˜ ê³„ì‚°
            weight = metadata.get('weight') or self.config.get_weight(chunk_type)

            # ê°€ì¤‘ì¹˜ ì ìš©ëœ ìµœì¢… ì ìˆ˜ ê³„ì‚°
            weighted_score = cosine_score * weight

            # ê²°ê³¼ ê°ì²´ ìƒì„±
            weighted_result = SearchResult(
                id=chunk_id,
                content=content,
                chunk_type=chunk_type,
                cosine_score=cosine_score,
                weight=weight,
                weighted_score=weighted_score,
                metadata=metadata
            )

            weighted_results.append(weighted_result)

        # ê°€ì¤‘ì¹˜ ì ìš©ëœ ì ìˆ˜ë¡œ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
        weighted_results.sort(key=lambda x: x.weighted_score, reverse=True)

        logger.info(f"âœ… {len(search_results)}ê°œ ê²€ìƒ‰ ê²°ê³¼ì— ê°€ì¤‘ì¹˜ ì ìš© ë° ì¬ì •ë ¬ ì™„ë£Œ")
        return weighted_results

    def prepare_reranker_input(self, weighted_results: List[SearchResult],
                              query: str) -> List[Dict[str, Any]]:
        """
        3. 2ë‹¨ê³„ Re-ranking ê°œì„ : Cross-Encoder ì…ë ¥ì— weight feature ì¶”ê°€

        Args:
            weighted_results: ê°€ì¤‘ì¹˜ ì ìš©ëœ ê²€ìƒ‰ ê²°ê³¼
            query: ì›ë³¸ ì¿¼ë¦¬

        Returns:
            Re-ranker ì…ë ¥ìš© ë°ì´í„° (weightë¥¼ featureë¡œ í¬í•¨)
        """
        reranker_inputs = []

        for result in weighted_results:
            reranker_input = {
                'query': query,
                'passage': result.content,
                'chunk_type': result.chunk_type,
                'weight': result.weight,
                'cosine_score': result.cosine_score,
                'weighted_score': result.weighted_score,
                'id': result.id,
                'metadata': result.metadata,
                # Cross-Encoderê°€ í™œìš©í•  ìˆ˜ ìˆëŠ” ì¶”ê°€ features
                'features': {
                    'chunk_weight': result.weight,
                    'base_similarity': result.cosine_score,
                    'chunk_priority': self._get_chunk_priority(result.chunk_type)
                }
            }
            reranker_inputs.append(reranker_input)

        logger.info(f"âœ… Re-ranker ì…ë ¥ ë°ì´í„° {len(reranker_inputs)}ê°œ ì¤€ë¹„ ì™„ë£Œ")
        return reranker_inputs

    def _get_chunk_priority(self, chunk_type: str) -> int:
        """chunk_typeì˜ ìš°ì„ ìˆœìœ„ ë°˜í™˜ (1=ìµœê³ , ìˆ«ìê°€ í´ìˆ˜ë¡ ë‚®ìŒ)"""
        priority_map = {
            'title': 1,
            'summary': 2,
            'description': 3,
            'header': 4,
            'body': 5,
            'comment': 6,
            'metadata': 7,
            'attachment': 8
        }
        return priority_map.get(chunk_type.lower(), 5)

def create_mock_data() -> Tuple[List[ChunkData], List[float]]:
    """í…ŒìŠ¤íŠ¸ìš© Mock ë°ì´í„° ìƒì„±"""

    # ê°€ìƒì˜ ì„ë² ë”© ë²¡í„° ìƒì„± (768ì°¨ì›)
    np.random.seed(42)

    chunks = [
        ChunkData(
            id="doc1_title",
            content="ì„œë²„ ì ‘ì† ì˜¤ë¥˜ í•´ê²° ë°©ë²•",
            chunk_type="title",
            embedding=np.random.normal(0.8, 0.1, 768).tolist()  # titleê³¼ ìœ ì‚¬ë„ ë†’ê²Œ
        ),
        ChunkData(
            id="doc1_desc",
            content="ë©”ì¸ ì„œë²„ì— ì ‘ì†í•  ìˆ˜ ì—†ì„ ë•Œ í™•ì¸í•´ì•¼ í•  ì‚¬í•­ë“¤ì„ ì„¤ëª…í•©ë‹ˆë‹¤.",
            chunk_type="description",
            embedding=np.random.normal(0.6, 0.1, 768).tolist()  # ì¤‘ê°„ ìœ ì‚¬ë„
        ),
        ChunkData(
            id="doc1_comment",
            content="ì €ë„ ê°™ì€ ë¬¸ì œê°€ ìˆì—ˆëŠ”ë° ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ ë°”ê¾¸ë‹ˆê¹Œ í•´ê²°ëì–´ìš”",
            chunk_type="comment",
            embedding=np.random.normal(0.4, 0.1, 768).tolist()  # ë‚®ì€ ìœ ì‚¬ë„
        ),
        ChunkData(
            id="doc2_summary",
            content="ì„œë²„ ì—°ê²° ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ìš”ì•½",
            chunk_type="summary",
            embedding=np.random.normal(0.7, 0.1, 768).tolist()  # ë†’ì€ ìœ ì‚¬ë„
        ),
        ChunkData(
            id="doc2_body",
            content="ì„œë²„ì— ì ‘ì†í•˜ëŠ” ë°©ë²•ê³¼ ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²° ì ˆì°¨ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.",
            chunk_type="body",
            embedding=np.random.normal(0.5, 0.1, 768).tolist()  # ì¤‘ê°„ ìœ ì‚¬ë„
        )
    ]

    # ì¿¼ë¦¬ ì„ë² ë”© (ì„œë²„ ì ‘ì† ë¬¸ì œì™€ ê´€ë ¨)
    query_embedding = np.random.normal(0.7, 0.1, 768).tolist()

    return chunks, query_embedding

def demonstrate_intelligent_weighting():
    """ì§€ëŠ¥í˜• ì²­í¬ ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ ë°ëª¨"""
    print("="*80)
    print("ğŸš€ ì§€ëŠ¥í˜• ì²­í¬ ê°€ì¤‘ì¹˜ ë¶€ì—¬ ì‹œìŠ¤í…œ ë°ëª¨")
    print("="*80)

    # 1. Mock ë°ì´í„° ìƒì„±
    chunks, query_embedding = create_mock_data()
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(chunks)}ê°œ ì²­í¬")

    # 2. ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    weighting_system = IntelligentChunkWeighting()

    # 3. ì²­í¬ì— ê°€ì¤‘ì¹˜ ë©”íƒ€ë°ì´í„° ì¶”ê°€
    weighted_chunks = weighting_system.add_chunks_with_weights(chunks)

    # 4. ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ìƒì„± (ê°€ì¤‘ì¹˜ ì ìš© ì „)
    basic_results = []
    for chunk in weighted_chunks:
        cosine_score = cosine_similarity([query_embedding], [chunk.embedding])[0][0]
        basic_results.append({
            'id': chunk.id,
            'content': chunk.content,
            'chunk_type': chunk.chunk_type,
            'embedding': chunk.embedding,
            'cosine_score': cosine_score,
            'metadata': chunk.metadata
        })

    # ê¸°ë³¸ ì ìˆ˜ë¡œ ì •ë ¬
    basic_results.sort(key=lambda x: x['cosine_score'], reverse=True)

    print("\nğŸ“‹ Before weighting (ê¸°ë³¸ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìˆœ):")
    print("-" * 60)
    for i, result in enumerate(basic_results, 1):
        weight = result['metadata'].get('weight', 1.0)
        print(f"{i}. {result['id']} ({result['chunk_type']})")
        print(f"   Content: {result['content'][:50]}...")
        print(f"   Cosine Score: {result['cosine_score']:.4f}")
        print(f"   Weight: {weight:.1f}")
        print()

    # 5. ê°€ì¤‘ì¹˜ ì ìš©ëœ ê²€ìƒ‰ ê²°ê³¼
    weighted_results = weighting_system.apply_weighted_scoring(basic_results, query_embedding)

    print("ğŸ“‹ After weighting (ê°€ì¤‘ì¹˜ ì ìš©ëœ ì ìˆ˜ ìˆœ):")
    print("-" * 60)
    for i, result in enumerate(weighted_results, 1):
        print(f"{i}. {result.id} ({result.chunk_type})")
        print(f"   Content: {result.content[:50]}...")
        print(f"   Cosine Score: {result.cosine_score:.4f}")
        print(f"   Weight: {result.weight:.1f}")
        print(f"   Weighted Score: {result.weighted_score:.4f} â­")
        print()

    # 6. ìˆœìœ„ ë³€í™” ë¶„ì„
    print("ğŸ“ˆ ìˆœìœ„ ë³€í™” ë¶„ì„:")
    print("-" * 60)

    basic_ranking = {result['id']: i+1 for i, result in enumerate(basic_results)}
    weighted_ranking = {result.id: i+1 for i, result in enumerate(weighted_results)}

    for chunk_id in basic_ranking:
        basic_rank = basic_ranking[chunk_id]
        weighted_rank = weighted_ranking[chunk_id]
        rank_change = basic_rank - weighted_rank

        change_symbol = "ğŸ“ˆ" if rank_change > 0 else "ğŸ“‰" if rank_change < 0 else "â¡ï¸"
        print(f"{chunk_id}: {basic_rank} â†’ {weighted_rank} {change_symbol}")

    # 7. Re-ranker ì…ë ¥ ë°ì´í„° ì¤€ë¹„
    query = "ì„œë²„ì— ì ‘ì†í•  ìˆ˜ ì—†ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•"
    reranker_inputs = weighting_system.prepare_reranker_input(weighted_results, query)

    print(f"\nğŸ”§ Re-ranker ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:")
    print("-" * 60)
    print(f"ì…ë ¥ ê°œìˆ˜: {len(reranker_inputs)}")
    print(f"ê° ì…ë ¥ì— í¬í•¨ëœ features:")
    if reranker_inputs:
        features = reranker_inputs[0]['features']
        for key, value in features.items():
            print(f"  - {key}: {value}")

    # 8. ê°€ì¤‘ì¹˜ íš¨ê³¼ ìš”ì•½
    print(f"\nğŸ“Š ê°€ì¤‘ì¹˜ íš¨ê³¼ ìš”ì•½:")
    print("-" * 60)

    # ê°€ì¤‘ì¹˜ë³„ í‰ê·  ì ìˆ˜ í–¥ìƒ ê³„ì‚°
    weight_effects = {}
    for result in weighted_results:
        chunk_type = result.chunk_type
        improvement = result.weighted_score - result.cosine_score
        if chunk_type not in weight_effects:
            weight_effects[chunk_type] = []
        weight_effects[chunk_type].append(improvement)

    for chunk_type, improvements in weight_effects.items():
        avg_improvement = np.mean(improvements)
        weight = weighting_system.config.get_weight(chunk_type)
        print(f"{chunk_type}: ê°€ì¤‘ì¹˜ {weight:.1f} â†’ í‰ê·  ì ìˆ˜ ë³€í™” {avg_improvement:+.4f}")

    print("\nğŸ‰ ì§€ëŠ¥í˜• ì²­í¬ ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ ë°ëª¨ ì™„ë£Œ!")
    return weighted_results, reranker_inputs

class EnhancedCrossEncoderReranker:
    """ê°€ì¤‘ì¹˜ë¥¼ í™œìš©í•˜ëŠ” í–¥ìƒëœ Cross-Encoder Re-ranker"""

    def __init__(self, model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2"):
        """
        Re-ranker ì´ˆê¸°í™”

        Args:
            model_name: Cross-Encoder ëª¨ë¸ëª…
        """
        self.model_name = model_name
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” sentence_transformers.CrossEncoder ì‚¬ìš©
        # self.model = CrossEncoder(model_name)
        logger.info(f"ğŸ”§ Enhanced Cross-Encoder Re-ranker ì´ˆê¸°í™”: {model_name}")

    def rerank_with_weights(self, reranker_inputs: List[Dict[str, Any]],
                          weight_boost: float = 0.1) -> List[Dict[str, Any]]:
        """
        ê°€ì¤‘ì¹˜ë¥¼ ê³ ë ¤í•œ Re-ranking

        Args:
            reranker_inputs: Re-ranker ì…ë ¥ ë°ì´í„°
            weight_boost: ê°€ì¤‘ì¹˜ ë¶€ìŠ¤íŠ¸ ê³„ìˆ˜

        Returns:
            Re-rankingëœ ê²°ê³¼
        """
        enhanced_results = []

        for item in reranker_inputs:
            # Mock Cross-Encoder ì ìˆ˜ (ì‹¤ì œë¡œëŠ” ëª¨ë¸ ì˜ˆì¸¡ ì‚¬ìš©)
            # cross_encoder_score = self.model.predict([(item['query'], item['passage'])])[0]

            # Mock ì ìˆ˜ ìƒì„± (ê¸°ì¡´ weighted_score ê¸°ë°˜)
            base_score = item.get('weighted_score', 0.5)
            mock_cross_encoder_score = base_score + np.random.normal(0, 0.1)
            mock_cross_encoder_score = max(0, min(1, mock_cross_encoder_score))

            # ê°€ì¤‘ì¹˜ë¥¼ í™œìš©í•œ ìµœì¢… ì ìˆ˜ ê³„ì‚°
            weight_factor = item['features']['chunk_weight']
            final_score = mock_cross_encoder_score + (weight_factor - 1.0) * weight_boost

            enhanced_result = {
                **item,
                'cross_encoder_score': mock_cross_encoder_score,
                'final_score': final_score,
                'weight_boost_applied': (weight_factor - 1.0) * weight_boost
            }

            enhanced_results.append(enhanced_result)

        # ìµœì¢… ì ìˆ˜ë¡œ ì •ë ¬
        enhanced_results.sort(key=lambda x: x['final_score'], reverse=True)

        logger.info(f"âœ… ê°€ì¤‘ì¹˜ ê¸°ë°˜ Re-ranking ì™„ë£Œ: {len(enhanced_results)}ê°œ ê²°ê³¼")
        return enhanced_results

def demonstrate_enhanced_reranking():
    """í–¥ìƒëœ Re-ranking ì‹œìŠ¤í…œ ë°ëª¨"""
    print("\n" + "="*80)
    print("ğŸ”§ í–¥ìƒëœ Cross-Encoder Re-ranking ë°ëª¨")
    print("="*80)

    # ê¸°ë³¸ ê°€ì¤‘ì¹˜ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    weighted_results, reranker_inputs = demonstrate_intelligent_weighting()

    # Enhanced Re-ranker ì´ˆê¸°í™”
    enhanced_reranker = EnhancedCrossEncoderReranker()

    # ê°€ì¤‘ì¹˜ë¥¼ ê³ ë ¤í•œ Re-ranking ìˆ˜í–‰
    final_results = enhanced_reranker.rerank_with_weights(reranker_inputs)

    print("\nğŸ“‹ Final Results (Enhanced Re-ranking í›„):")
    print("-" * 60)
    for i, result in enumerate(final_results, 1):
        print(f"{i}. {result['id']} ({result['chunk_type']})")
        print(f"   Cross-Encoder Score: {result['cross_encoder_score']:.4f}")
        print(f"   Weight Boost: {result['weight_boost_applied']:+.4f}")
        print(f"   Final Score: {result['final_score']:.4f} â­")
        print()

    return final_results

if __name__ == "__main__":
    # ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ ë°ëª¨
    demonstrate_intelligent_weighting()

    # í–¥ìƒëœ Re-ranking ë°ëª¨
    demonstrate_enhanced_reranking()