#!/usr/bin/env python3
"""
JIRA ì¼ê° ìƒì„± ì í•©ì„± íŒë‹¨ ì‹œìŠ¤í…œ
í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•´ë‹¹ ë‚´ìš©ì´ JIRA í‹°ì¼“ìœ¼ë¡œ ìƒì„±í•  ë§Œí•œ ì‘ì—…ì¸ì§€ íŒë‹¨
"""

import os
import re
import json
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime

# Azure OpenAI ì‚¬ìš©ì‹œ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ì—°ë™)
try:
    from module.image_to_text import AzureOpenAIImageProcessor
    AZURE_AVAILABLE = True
except ImportError:
    AZURE_AVAILABLE = False


class TaskType(Enum):
    """ì‘ì—… ìœ í˜•"""
    BUG_FIX = "bug_fix"
    FEATURE = "feature"
    IMPROVEMENT = "improvement"
    TASK = "task"
    STORY = "story"
    EPIC = "epic"
    RESEARCH = "research"
    DOCUMENTATION = "documentation"
    NOT_APPLICABLE = "not_applicable"


class Priority(Enum):
    """ìš°ì„ ìˆœìœ„"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    UNDEFINED = "undefined"


class JiraEligibility(Enum):
    """JIRA ì í•©ì„±"""
    HIGHLY_SUITABLE = "highly_suitable"      # ë§¤ìš° ì í•©
    SUITABLE = "suitable"                    # ì í•©
    PARTIALLY_SUITABLE = "partially_suitable"  # ë¶€ë¶„ì ìœ¼ë¡œ ì í•©
    NOT_SUITABLE = "not_suitable"           # ë¶€ì í•©


@dataclass
class TaskAnalysisResult:
    """ì‘ì—… ë¶„ì„ ê²°ê³¼"""
    text: str
    eligibility: JiraEligibility
    confidence: float  # 0.0 ~ 1.0
    task_type: TaskType
    priority: Priority
    reasoning: List[str] = field(default_factory=list)
    suggested_title: Optional[str] = None
    suggested_description: Optional[str] = None
    estimated_effort: Optional[str] = None  # "1h", "1d", "1w" ë“±
    tags: List[str] = field(default_factory=list)
    blockers: List[str] = field(default_factory=list)  # ì‘ì—… ì§„í–‰ì„ ë§‰ëŠ” ìš”ì†Œë“¤
    analysis_timestamp: str = field(default_factory=lambda: datetime.now().isoformat())


class JiraTaskAnalyzer:
    """JIRA ì¼ê° ìƒì„± ì í•©ì„± ë¶„ì„ê¸°"""
    
    def __init__(self, use_llm: bool = True, azure_processor: Optional[AzureOpenAIImageProcessor] = None):
        """
        Args:
            use_llm: LLMì„ ì‚¬ìš©í•œ ê³ ë„í™”ëœ ë¶„ì„ ì—¬ë¶€
            azure_processor: Azure OpenAI í”„ë¡œì„¸ì„œ (ì„ íƒì‚¬í•­)
        """
        self.use_llm = use_llm and AZURE_AVAILABLE
        self.azure_processor = azure_processor
        
        # í‚¤ì›Œë“œ íŒ¨í„´ ì •ì˜
        self._init_patterns()
        
        # ì‘ì—… ìœ í˜•ë³„ ê°€ì¤‘ì¹˜
        self.type_weights = {
            TaskType.BUG_FIX: 0.9,        # ë²„ê·¸ëŠ” ë†’ì€ ìš°ì„ ìˆœìœ„
            TaskType.FEATURE: 0.8,        # ê¸°ëŠ¥ ê°œë°œ
            TaskType.IMPROVEMENT: 0.7,    # ê°œì„ ì‚¬í•­
            TaskType.TASK: 0.6,          # ì¼ë°˜ ì‘ì—…
            TaskType.STORY: 0.8,         # ì‚¬ìš©ì ìŠ¤í† ë¦¬
            TaskType.RESEARCH: 0.5,      # ì¡°ì‚¬/ì—°êµ¬
            TaskType.DOCUMENTATION: 0.4, # ë¬¸ì„œí™”
        }
    
    def _init_patterns(self):
        """í‚¤ì›Œë“œ íŒ¨í„´ ì´ˆê¸°í™”"""
        self.patterns = {
            "bug_keywords": [
                r"ë²„ê·¸", r"ì˜¤ë¥˜", r"ì—ëŸ¬", r"bug", r"error", r"issue", r"ë¬¸ì œ",
                r"ì•ˆ\s*ë¨", r"ì‘ë™í•˜ì§€\s*ì•Š", r"ì‹¤íŒ¨", r"ê¹¨ì§", r"crash", r"exception"
            ],
            "feature_keywords": [
                r"ê¸°ëŠ¥", r"ì¶”ê°€", r"ê°œë°œ", r"êµ¬í˜„", r"feature", r"add", r"create", r"build",
                r"ìƒˆë¡œìš´", r"ì‹ ê·œ", r"ë§Œë“¤", r"ìƒì„±"
            ],
            "improvement_keywords": [
                r"ê°œì„ ", r"í–¥ìƒ", r"ìµœì í™”", r"ë¦¬íŒ©í† ë§", r"upgrade", r"optimize", r"improve",
                r"ì„±ëŠ¥", r"ì†ë„", r"íš¨ìœ¨", r"ì‚¬ìš©ì„±", r"UX", r"UI"
            ],
            "task_keywords": [
                r"ì‘ì—…", r"ì„¤ì •", r"ì„¤ì¹˜", r"ë°°í¬", r"ì„¤ì •", r"config", r"setup", r"install",
                r"deploy", r"migration", r"update"
            ],
            "story_keywords": [
                r"ì‚¬ìš©ì", r"ê³ ê°", r"user", r"customer", r"~ë¡œì„œ", r"~ì„\s*ìœ„í•´",
                r"story", r"requirement", r"ìš”êµ¬ì‚¬í•­"
            ],
            "research_keywords": [
                r"ì¡°ì‚¬", r"ì—°êµ¬", r"ë¶„ì„", r"ê²€í† ", r"research", r"investigate", r"analyze",
                r"study", r"review", r"evaluate"
            ],
            "documentation_keywords": [
                r"ë¬¸ì„œ", r"ë©”ë‰´ì–¼", r"ê°€ì´ë“œ", r"ì„¤ëª…ì„œ", r"docs", r"documentation", r"manual",
                r"guide", r"readme", r"wiki"
            ],
            "priority_high": [
                r"ê¸´ê¸‰", r"ì¤‘ìš”", r"critical", r"urgent", r"high", r"asap", r"ë¹¨ë¦¬",
                r"ì¦‰ì‹œ", r"ìš°ì„ ìˆœìœ„"
            ],
            "priority_low": [
                r"ë‚˜ì¤‘ì—", r"ì—¬ìœ \s*ìˆì„\s*ë•Œ", r"low", r"minor", r"nice\s*to\s*have",
                r"ì¶”í›„", r"í–¥í›„"
            ],
            "actionable": [
                r"í•´ì•¼\s*í•œë‹¤", r"í•´ì£¼ì„¸ìš”", r"í•„ìš”í•˜ë‹¤", r"ìš”ì²­", r"ë¶€íƒ", r"~í•˜ì",
                r"should", r"need", r"must", r"require", r"please", r"let's",
                r"ê³ ì³", r"ìˆ˜ì •", r"ê°œì„ ", r"ì¶”ê°€", r"êµ¬í˜„", r"ê°œë°œ", r"ë§Œë“¤",
                r"fix", r"add", r"create", r"build", r"implement", r"develop"
            ],
            "vague": [
                r"ì¢€", r"ì•½ê°„", r"ì¡°ê¸ˆ", r"ê°€ë”", r"maybe", r"perhaps", r"might",
                r"ìƒê°í•´ë³´", r"ê³ ë¯¼", r"ì–´ë–¨ê¹Œ", r"ê´œì°®ì„ê¹Œ"
            ],
            "jira_notifications": [
                r"ì—…ë°ì´íŠ¸", r"update", r"ëŒ“ê¸€", r"comment", r"ìˆ˜ì •", r"modified",
                r"ë³€ê²½", r"changed", r"assigned", r"mention", r"ì°¸ì¡°", r"watched",
                r"resolved", r"closed", r"reopened", r"ì§„í–‰", r"ì™„ë£Œ", r"í•´ê²°",
                r"ìƒíƒœ ë³€ê²½", r"status.*changed", r"due date", r"ë§ˆê°ì¼"
            ],
            "jira_creation": [
                r"ìƒì„±", r"created", r"ì‹ ê·œ", r"new", r"ë“±ë¡", r"ìš”ì²­", r"request",
                r"ë¬¸ì˜", r"inquiry", r"ë²„ê·¸ ë¦¬í¬íŠ¸", r"bug report", r"ê°œë°œ ìš”ì²­"
            ],
            "effort_indicators": [
                r"(\d+)\s*(ì‹œê°„|hour|h)", r"(\d+)\s*(ì¼|day|d)", r"(\d+)\s*(ì£¼|week|w)",
                r"(\d+)\s*(ê°œì›”|month|m)", r"ê°„ë‹¨í•œ", r"ë³µì¡í•œ", r"ì–´ë ¤ìš´", r"ì‰¬ìš´"
            ]
        }
    
    def analyze_text(self, text: str) -> TaskAnalysisResult:
        """í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ JIRA ì¼ê° ì í•©ì„± íŒë‹¨"""
        try:
            # 1. ê¸°ë³¸ ë¶„ì„ (í‚¤ì›Œë“œ ê¸°ë°˜)
            basic_result = self._basic_analysis(text)
            
            # 2. LLM ê¸°ë°˜ ê³ ë„í™”ëœ ë¶„ì„ (ì‚¬ìš© ê°€ëŠ¥ì‹œ)
            if self.use_llm and self.azure_processor:
                enhanced_result = self._llm_enhanced_analysis(text, basic_result)
                return enhanced_result
            else:
                return basic_result
                
        except Exception as e:
            print(f"ë¶„ì„ ì˜¤ë¥˜: {e}")
            return TaskAnalysisResult(
                text=text,
                eligibility=JiraEligibility.NOT_SUITABLE,
                confidence=0.1,
                task_type=TaskType.NOT_APPLICABLE,
                priority=Priority.UNDEFINED,
                reasoning=[f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}"]
            )
    
    def _basic_analysis(self, text: str) -> TaskAnalysisResult:
        """ê¸°ë³¸ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„"""
        text_lower = text.lower()
        
        # JIRA ì•Œë¦¼/ì—…ë°ì´íŠ¸ ë©”ì¼ ì‚¬ì „ í•„í„°ë§
        if self._is_jira_notification(text_lower):
            return TaskAnalysisResult(
                text=text,
                eligibility=JiraEligibility.NOT_SUITABLE,
                confidence=0.9,  # ë†’ì€ ì‹ ë¢°ë„ë¡œ ë¶€ì í•© íŒì •
                task_type=TaskType.NOT_APPLICABLE,
                priority=Priority.UNDEFINED,
                reasoning=["JIRA ì•Œë¦¼/ì—…ë°ì´íŠ¸ ë©”ì¼ë¡œ ê°ì§€ë¨", "ì‹ ê·œ ì¼ê°ì´ ì•„ë‹Œ ê¸°ì¡´ í‹°ì¼“ ì§„í–‰ì‚¬í•­"],
                suggested_title="[ì•Œë¦¼] " + text.split('\n')[0][:50] + "...",
                estimated_effort="0h"
            )
        
        # ì‘ì—… ìœ í˜• íŒë³„
        task_type = self._detect_task_type(text_lower)
        
        # ìš°ì„ ìˆœìœ„ íŒë³„
        priority = self._detect_priority(text_lower)
        
        # ì‹¤í–‰ ê°€ëŠ¥ì„± ì ìˆ˜ ê³„ì‚°
        actionability_score = self._calculate_actionability(text_lower)
        
        # ëª…í™•ì„± ì ìˆ˜ ê³„ì‚°
        clarity_score = self._calculate_clarity(text_lower)
        
        # JIRA ì í•©ì„± ê³„ì‚°
        eligibility, confidence = self._calculate_eligibility(
            task_type, actionability_score, clarity_score, len(text)
        )
        
        # ì¶”ì²œ ì œëª© ìƒì„±
        suggested_title = self._generate_title(text, task_type)
        
        # ë…¸ë ¥ ì¶”ì •
        estimated_effort = self._estimate_effort(text_lower)
        
        # íƒœê·¸ ì¶”ì¶œ
        tags = self._extract_tags(text_lower, task_type)
        
        # ë¸”ë¡œì»¤ ì‹ë³„
        blockers = self._identify_blockers(text_lower)
        
        # ë¶„ì„ ê·¼ê±° ìƒì„±
        reasoning = self._generate_reasoning(
            task_type, actionability_score, clarity_score, len(text)
        )
        
        return TaskAnalysisResult(
            text=text,
            eligibility=eligibility,
            confidence=confidence,
            task_type=task_type,
            priority=priority,
            reasoning=reasoning,
            suggested_title=suggested_title,
            suggested_description=self._generate_description(text),
            estimated_effort=estimated_effort,
            tags=tags,
            blockers=blockers
        )
    
    def _detect_task_type(self, text: str) -> TaskType:
        """ì‘ì—… ìœ í˜• ê°ì§€"""
        scores = {}
        
        for task_type, patterns in [
            (TaskType.BUG_FIX, self.patterns["bug_keywords"]),
            (TaskType.FEATURE, self.patterns["feature_keywords"]),
            (TaskType.IMPROVEMENT, self.patterns["improvement_keywords"]),
            (TaskType.TASK, self.patterns["task_keywords"]),
            (TaskType.STORY, self.patterns["story_keywords"]),
            (TaskType.RESEARCH, self.patterns["research_keywords"]),
            (TaskType.DOCUMENTATION, self.patterns["documentation_keywords"])
        ]:
            score = sum(len(re.findall(pattern, text, re.IGNORECASE)) for pattern in patterns)
            scores[task_type] = score
        
        if not any(scores.values()):
            return TaskType.NOT_APPLICABLE
        
        return max(scores, key=scores.get)
    
    def _detect_priority(self, text: str) -> Priority:
        """ìš°ì„ ìˆœìœ„ ê°ì§€"""
        high_score = sum(len(re.findall(pattern, text, re.IGNORECASE)) 
                        for pattern in self.patterns["priority_high"])
        low_score = sum(len(re.findall(pattern, text, re.IGNORECASE)) 
                       for pattern in self.patterns["priority_low"])
        
        if high_score > low_score:
            return Priority.HIGH
        elif low_score > 0:
            return Priority.LOW
        else:
            return Priority.MEDIUM
    
    def _calculate_actionability(self, text: str) -> float:
        """ì‹¤í–‰ ê°€ëŠ¥ì„± ì ìˆ˜ ê³„ì‚°"""
        actionable_count = sum(len(re.findall(pattern, text, re.IGNORECASE)) 
                             for pattern in self.patterns["actionable"])
        vague_count = sum(len(re.findall(pattern, text, re.IGNORECASE)) 
                         for pattern in self.patterns["vague"])
        
        # ëª…í™•í•œ ì•¡ì…˜ì´ ìˆìœ¼ë©´ ë†’ì€ ì ìˆ˜, ëª¨í˜¸í•œ í‘œí˜„ì´ ìˆìœ¼ë©´ ê°ì 
        score = min(actionable_count * 0.3 - vague_count * 0.2, 1.0)
        return max(score, 0.0)
    
    def _calculate_clarity(self, text: str) -> float:
        """ëª…í™•ì„± ì ìˆ˜ ê³„ì‚°"""
        # ë¬¸ì¥ ê¸¸ì´, êµ¬ì²´ì„±, ê¸°ìˆ ì  ìš©ì–´ ë“±ì„ ê³ ë ¤
        sentences = text.split('.')
        avg_sentence_length = sum(len(s.split()) for s in sentences) / max(len(sentences), 1)
        
        # ì ì ˆí•œ ë¬¸ì¥ ê¸¸ì´ (5-20 ë‹¨ì–´)
        length_score = 1.0 - abs(avg_sentence_length - 12.5) / 12.5
        length_score = max(0.0, min(1.0, length_score))
        
        # êµ¬ì²´ì ì¸ ìš©ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
        specific_terms = len(re.findall(r'[A-Z]{2,}|[a-z]+\.[a-z]+|\d+', text))
        specificity_score = min(specific_terms * 0.1, 1.0)
        
        return (length_score + specificity_score) / 2
    
    def _calculate_eligibility(self, task_type: TaskType, actionability: float, 
                              clarity: float, text_length: int) -> Tuple[JiraEligibility, float]:
        """JIRA ì í•©ì„± ê³„ì‚°"""
        # ì‘ì—… ìœ í˜•ë³„ ê¸°ë³¸ ì ìˆ˜
        base_score = self.type_weights.get(task_type, 0.3)
        
        # NOT_APPLICABLEì´ ì•„ë‹Œ ê²½ìš° ê¸°ë³¸ ì ìˆ˜ ìƒí–¥ ì¡°ì •
        if task_type != TaskType.NOT_APPLICABLE:
            base_score = max(base_score, 0.5)
        
        # ì‹¤í–‰ ê°€ëŠ¥ì„±ê³¼ ëª…í™•ì„± ë°˜ì˜
        score = base_score * 0.5 + actionability * 0.25 + clarity * 0.25
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ê³ ë ¤ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ë©´ ê°ì )
        if text_length < 10:
            score *= 0.5  # ë„ˆë¬´ ì§§ìŒ
        elif text_length > 1000:
            score *= 0.8  # ë„ˆë¬´ ê¹€
        
        # ì í•©ì„± ë“±ê¸‰ ê²°ì •
        if score >= 0.8:
            eligibility = JiraEligibility.HIGHLY_SUITABLE
        elif score >= 0.6:
            eligibility = JiraEligibility.SUITABLE
        elif score >= 0.4:
            eligibility = JiraEligibility.PARTIALLY_SUITABLE
        else:
            eligibility = JiraEligibility.NOT_SUITABLE
        
        confidence = min(score, 0.95)  # ìµœëŒ€ 95% ì‹ ë¢°ë„
        
        return eligibility, confidence
    
    def _generate_title(self, text: str, task_type: TaskType) -> str:
        """ì œëª© ìƒì„±"""
        # ì²« ë¬¸ì¥ì´ë‚˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œëª© ìƒì„±
        first_sentence = text.split('.')[0].strip()
        if len(first_sentence) > 50:
            first_sentence = first_sentence[:47] + "..."
        
        type_prefix = {
            TaskType.BUG_FIX: "[ë²„ê·¸ìˆ˜ì •]",
            TaskType.FEATURE: "[ê¸°ëŠ¥ê°œë°œ]",
            TaskType.IMPROVEMENT: "[ê°œì„ ]",
            TaskType.TASK: "[ì‘ì—…]",
            TaskType.STORY: "[ìŠ¤í† ë¦¬]",
            TaskType.RESEARCH: "[ì¡°ì‚¬]",
            TaskType.DOCUMENTATION: "[ë¬¸ì„œí™”]"
        }.get(task_type, "[ì‘ì—…]")
        
        return f"{type_prefix} {first_sentence}"
    
    def _generate_description(self, text: str) -> str:
        """ì„¤ëª… ìƒì„±"""
        if len(text) <= 200:
            return text
        
        # ê¸´ í…ìŠ¤íŠ¸ì˜ ê²½ìš° ìš”ì•½ í˜•íƒœë¡œ êµ¬ì„±
        sentences = text.split('.')
        key_sentences = sentences[:3]  # ì²˜ìŒ 3ë¬¸ì¥
        
        description = "## ìš”ì²­ì‚¬í•­\n"
        description += '. '.join(key_sentences) + "\n\n"
        
        if len(sentences) > 3:
            description += "## ìƒì„¸ë‚´ìš©\n"
            description += '. '.join(sentences[3:])
        
        return description
    
    def _estimate_effort(self, text: str) -> Optional[str]:
        """ì‘ì—… ë…¸ë ¥ ì¶”ì •"""
        for pattern in self.patterns["effort_indicators"]:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(0)
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì •
        if any(keyword in text for keyword in ["ê°„ë‹¨", "ì‰¬ìš´", "simple", "easy"]):
            return "1-2h"
        elif any(keyword in text for keyword in ["ë³µì¡", "ì–´ë ¤ìš´", "complex", "difficult"]):
            return "1-2w"
        else:
            return "2-3d"  # ê¸°ë³¸ê°’
    
    def _extract_tags(self, text: str, task_type: TaskType) -> List[str]:
        """íƒœê·¸ ì¶”ì¶œ"""
        tags = [task_type.value]
        
        # ê¸°ìˆ  ìŠ¤íƒ ê´€ë ¨ íƒœê·¸
        tech_patterns = {
            "frontend": r"í”„ë¡ íŠ¸ì—”ë“œ|frontend|react|vue|angular|javascript|html|css",
            "backend": r"ë°±ì—”ë“œ|backend|api|server|java|python|node",
            "database": r"ë°ì´í„°ë² ì´ìŠ¤|database|db|sql|mysql|postgresql|mongodb",
            "mobile": r"ëª¨ë°”ì¼|mobile|ios|android|app",
            "devops": r"ë°°í¬|deploy|ci/cd|docker|kubernetes|aws|azure"
        }
        
        for tag, pattern in tech_patterns.items():
            if re.search(pattern, text, re.IGNORECASE):
                tags.append(tag)
        
        return tags
    
    def _identify_blockers(self, text: str) -> List[str]:
        """ì‘ì—… ë¸”ë¡œì»¤ ì‹ë³„"""
        blockers = []
        
        blocker_patterns = {
            "ì˜ì¡´ì„±": r"ì˜ì¡´|depend|require|í•„ìš”",
            "ê¶Œí•œ": r"ê¶Œí•œ|permission|access|ìŠ¹ì¸",
            "ë¦¬ì†ŒìŠ¤": r"ë¦¬ì†ŒìŠ¤|resource|ì¸ë ¥|ì‹œê°„|ì˜ˆì‚°",
            "ê¸°ìˆ ë¶€ì±„": r"ê¸°ìˆ ë¶€ì±„|legacy|ì˜¤ë˜ëœ|outdated"
        }
        
        for blocker_type, pattern in blocker_patterns.items():
            if re.search(pattern, text, re.IGNORECASE):
                blockers.append(blocker_type)
        
        return blockers
    
    def _generate_reasoning(self, task_type: TaskType, actionability: float, 
                           clarity: float, text_length: int) -> List[str]:
        """ë¶„ì„ ê·¼ê±° ìƒì„±"""
        reasoning = []
        
        reasoning.append(f"ì‘ì—… ìœ í˜•: {task_type.value}")
        reasoning.append(f"ì‹¤í–‰ê°€ëŠ¥ì„±: {actionability:.2f}")
        reasoning.append(f"ëª…í™•ì„±: {clarity:.2f}")
        reasoning.append(f"í…ìŠ¤íŠ¸ ê¸¸ì´: {text_length}ì")
        
        if actionability > 0.7:
            reasoning.append("ëª…í™•í•œ ì•¡ì…˜ ì•„ì´í…œ í¬í•¨")
        elif actionability < 0.3:
            reasoning.append("ëª¨í˜¸í•œ í‘œí˜„ìœ¼ë¡œ ì•¡ì…˜ ë¶ˆëª…í™•")
        
        if clarity > 0.7:
            reasoning.append("êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ìš”êµ¬ì‚¬í•­")
        elif clarity < 0.3:
            reasoning.append("ìš”êµ¬ì‚¬í•­ì´ ë¶ˆëª…í™•í•¨")
        
        return reasoning
    
    def _is_jira_notification(self, text: str) -> bool:
        """JIRA ì•Œë¦¼/ì—…ë°ì´íŠ¸ ë©”ì¼ì¸ì§€ íŒë³„"""
        # ì œëª©/ì²« ì¤„ì—ì„œ JIRA ì•Œë¦¼ íŒ¨í„´ í™•ì¸
        first_lines = text.split('\n')[:3]  # ì²˜ìŒ 3ì¤„ í™•ì¸
        first_text = '\n'.join(first_lines).lower()
        
        # 1. JIRA í‹°ì¼“ ë²ˆí˜¸ + ì—…ë°ì´íŠ¸ íŒ¨í„´
        jira_ticket_pattern = r'(jira|btvo|btvdb|bpm|testbed|ncms)[-_]?\d+.*ì—…ë°ì´íŠ¸'
        if re.search(jira_ticket_pattern, first_text, re.IGNORECASE):
            return True
        
        # 2. ì¼ë°˜ì ì¸ JIRA ì•Œë¦¼ í‚¤ì›Œë“œ
        notification_count = sum(len(re.findall(pattern, text, re.IGNORECASE)) 
                               for pattern in self.patterns["jira_notifications"])
        
        # 3. ìƒˆë¡œìš´ ìƒì„± í‚¤ì›Œë“œ (ì´ê±´ ì œì™¸)
        creation_count = sum(len(re.findall(pattern, text, re.IGNORECASE)) 
                           for pattern in self.patterns["jira_creation"])
        
        # ì•Œë¦¼ í‚¤ì›Œë“œê°€ ë§ê³  ìƒì„± í‚¤ì›Œë“œê°€ ì ìœ¼ë©´ ì•Œë¦¼ìœ¼ë¡œ íŒë‹¨
        if notification_count >= 2 and creation_count <= 1:
            return True
            
        # 4. ë°œì‹ ìê°€ JIRA ì‹œìŠ¤í…œì¸ì§€ í™•ì¸
        if re.search(r'jira@.*\.com|noreply.*jira', text, re.IGNORECASE):
            return True
        
        return False
    
    def _llm_enhanced_analysis(self, text: str, basic_result: TaskAnalysisResult) -> TaskAnalysisResult:
        """LLMì„ ì‚¬ìš©í•œ ê³ ë„í™”ëœ ë¶„ì„"""
        if not self.azure_processor:
            return basic_result
        
        try:
            # LLMì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._create_llm_prompt(text, basic_result)
            
            # ì§ì ‘ Azure OpenAI client ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë¶„ì„
            llm_response = self._call_azure_openai_text(prompt)
            
            # LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ê²°ê³¼ ê°œì„ 
            enhanced_result = self._parse_llm_response(llm_response, basic_result)
            
            return enhanced_result
            
        except Exception as e:
            print(f"LLM ë¶„ì„ ì˜¤ë¥˜: {e}")
            # LLM ë¶„ì„ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
            basic_result.reasoning.append(f"LLM ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return basic_result
    
    def _call_azure_openai_text(self, prompt: str) -> str:
        """Azure OpenAIë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ë¶„ì„"""
        try:
            response = self.azure_processor.client.chat.completions.create(
                model=self.azure_processor.deployment_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ JIRA ì¼ê° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ JIRA í‹°ì¼“ ìƒì„± ì í•©ì„±ì„ íŒë‹¨í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.3
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            raise Exception(f"Azure OpenAI í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
    
    def _create_llm_prompt(self, text: str, basic_result: TaskAnalysisResult) -> str:
        """LLM ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ê°€ JIRA ì¼ê°(í‹°ì¼“)ìœ¼ë¡œ ìƒì„±í•˜ê¸°ì— ì í•©í•œì§€ ë¶„ì„í•´ì£¼ì„¸ìš”:

        ==== ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸ ====
        {text}

        ==== ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ====
        - ì‘ì—… ìœ í˜•: {basic_result.task_type.value}
        - ìš°ì„ ìˆœìœ„: {basic_result.priority.value}
        - ì í•©ì„±: {basic_result.eligibility.value}
        - ì‹ ë¢°ë„: {basic_result.confidence:.2f}

        ==== ë¶„ì„ ìš”ì²­ì‚¬í•­ ====
        1. ì´ í…ìŠ¤íŠ¸ê°€ ì‹¤ì œ ê°œë°œ/ì‘ì—…ì´ í•„ìš”í•œ êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ì¸ê°€?
        2. JIRA í‹°ì¼“ìœ¼ë¡œ ë§Œë“¤ê¸°ì— ì¶©ë¶„íˆ ëª…í™•í•œê°€?
        3. ìš°ì„ ìˆœìœ„ì™€ ì‘ì—… ìœ í˜•ì´ ì ì ˆí•œê°€?
        4. ê°œì„ ëœ ì œëª©ê³¼ ì„¤ëª…ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
        5. ì˜ˆìƒ ì‘ì—… ì‹œê°„ì„ ì¶”ì •í•´ì£¼ì„¸ìš”.

        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        {{
            "is_suitable": true/false,
            "confidence": 0.0-1.0,
            "task_type": "bug_fix|feature|improvement|task|story|research|documentation",
            "priority": "critical|high|medium|low",
            "improved_title": "ê°œì„ ëœ ì œëª©",
            "improved_description": "ê°œì„ ëœ ì„¤ëª…",
            "estimated_hours": "ì˜ˆìƒ ì‹œê°„",
            "reasoning": ["ë¶„ì„ ê·¼ê±°1", "ë¶„ì„ ê·¼ê±°2", ...]
        }}
        """
        return prompt
    
    def _parse_llm_response(self, llm_response: str, basic_result: TaskAnalysisResult) -> TaskAnalysisResult:
        """LLM ì‘ë‹µ íŒŒì‹± ë° ê²°ê³¼ ê°œì„ """
        try:
            # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
            json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
            if json_match:
                llm_data = json.loads(json_match.group())
                
                # LLM ê²°ê³¼ë¡œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ê°œì„ 
                if "is_suitable" in llm_data:
                    if llm_data["is_suitable"]:
                        if basic_result.eligibility == JiraEligibility.NOT_SUITABLE:
                            basic_result.eligibility = JiraEligibility.PARTIALLY_SUITABLE
                    else:
                        basic_result.eligibility = JiraEligibility.NOT_SUITABLE
                
                if "confidence" in llm_data:
                    # ê¸°ë³¸ ë¶„ì„ê³¼ LLM ë¶„ì„ì˜ í‰ê· 
                    basic_result.confidence = (basic_result.confidence + llm_data["confidence"]) / 2
                
                if "improved_title" in llm_data:
                    basic_result.suggested_title = llm_data["improved_title"]
                
                if "improved_description" in llm_data:
                    basic_result.suggested_description = llm_data["improved_description"]
                
                if "estimated_hours" in llm_data:
                    basic_result.estimated_effort = llm_data["estimated_hours"]
                
                if "reasoning" in llm_data:
                    basic_result.reasoning.extend(llm_data["reasoning"])
            
            basic_result.reasoning.append("LLM ê³ ë„í™” ë¶„ì„ ì™„ë£Œ")
            
        except Exception as e:
            basic_result.reasoning.append(f"LLM ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        
        return basic_result


def analyze_jira_eligibility(text: str, use_llm: bool = False, 
                            azure_processor: Optional[AzureOpenAIImageProcessor] = None) -> TaskAnalysisResult:
    """
    í¸ì˜ í•¨ìˆ˜: í…ìŠ¤íŠ¸ì˜ JIRA ì¼ê° ì í•©ì„± ë¶„ì„
    
    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸
        use_llm: LLM ì‚¬ìš© ì—¬ë¶€
        azure_processor: Azure OpenAI í”„ë¡œì„¸ì„œ
    
    Returns:
        TaskAnalysisResult: ë¶„ì„ ê²°ê³¼
    """
    analyzer = JiraTaskAnalyzer(use_llm=use_llm, azure_processor=azure_processor)
    return analyzer.analyze_text(text)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì˜ˆì œ
    test_texts = [
        "ë¡œê·¸ì¸ ë²„íŠ¼ì´ ì•ˆ ëˆŒëŸ¬ì ¸ìš”. ê³ ì³ì£¼ì„¸ìš”.",
        "ì‚¬ìš©ìê°€ í”„ë¡œí•„ ì‚¬ì§„ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.",
        "ì„±ëŠ¥ì´ ì¢€ ëŠë¦° ê²ƒ ê°™ì•„ìš”. ë­”ê°€ ê°œì„ í•  ë°©ë²•ì´ ìˆì„ê¹Œìš”?",
        "ì ì‹¬ ë­ ë¨¹ì„ê¹Œìš”?",
        "API ì‘ë‹µ ì‹œê°„ì„ 2ì´ˆì—ì„œ 500msë¡œ ê°œì„ í•´ì•¼ í•©ë‹ˆë‹¤. ìºì‹± ë¡œì§ ì¶”ê°€ ê²€í†  í•„ìš”.",
        "ìƒˆë¡œìš´ ê²°ì œ ì‹œìŠ¤í…œ ì—°ë™ì„ ìœ„í•œ ê¸°ìˆ  ì¡°ì‚¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. PGì‚¬ 3ê³³ ë¹„êµ ë¶„ì„ í›„ ë³´ê³ ì„œ ì‘ì„±."
    ]
    
    print("ğŸ¯ JIRA ì¼ê° ì í•©ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    analyzer = JiraTaskAnalyzer(use_llm=False)  # ê¸°ë³¸ ë¶„ì„ë§Œ ì‚¬ìš©
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ {i}: {text}")
        result = analyzer.analyze_text(text)
        
        print(f"   ğŸ¯ ì í•©ì„±: {result.eligibility.value} (ì‹ ë¢°ë„: {result.confidence:.2f})")
        print(f"   ğŸ“‹ ì‘ì—… ìœ í˜•: {result.task_type.value}")
        print(f"   âš¡ ìš°ì„ ìˆœìœ„: {result.priority.value}")
        print(f"   ğŸ’¡ ì œì•ˆ ì œëª©: {result.suggested_title}")
        print(f"   â±ï¸  ì˜ˆìƒ ì‘ì—…ì‹œê°„: {result.estimated_effort}")
        print(f"   ğŸ·ï¸  íƒœê·¸: {', '.join(result.tags)}")
        if result.blockers:
            print(f"   ğŸš« ë¸”ë¡œì»¤: {', '.join(result.blockers)}")
        print(f"   ğŸ“Š ë¶„ì„ ê·¼ê±°: {', '.join(result.reasoning[:3])}")