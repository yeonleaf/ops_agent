#!/usr/bin/env python3
"""
í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë“ˆ
LLMì„ ì´ìš©í•˜ì—¬ ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ BM25 ê²€ìƒ‰ì— ì í•©í•œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import logging
from typing import List, Optional
from langchain_openai import AzureChatOpenAI
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

logger = logging.getLogger(__name__)

class KeywordExtractor:
    """
    LLMì„ ì´ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œê¸°
    ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ BM25 ê²€ìƒ‰ì— ì í•©í•œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """í‚¤ì›Œë“œ ì¶”ì¶œê¸° ì´ˆê¸°í™”"""
        self.llm = None
        self._init_llm()
    
    def _init_llm(self):
        """Azure OpenAI LLM ì´ˆê¸°í™”"""
        try:
            self.llm = AzureChatOpenAI(
                azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-4.1"),
                api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-10-21"),
                azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
                api_key=os.getenv("AZURE_OPENAI_API_KEY"),
                temperature=0,  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
                max_tokens=100  # í‚¤ì›Œë“œ ì¶”ì¶œì´ë¯€ë¡œ ì§§ì€ ì‘ë‹µ
            )
            logger.info("âœ… í‚¤ì›Œë“œ ì¶”ì¶œìš© Azure OpenAI LLM ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œìš© LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.llm = None
    
    def extract_keywords(self, query: str) -> List[str]:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            query: ì‚¬ìš©ìì˜ ì›ë³¸ ì¿¼ë¦¬
            
        Returns:
            ì¶”ì¶œëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.llm:
            logger.warning("âš ï¸ LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return self._fallback_keyword_extraction(query)
        
        try:
            # í‚¤ì›Œë“œ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
            prompt = self._create_keyword_extraction_prompt(query)
            
            # LLM í˜¸ì¶œ
            response = self.llm.invoke(prompt)
            keywords_text = response.content.strip()
            
            # í‚¤ì›Œë“œ íŒŒì‹±
            keywords = self._parse_keywords(keywords_text)
            
            logger.info(f"ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ: '{query}' -> {keywords}")
            return keywords
            
        except Exception as e:
            logger.error(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return self._fallback_keyword_extraction(query)
    
    def _create_keyword_extraction_prompt(self, query: str) -> str:
        """í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""ë‹¹ì‹ ì€ ê²€ìƒ‰ ì¿¼ë¦¬ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ, í‚¤ì›Œë“œ ê²€ìƒ‰(BM25)ì— ì‚¬ìš©í•˜ê¸°ì— ê°€ì¥ ì í•©í•œ í•µì‹¬ ëª…ì‚¬, ê³ ìœ ëª…ì‚¬, ê¸°ìˆ  ìš©ì–´ë¥¼ 3~5ê°œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ë‹µë³€ì€ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë‹¨ì–´ ëª©ë¡ìœ¼ë¡œë§Œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

ì…ë ¥: {query}
ì¶œë ¥:"""
    
    def _parse_keywords(self, keywords_text: str) -> List[str]:
        """LLM ì‘ë‹µì—ì„œ í‚¤ì›Œë“œë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        try:
            # ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ê³  ê³µë°± ì œê±°
            keywords = [keyword.strip() for keyword in keywords_text.split(',')]
            
            # ë¹ˆ ë¬¸ìì—´ ì œê±°
            keywords = [keyword for keyword in keywords if keyword]
            
            # 3~5ê°œë¡œ ì œí•œ
            keywords = keywords[:5]
            
            # ìµœì†Œ 3ê°œê°€ ë˜ë„ë¡ ë³´ì¥
            if len(keywords) < 3:
                logger.warning(f"âš ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ 3ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤: {keywords}")
            
            return keywords
            
        except Exception as e:
            logger.error(f"âŒ í‚¤ì›Œë“œ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []
    
    def _fallback_keyword_extraction(self, query: str) -> List[str]:
        """LLM ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        try:
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬)
            words = query.split()
            
            # ë¶ˆìš©ì–´ ì œê±° (ê°„ë‹¨í•œ ë²„ì „)
            stop_words = {'ìˆë‚˜ìš”', 'ìˆë‚˜', 'ìˆì–´ìš”', 'ìˆìŠµë‹ˆë‹¤', 'ìˆìŠµë‹ˆê¹Œ', 'ë¬¸ì œ', 'ë„ì›€ì´', 'í•„ìš”í•©ë‹ˆë‹¤', 'ê´€ë ¨', 'ì–´ë””', 'ì–´ë–¤', 'ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–¸ì œ', 'ì–´ëŠ', 'ì´', 'ê·¸', 'ì €', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ë¡œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼', 'ì˜', 'ëŠ”', 'ì€', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ë¡œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼', 'ì˜', 'ëŠ”', 'ì€'}
            
            keywords = [word for word in words if word not in stop_words and len(word) > 1]
            
            # 3~5ê°œë¡œ ì œí•œ
            keywords = keywords[:5]
            
            # ìµœì†Œ 3ê°œê°€ ë˜ë„ë¡ ë³´ì¥
            if len(keywords) < 3:
                keywords = words[:3]  # ì›ë³¸ ë‹¨ì–´ ì‚¬ìš©
            
            logger.info(f"ğŸ” ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ: '{query}' -> {keywords}")
            return keywords
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ['ê²€ìƒ‰', 'ì¿¼ë¦¬', 'ë¬¸ì œ']  # ìµœí›„ì˜ ìˆ˜ë‹¨

def create_keyword_extractor() -> KeywordExtractor:
    """KeywordExtractor ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return KeywordExtractor()
