"""ì ì‘í˜• íŒŒì¼ í”„ë¡œì„¸ì„œ - í˜ì´ì§€ë³„ë¡œ ìµœì ì˜ ì²˜ë¦¬ ë°©ì‹ ì„ íƒ"""

import os
import tempfile
import json
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import fitz  # PyMuPDF
from docx import Document
from pptx import Presentation
import pandas as pd

from module.image_to_text import AzureOpenAIImageProcessor
from module.types import DocumentType, ContentType, ElementType, ClassificationResult
from module.page_analyzer import PageContentAnalyzer
from module.file_processor import DocumentElement, ProcessedPage, TextBasedProcessor, LayoutBasedProcessor


class AdaptiveFileProcessor:
    """í˜ì´ì§€ë³„ë¡œ ìµœì ì˜ ì²˜ë¦¬ ë°©ì‹ì„ ì„ íƒí•˜ëŠ” ì ì‘í˜• íŒŒì¼ í”„ë¡œì„¸ì„œ"""
    
    def __init__(self, azure_processor: AzureOpenAIImageProcessor):
        self.azure_processor = azure_processor
        self.page_analyzer = PageContentAnalyzer()
        self.text_processor = TextBasedProcessor(azure_processor)
        self.layout_processor = LayoutBasedProcessor(azure_processor)
        self.temp_storage = {}
        
        # ì²˜ë¦¬ í†µê³„
        self.processing_stats = {
            "text_based_pages": 0,
            "layout_based_pages": 0,
            "total_pages": 0,
            "page_classifications": []
        }
    
    def process_file_adaptive(self, file_path: str, doc_type: DocumentType) -> Dict[str, Any]:
        """íŒŒì¼ì„ í˜ì´ì§€ë³„ ì ì‘í˜• ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            print(f"\nğŸš€ ì ì‘í˜• ì²˜ë¦¬ ì‹œì‘: {file_path}")
            print(f"ğŸ“„ íŒŒì¼ íƒ€ì…: {doc_type.value}")
            
            # í˜ì´ì§€ë³„ ì²˜ë¦¬
            if doc_type == DocumentType.PDF:
                processed_pages = self._process_pdf_adaptive(file_path)
            elif doc_type == DocumentType.DOCX:
                processed_pages = self._process_docx_adaptive(file_path)
            elif doc_type == DocumentType.PPTX:
                processed_pages = self._process_pptx_adaptive(file_path)
            elif doc_type == DocumentType.XLSX:
                processed_pages = self._process_xlsx_adaptive(file_path)
            elif doc_type == DocumentType.XML:
                processed_pages = self.text_processor._process_xml_file(file_path)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {doc_type}")
            
            # ì „ì²´ ê²°ê³¼ ìƒì„±
            result = {
                "file_path": file_path,
                "file_type": doc_type.value,
                "processing_mode": "adaptive",
                "processed_pages": [page.to_dict() for page in processed_pages],
                "total_pages": len(processed_pages),
                "processing_stats": self.processing_stats,
                "processing_timestamp": str(pd.Timestamp.now())
            }
            
            # ì²˜ë¦¬ í†µê³„ ì¶œë ¥
            self._print_processing_summary()
            
            # ì„ì‹œ ì €ì¥
            self._save_to_temp_storage(file_path, result)
            
            return result
            
        except Exception as e:
            print(f"âŒ ì ì‘í˜• ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def _process_pdf_adaptive(self, file_path: str) -> List[ProcessedPage]:
        """PDFë¥¼ í˜ì´ì§€ë³„ ì ì‘í˜•ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            doc = fitz.open(file_path)
            processed_pages = []
            
            for page_num in range(1, len(doc) + 1):
                print(f"ğŸ“„ í˜ì´ì§€ {page_num}/{len(doc)} ë¶„ì„ ì¤‘...")
                
                # í˜ì´ì§€ë³„ ì½˜í…ì¸  ë¶„ì„
                classification = self.page_analyzer.analyze_pdf_page(file_path, page_num)
                self._update_stats(page_num, classification)
                
                # ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬
                if classification.content_type == ContentType.TEXT_BASED:
                    page = self._process_pdf_page_text_based(doc, page_num - 1, classification)
                else:
                    page = self._process_pdf_page_layout_based(file_path, page_num, classification)
                
                processed_pages.append(page)
            
            doc.close()
            return processed_pages
            
        except Exception as e:
            print(f"PDF ì ì‘í˜• ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []
    
    def _process_docx_adaptive(self, file_path: str) -> List[ProcessedPage]:
        """DOCXë¥¼ í˜ì´ì§€ë³„ ì ì‘í˜•ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            doc = Document(file_path)
            processed_pages = []
            
            # ë¬¸ë‹¨ì„ í˜ì´ì§€ë¡œ ë¶„í•  (ëŒ€ëµì )
            paragraphs_per_page = 12
            total_paragraphs = len(doc.paragraphs)
            total_pages = (total_paragraphs + paragraphs_per_page - 1) // paragraphs_per_page
            
            for page_num in range(1, total_pages + 1):
                print(f"ğŸ“„ í˜ì´ì§€ {page_num}/{total_pages} ë¶„ì„ ì¤‘...")
                
                # í˜ì´ì§€ë³„ ì½˜í…ì¸  ë¶„ì„
                classification = self.page_analyzer.analyze_docx_page(file_path, page_num)
                self._update_stats(page_num, classification)
                
                # ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬
                if classification.content_type == ContentType.TEXT_BASED:
                    page = self._process_docx_page_text_based(doc, page_num, paragraphs_per_page, classification)
                else:
                    page = self._process_docx_page_layout_based(file_path, page_num, classification)
                
                processed_pages.append(page)
            
            return processed_pages
            
        except Exception as e:
            print(f"DOCX ì ì‘í˜• ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []
    
    def _process_pptx_adaptive(self, file_path: str) -> List[ProcessedPage]:
        """PPTXë¥¼ ìŠ¬ë¼ì´ë“œë³„ ì ì‘í˜•ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            prs = Presentation(file_path)
            processed_pages = []
            
            for slide_num in range(1, len(prs.slides) + 1):
                print(f"ğŸ“Š ìŠ¬ë¼ì´ë“œ {slide_num}/{len(prs.slides)} ë¶„ì„ ì¤‘...")
                
                # ìŠ¬ë¼ì´ë“œë³„ ì½˜í…ì¸  ë¶„ì„
                classification = self.page_analyzer.analyze_pptx_slide(file_path, slide_num)
                self._update_stats(slide_num, classification)
                
                # ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬
                if classification.content_type == ContentType.TEXT_BASED:
                    page = self._process_pptx_slide_text_based(prs, slide_num - 1, classification)
                else:
                    page = self._process_pptx_slide_layout_based(file_path, slide_num, classification)
                
                processed_pages.append(page)
            
            return processed_pages
            
        except Exception as e:
            print(f"PPTX ì ì‘í˜• ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []
    
    def _process_xlsx_adaptive(self, file_path: str) -> List[ProcessedPage]:
        """XLSXë¥¼ ì‹œíŠ¸ë³„ ì ì‘í˜•ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            from openpyxl import load_workbook
            wb = load_workbook(file_path, data_only=True)
            processed_pages = []
            
            for sheet_num in range(1, len(wb.sheetnames) + 1):
                print(f"ğŸ“‹ ì‹œíŠ¸ {sheet_num}/{len(wb.sheetnames)} ë¶„ì„ ì¤‘...")
                
                # ì‹œíŠ¸ë³„ ì½˜í…ì¸  ë¶„ì„
                classification = self.page_analyzer.analyze_xlsx_sheet(file_path, sheet_num)
                self._update_stats(sheet_num, classification)
                
                # Excelì€ ëŒ€ë¶€ë¶„ text-basedë¡œ ì²˜ë¦¬
                page = self._process_xlsx_sheet_text_based(wb, sheet_num, classification)
                processed_pages.append(page)
            
            wb.close()
            return processed_pages
            
        except Exception as e:
            print(f"XLSX ì ì‘í˜• ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []
    
    def _process_pdf_page_text_based(self, doc: fitz.Document, page_idx: int, 
                                    classification: ClassificationResult) -> ProcessedPage:
        """PDF í˜ì´ì§€ë¥¼ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            page = doc[page_idx]
            text = page.get_text()
            
            elements = [DocumentElement(
                ElementType.TEXT,
                text,
                {
                    "page_number": page_idx + 1,
                    "source": "pdf_text_extraction",
                    "classification": classification.content_type.value,
                    "confidence": classification.confidence,
                    "reasoning": classification.reasoning[:3]
                }
            )]
            
            return ProcessedPage(
                page_idx + 1, elements, "page",
                {
                    "file_type": "pdf",
                    "processing_method": "text_based",
                    "classification": classification.content_type.value,
                    "confidence": classification.confidence
                }
            )
            
        except Exception as e:
            print(f"PDF í˜ì´ì§€ {page_idx + 1} í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return ProcessedPage(page_idx + 1, [], "page", {"error": str(e)})
    
    def _process_pdf_page_layout_based(self, file_path: str, page_num: int, 
                                      classification: ClassificationResult) -> ProcessedPage:
        """PDF í˜ì´ì§€ë¥¼ ë ˆì´ì•„ì›ƒ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬ (ì´ë¯¸ì§€ ë³€í™˜ í›„ GPT Vision)"""
        try:
            # ë‹¨ì¼ í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            doc = fitz.open(file_path)
            page = doc[page_num - 1]
            
            # ì´ë¯¸ì§€ë¡œ ë³€í™˜
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x í•´ìƒë„
            img_data = pix.tobytes("png")
            
            # GPT Visionìœ¼ë¡œ ì²˜ë¦¬
            try:
                vision_result = self.azure_processor.process_image_from_bytes(
                    img_data, 
                    f"í˜ì´ì§€ {page_num}ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  í‘œë‚˜ ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                )
                
                elements = [DocumentElement(
                    ElementType.TEXT,
                    vision_result,
                    {
                        "page_number": page_num,
                        "source": "gpt_vision",
                        "classification": classification.content_type.value,
                        "confidence": classification.confidence,
                        "reasoning": classification.reasoning[:3]
                    }
                )]
                
            except Exception as vision_error:
                print(f"GPT Vision ì²˜ë¦¬ ì˜¤ë¥˜: {vision_error}")
                # í´ë°±: í…ìŠ¤íŠ¸ ì¶”ì¶œ
                text = page.get_text()
                elements = [DocumentElement(
                    ElementType.TEXT,
                    text or "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨",
                    {
                        "page_number": page_num,
                        "source": "pdf_text_fallback",
                        "error": str(vision_error)
                    }
                )]
            
            doc.close()
            
            return ProcessedPage(
                page_num, elements, "page",
                {
                    "file_type": "pdf",
                    "processing_method": "layout_based",
                    "classification": classification.content_type.value,
                    "confidence": classification.confidence
                }
            )
            
        except Exception as e:
            print(f"PDF í˜ì´ì§€ {page_num} ë ˆì´ì•„ì›ƒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return ProcessedPage(page_num, [], "page", {"error": str(e)})
    
    def _process_docx_page_text_based(self, doc: Document, page_num: int, paragraphs_per_page: int,
                                     classification: ClassificationResult) -> ProcessedPage:
        """DOCX í˜ì´ì§€ë¥¼ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            start_idx = (page_num - 1) * paragraphs_per_page
            end_idx = min(start_idx + paragraphs_per_page, len(doc.paragraphs))
            
            page_paragraphs = doc.paragraphs[start_idx:end_idx]
            text_content = "\n".join([p.text for p in page_paragraphs if p.text.strip()])
            
            elements = [DocumentElement(
                ElementType.TEXT,
                text_content,
                {
                    "page_number": page_num,
                    "source": "docx_text_extraction",
                    "classification": classification.content_type.value,
                    "confidence": classification.confidence,
                    "paragraph_range": f"{start_idx}-{end_idx}"
                }
            )]
            
            return ProcessedPage(
                page_num, elements, "page",
                {
                    "file_type": "docx",
                    "processing_method": "text_based",
                    "classification": classification.content_type.value
                }
            )
            
        except Exception as e:
            print(f"DOCX í˜ì´ì§€ {page_num} í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return ProcessedPage(page_num, [], "page", {"error": str(e)})
    
    def _process_docx_page_layout_based(self, file_path: str, page_num: int,
                                       classification: ClassificationResult) -> ProcessedPage:
        """DOCX í˜ì´ì§€ë¥¼ ë ˆì´ì•„ì›ƒ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬ (PDF ë³€í™˜ í›„ ì´ë¯¸ì§€ ì²˜ë¦¬)"""
        try:
            # DOCXë¥¼ PDFë¡œ ë³€í™˜ í›„ í•´ë‹¹ í˜ì´ì§€ë§Œ ì´ë¯¸ì§€ë¡œ ì²˜ë¦¬
            # ì„ì‹œ PDF ìƒì„±
            temp_dir = "temp_pdfs"
            os.makedirs(temp_dir, exist_ok=True)
            pdf_path = os.path.join(temp_dir, f"temp_docx_page_{page_num}.pdf")
            
            # LibreOfficeë¡œ ë³€í™˜ (ê¸°ì¡´ ë ˆì´ì•„ì›ƒ í”„ë¡œì„¸ì„œ í™œìš©)
            self.layout_processor._convert_docx_to_pdf(file_path, pdf_path)
            
            # PDFì˜ í•´ë‹¹ í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ì²˜ë¦¬
            result_page = self._process_pdf_page_layout_based(pdf_path, page_num, classification)
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            result_page.metadata["original_file_type"] = "docx"
            result_page.metadata["converted_via"] = "pdf"
            
            return result_page
            
        except Exception as e:
            print(f"DOCX í˜ì´ì§€ {page_num} ë ˆì´ì•„ì›ƒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            # í´ë°±: í…ìŠ¤íŠ¸ ê¸°ë°˜ ì²˜ë¦¬
            return self._process_docx_page_text_based(Document(file_path), page_num, 12, classification)
    
    def _process_pptx_slide_text_based(self, prs: Presentation, slide_idx: int,
                                      classification: ClassificationResult) -> ProcessedPage:
        """PPTX ìŠ¬ë¼ì´ë“œë¥¼ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            slide = prs.slides[slide_idx]
            text_content = ""
            
            for shape in slide.shapes:
                if hasattr(shape, "text") and shape.text.strip():
                    text_content += shape.text.strip() + "\n"
            
            elements = [DocumentElement(
                ElementType.TEXT,
                text_content,
                {
                    "page_number": slide_idx + 1,
                    "source": "pptx_text_extraction",
                    "classification": classification.content_type.value,
                    "confidence": classification.confidence
                }
            )]
            
            return ProcessedPage(
                slide_idx + 1, elements, "slide",
                {
                    "file_type": "pptx",
                    "processing_method": "text_based",
                    "classification": classification.content_type.value
                }
            )
            
        except Exception as e:
            print(f"PPTX ìŠ¬ë¼ì´ë“œ {slide_idx + 1} í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return ProcessedPage(slide_idx + 1, [], "slide", {"error": str(e)})
    
    def _process_pptx_slide_layout_based(self, file_path: str, slide_num: int,
                                        classification: ClassificationResult) -> ProcessedPage:
        """PPTX ìŠ¬ë¼ì´ë“œë¥¼ ë ˆì´ì•„ì›ƒ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            # PPTXë¥¼ PDFë¡œ ë³€í™˜ í›„ í•´ë‹¹ ìŠ¬ë¼ì´ë“œë§Œ ì´ë¯¸ì§€ë¡œ ì²˜ë¦¬
            temp_dir = "temp_pdfs"
            os.makedirs(temp_dir, exist_ok=True)
            pdf_path = os.path.join(temp_dir, f"temp_pptx_slide_{slide_num}.pdf")
            
            # PPTXë¥¼ PDFë¡œ ë³€í™˜
            self.layout_processor._convert_pptx_to_pdf(file_path, pdf_path)
            
            # PDFì˜ í•´ë‹¹ ìŠ¬ë¼ì´ë“œë¥¼ ì´ë¯¸ì§€ë¡œ ì²˜ë¦¬
            result_page = self._process_pdf_page_layout_based(pdf_path, slide_num, classification)
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            result_page.metadata["original_file_type"] = "pptx"
            result_page.metadata["converted_via"] = "pdf"
            result_page.page_type = "slide"
            
            return result_page
            
        except Exception as e:
            print(f"PPTX ìŠ¬ë¼ì´ë“œ {slide_num} ë ˆì´ì•„ì›ƒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            # í´ë°±: í…ìŠ¤íŠ¸ ê¸°ë°˜ ì²˜ë¦¬
            return self._process_pptx_slide_text_based(Presentation(file_path), slide_num - 1, classification)
    
    def _process_xlsx_sheet_text_based(self, wb, sheet_num: int,
                                      classification: ClassificationResult) -> ProcessedPage:
        """XLSX ì‹œíŠ¸ë¥¼ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            sheet_name = wb.sheetnames[sheet_num - 1]
            ws = wb[sheet_name]
            
            # ì‹œíŠ¸ ë°ì´í„°ë¥¼ í‘œë¡œ ë³€í™˜
            table_data = []
            for row in ws.iter_rows(values_only=True):
                if any(cell is not None for cell in row):
                    table_data.append([str(cell) if cell is not None else "" for cell in row])
            
            elements = [DocumentElement(
                ElementType.TABLE,
                table_data,
                {
                    "page_number": sheet_num,
                    "source": "xlsx_direct_extraction",
                    "classification": classification.content_type.value,
                    "sheet_name": sheet_name
                }
            )]
            
            return ProcessedPage(
                sheet_num, elements, "sheet",
                {
                    "file_type": "xlsx",
                    "processing_method": "text_based",
                    "sheet_name": sheet_name,
                    "classification": classification.content_type.value
                }
            )
            
        except Exception as e:
            print(f"XLSX ì‹œíŠ¸ {sheet_num} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return ProcessedPage(sheet_num, [], "sheet", {"error": str(e)})
    
    def _update_stats(self, page_num: int, classification: ClassificationResult):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.processing_stats["total_pages"] += 1
        
        if classification.content_type == ContentType.TEXT_BASED:
            self.processing_stats["text_based_pages"] += 1
        else:
            self.processing_stats["layout_based_pages"] += 1
        
        self.processing_stats["page_classifications"].append({
            "page_number": page_num,
            "content_type": classification.content_type.value,
            "confidence": classification.confidence,
            "reasoning": classification.reasoning[:2]  # ìƒìœ„ 2ê°œë§Œ
        })
        
        # ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© ì¶œë ¥
        content_type_icon = "ğŸ“" if classification.content_type == ContentType.TEXT_BASED else "ğŸ¨"
        print(f"   {content_type_icon} {classification.content_type.value} (ì‹ ë¢°ë„: {classification.confidence:.2f})")
    
    def _print_processing_summary(self):
        """ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        stats = self.processing_stats
        total = stats["total_pages"]
        text_count = stats["text_based_pages"]
        layout_count = stats["layout_based_pages"]
        
        print(f"\nğŸ“Š ì ì‘í˜• ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½")
        print(f"   ì´ í˜ì´ì§€: {total}ê°œ")
        if total > 0:
            print(f"   ğŸ“ í…ìŠ¤íŠ¸ ê¸°ë°˜: {text_count}ê°œ ({text_count/total*100:.1f}%)")
            print(f"   ğŸ¨ ë ˆì´ì•„ì›ƒ ê¸°ë°˜: {layout_count}ê°œ ({layout_count/total*100:.1f}%)")
        else:
            print(f"   ğŸ“ í…ìŠ¤íŠ¸ ê¸°ë°˜: {text_count}ê°œ")
            print(f"   ğŸ¨ ë ˆì´ì•„ì›ƒ ê¸°ë°˜: {layout_count}ê°œ")
        
        # í˜ì´ì§€ë³„ ë¶„ë¥˜ ê²°ê³¼ ê°„ëµ í‘œì‹œ (ì²˜ìŒ 10ê°œë§Œ)
        print(f"\nğŸ“„ í˜ì´ì§€ë³„ ë¶„ë¥˜ ê²°ê³¼ (ì²˜ìŒ 10ê°œ):")
        for i, classification in enumerate(stats["page_classifications"][:10]):
            page_num = classification["page_number"]
            content_type = classification["content_type"]
            confidence = classification["confidence"]
            icon = "ğŸ“" if content_type == "text_based" else "ğŸ¨"
            print(f"   í˜ì´ì§€ {page_num:2d}: {icon} {content_type} ({confidence:.2f})")
        
        if total > 10:
            print(f"   ... ë° {total - 10}ê°œ í˜ì´ì§€ ë”")
    
    def _save_to_temp_storage(self, file_path: str, result: Dict[str, Any]):
        """ê²°ê³¼ë¥¼ ì„ì‹œ ì €ì¥ì†Œì— ì €ì¥"""
        try:
            temp_dir = "temp_results"
            os.makedirs(temp_dir, exist_ok=True)
            
            filename = Path(file_path).stem
            result_filename = f"{filename}_adaptive_result.json"
            result_path = os.path.join(temp_dir, result_filename)
            
            with open(result_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“ ì ì‘í˜• ì²˜ë¦¬ ê²°ê³¼ ì €ì¥: {result_path}")
            
        except Exception as e:
            print(f"ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")