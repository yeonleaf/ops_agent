import os
import sys
import json
import tempfile
import shutil
from typing import List, Dict, Any, Optional, Tuple, Union
from enum import Enum
from pathlib import Path
import fitz  # PyMuPDF
from docx import Document
from pptx import Presentation
import pandas as pd
from openpyxl import load_workbook
import xlrd
from PIL import Image
import io
import xml.etree.ElementTree as ET
import html

from module.image_to_text import AzureOpenAIImageProcessor
from structured_chunking import JiraStructuredChunker, StructuredChunk

class DocumentType(Enum):
    """ë¬¸ì„œ íƒ€ì…"""
    DOCX = "docx"
    PPTX = "pptx"
    PDF = "pdf"
    XLSX = "xlsx"
    XLS = "xls"
    HTML = "html"
    TEXT = "text"
    XML = "xml"

class ContentType(Enum):
    """ì½˜í…ì¸  íƒ€ì… (text-based vs layout-based)"""
    TEXT_BASED = "text_based"
    LAYOUT_BASED = "layout_based"

class ElementType(Enum):
    """ë¬¸ì„œ ìš”ì†Œ íƒ€ì…"""
    TEXT = "text"
    TABLE = "table"
    IMAGE = "image"
    SHAPE = "shape"

class DocumentElement:
    """ë¬¸ì„œ ìš”ì†Œ í´ë˜ìŠ¤"""
    def __init__(self, element_type: ElementType, content: Any, metadata: Dict = None):
        self.element_type = element_type
        self.content = content
        self.metadata = metadata or {}
    
    def __str__(self):
        return f"{self.element_type.value}: {str(self.content)[:50]}..."

    def to_dict(self):
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "element_type": self.element_type.value,
            "content": self.content,
            "metadata": self.metadata
        }

class ProcessedPage:
    """ì²˜ë¦¬ëœ í˜ì´ì§€/ìŠ¬ë¼ì´ë“œ ì •ë³´"""
    def __init__(self, page_number: int, elements: List[DocumentElement], 
                 page_type: str = "page", metadata: Dict = None):
        self.page_number = page_number
        self.elements = elements
        self.page_type = page_type  # "page", "slide", "sheet"
        self.metadata = metadata or {}
    
    def to_dict(self):
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "page_number": self.page_number,
            "page_type": self.page_type,
            "elements": [elem.to_dict() for elem in self.elements],
            "metadata": self.metadata
        }

class FileTypeDetector:
    """íŒŒì¼ íƒ€ì… íŒë³„ê¸°"""
    
    @staticmethod
    def detect_file_type(file_path: str) -> DocumentType:
        """íŒŒì¼ í™•ì¥ìë¡œë¶€í„° ë¬¸ì„œ íƒ€ì… íŒë³„"""
        ext = Path(file_path).suffix.lower()
        if ext == '.docx':
            return DocumentType.DOCX
        elif ext == '.pptx':
            return DocumentType.PPTX
        elif ext == '.pdf':
            return DocumentType.PDF
        elif ext == '.xlsx':
            return DocumentType.XLSX
        elif ext == '.xls':
            return DocumentType.XLS
        elif ext == '.html':
            return DocumentType.HTML
        elif ext in ['.txt', '.md']:
            return DocumentType.TEXT
        elif ext == '.xml':
            return DocumentType.XML
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {ext}")
    
    @staticmethod
    def detect_content_type(file_path: str, doc_type: DocumentType) -> ContentType:
        """ì½˜í…ì¸ ê°€ text-basedì¸ì§€ layout-basedì¸ì§€ íŒë³„"""
        try:
            if doc_type == DocumentType.PDF:
                return FileTypeDetector._analyze_pdf_content(file_path)
            elif doc_type == DocumentType.DOCX:
                return FileTypeDetector._analyze_docx_content(file_path)
            elif doc_type == DocumentType.PPTX:
                return FileTypeDetector._analyze_pptx_content(file_path)
            elif doc_type == DocumentType.XLSX:
                return FileTypeDetector._analyze_xlsx_content(file_path)
            elif doc_type == DocumentType.XLS:
                return FileTypeDetector._analyze_xls_content(file_path)
            elif doc_type == DocumentType.XML:
                return ContentType.TEXT_BASED  # XMLì€ í•­ìƒ text-basedë¡œ ì²˜ë¦¬
            else:
                return ContentType.TEXT_BASED
        except Exception as e:
            print(f"ì½˜í…ì¸  íƒ€ì… íŒë³„ ì˜¤ë¥˜: {e}")
            return ContentType.LAYOUT_BASED  # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ layout-basedë¡œ ë¶„ë¥˜
    
    @staticmethod
    def _analyze_pdf_content(file_path: str) -> ContentType:
        """PDF ì½˜í…ì¸  ë¶„ì„"""
        try:
            doc = fitz.open(file_path)
            text_content = ""
            image_count = 0
            
            for page in doc:
                text_content += page.get_text()
                image_list = page.get_images()
                image_count += len(image_list)
            
            doc.close()
            
            # í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•˜ê³  ì´ë¯¸ì§€ê°€ ì ìœ¼ë©´ text-based
            if len(text_content.strip()) > 100 and image_count < 3:
                return ContentType.TEXT_BASED
            else:
                return ContentType.LAYOUT_BASED
                
        except Exception:
            return ContentType.LAYOUT_BASED
    
    @staticmethod
    def _analyze_docx_content(file_path: str) -> ContentType:
        """DOCX ì½˜í…ì¸  ë¶„ì„"""
        try:
            doc = Document(file_path)
            text_content = ""
            image_count = 0
            
            for para in doc.paragraphs:
                text_content += para.text + "\n"
            
            # ì´ë¯¸ì§€ ê°œìˆ˜ í™•ì¸ (ê°„ë‹¨í•œ ë°©ë²•)
            for rel in doc.part.rels.values():
                if "image" in rel.target_ref:
                    image_count += 1
            
            if len(text_content.strip()) > 100 and image_count < 3:
                return ContentType.TEXT_BASED
            else:
                return ContentType.LAYOUT_BASED
                
        except Exception:
            return ContentType.LAYOUT_BASED
    
    @staticmethod
    def _analyze_pptx_content(file_path: str) -> ContentType:
        """PPTX ì½˜í…ì¸  ë¶„ì„"""
        try:
            prs = Presentation(file_path)
            text_content = ""
            image_count = 0
            
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text") and shape.text:
                        text_content += shape.text + "\n"
                    if shape.shape_type == 13:  # ì´ë¯¸ì§€ íƒ€ì…
                        image_count += 1
            
            if len(text_content.strip()) > 50 and image_count < 5:
                return ContentType.TEXT_BASED
            else:
                return ContentType.LAYOUT_BASED
                
        except Exception:
            return ContentType.LAYOUT_BASED
    
    @staticmethod
    def _analyze_xlsx_content(file_path: str) -> ContentType:
        """XLSX ì½˜í…ì¸  ë¶„ì„"""
        try:
            wb = load_workbook(file_path, data_only=True)
            text_content = ""
            
            for sheet_name in wb.sheetnames:
                ws = wb[sheet_name]
                for row in ws.iter_rows(values_only=True):
                    for cell in row:
                        if cell:
                            text_content += str(cell) + " "
            
            wb.close()
            
            # ì—‘ì…€ì€ ëŒ€ë¶€ë¶„ text-based
            if len(text_content.strip()) > 50:
                return ContentType.TEXT_BASED
            else:
                return ContentType.LAYOUT_BASED
                
        except Exception:
            return ContentType.LAYOUT_BASED
    
    @staticmethod
    def _analyze_xls_content(file_path: str) -> ContentType:
        """XLS ì½˜í…ì¸  ë¶„ì„"""
        try:
            wb = xlrd.open_workbook(file_path)
            text_content = ""
            
            for sheet_name in wb.sheet_names():
                sheet = wb.sheet_by_name(sheet_name)
                for row_idx in range(sheet.nrows):
                    for col_idx in range(sheet.ncols):
                        cell_value = sheet.cell_value(row_idx, col_idx)
                        if cell_value:
                            text_content += str(cell_value) + " "
            
            # XLS íŒŒì¼ì€ í•­ìƒ text-basedë¡œ ì²˜ë¦¬ (PDF ë³€í™˜ ë¶ˆê°€ëŠ¥)
            return ContentType.TEXT_BASED
                
        except Exception:
            # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ text-basedë¡œ ì²˜ë¦¬ (PDF ë³€í™˜ ë°©ì§€)
            return ContentType.TEXT_BASED

class TextBasedProcessor:
    """Text-based íŒŒì¼ ì²˜ë¦¬ê¸°"""
    
    def __init__(self, azure_processor: AzureOpenAIImageProcessor):
        self.azure_processor = azure_processor
    
    def process_docx(self, file_path: str) -> List[ProcessedPage]:
        """DOCX íŒŒì¼ì„ í˜ì´ì§€ë³„ë¡œ ì²˜ë¦¬"""
        try:
            doc = Document(file_path)
            elements = []
            
            # ë¬¸ë‹¨ë³„ë¡œ ìš”ì†Œ ì¶”ì¶œ
            for para in doc.paragraphs:
                if para.text.strip():
                    elements.append(DocumentElement(
                        ElementType.TEXT, 
                        para.text.strip(),
                        {"paragraph_style": para.style.name if para.style else "Normal"}
                    ))
            
            # í…Œì´ë¸” ì²˜ë¦¬
            for table in doc.tables:
                table_data = []
                for row in table.rows:
                    row_data = []
                    for cell in row.cells:
                        row_data.append(cell.text.strip())
                    table_data.append(row_data)
                
                if table_data:
                    elements.append(DocumentElement(
                        ElementType.TABLE,
                        table_data,
                        {"table_type": "docx_table"}
                    ))
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            for rel in doc.part.rels.values():
                if "image" in rel.target_ref:
                    try:
                        image_path = rel.target_path
                        elements.append(DocumentElement(
                            ElementType.IMAGE,
                            image_path,
                            {"image_source": "docx_embed"}
                        ))
                    except Exception as e:
                        print(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            
            # ë‹¨ì¼ í˜ì´ì§€ë¡œ ì²˜ë¦¬ (DOCXëŠ” í˜ì´ì§€ êµ¬ë¶„ì´ ëª…í™•í•˜ì§€ ì•ŠìŒ)
            return [ProcessedPage(1, elements, "page", {"file_type": "docx"})]
            
        except Exception as e:
            print(f"DOCX ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []
    
    def process_pptx(self, file_path: str) -> List[ProcessedPage]:
        """PPTX íŒŒì¼ì„ ìŠ¬ë¼ì´ë“œë³„ë¡œ ì²˜ë¦¬"""
        try:
            prs = Presentation(file_path)
            processed_slides = []
            
            for slide_num, slide in enumerate(prs.slides, 1):
                elements = []
                
                for shape in slide.shapes:
                    if hasattr(shape, "text") and shape.text.strip():
                        elements.append(DocumentElement(
                            ElementType.TEXT,
                            shape.text.strip(),
                            {"shape_type": str(shape.shape_type)}
                        ))
                    
                    if shape.shape_type == 13:  # ì´ë¯¸ì§€
                        try:
                            # ì´ë¯¸ì§€ ì¶”ì¶œ ë° ì €ì¥
                            image_path = self._extract_pptx_image(shape, slide_num, len(elements))
                            elements.append(DocumentElement(
                                ElementType.IMAGE,
                                image_path,
                                {"image_source": "pptx_slide"}
                            ))
                        except Exception as e:
                            print(f"PPTX ì´ë¯¸ì§€ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
                
                processed_slides.append(ProcessedPage(
                    slide_num, elements, "slide", 
                    {"file_type": "pptx", "slide_layout": slide.slide_layout.name}
                ))
            
            return processed_slides
            
        except Exception as e:
            print(f"PPTX ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []
    
    def process_xlsx(self, file_path: str) -> List[ProcessedPage]:
        """XLSX íŒŒì¼ì„ ì‹œíŠ¸ë³„ë¡œ ì²˜ë¦¬"""
        try:
            wb = load_workbook(file_path, data_only=True)
            processed_sheets = []
            
            for sheet_num, sheet_name in enumerate(wb.sheetnames, 1):
                ws = wb[sheet_name]
                elements = []
                
                # ì‹œíŠ¸ ë°ì´í„°ë¥¼ í‘œë¡œ ë³€í™˜
                table_data = []
                for row in ws.iter_rows(values_only=True):
                    if any(cell is not None for cell in row):
                        table_data.append([str(cell) if cell is not None else "" for cell in row])
                
                if table_data:
                    elements.append(DocumentElement(
                        ElementType.TABLE,
                        table_data,
                        {"table_type": "xlsx_sheet", "sheet_name": sheet_name}
                    ))
                
                processed_sheets.append(ProcessedPage(
                    sheet_num, elements, "sheet",
                    {"file_type": "xlsx", "sheet_name": sheet_name}
                ))
            
            wb.close()
            return processed_sheets
            
        except Exception as e:
            print(f"XLSX ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []
    
    def process_xls(self, file_path: str) -> List[ProcessedPage]:
        """XLS íŒŒì¼ì„ ì‹œíŠ¸ë³„ë¡œ ì²˜ë¦¬"""
        try:
            # íŒŒì¼ ë‚´ìš© í™•ì¸ (HTML íŒŒì¼ì¸ì§€ ì²´í¬)
            with open(file_path, 'rb') as f:
                first_bytes = f.read(100)
                if b'<html' in first_bytes.lower() or b'<!doctype' in first_bytes.lower():
                    print(f"âš ï¸ íŒŒì¼ì´ HTML í˜•ì‹ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤: {file_path}")
                    return self.process_html(file_path)
            
            wb = xlrd.open_workbook(file_path)
            processed_sheets = []
            
            for sheet_num, sheet_name in enumerate(wb.sheet_names(), 1):
                sheet = wb.sheet_by_name(sheet_name)
                elements = []
                
                # ì‹œíŠ¸ ë°ì´í„°ë¥¼ í‘œë¡œ ë³€í™˜
                table_data = []
                for row_idx in range(sheet.nrows):
                    row_data = []
                    for col_idx in range(sheet.ncols):
                        cell_value = sheet.cell_value(row_idx, col_idx)
                        row_data.append(str(cell_value) if cell_value else "")
                    
                    if any(cell for cell in row_data):
                        table_data.append(row_data)
                
                if table_data:
                    elements.append(DocumentElement(
                        ElementType.TABLE,
                        table_data,
                        {"table_type": "xls_sheet", "sheet_name": sheet_name}
                    ))
                
                processed_sheets.append(ProcessedPage(
                    sheet_num, elements, "sheet",
                    {"file_type": "xls", "sheet_name": sheet_name}
                ))
            
            return processed_sheets
            
        except Exception as e:
            print(f"XLS ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            # XLS íŒŒì¼ì´ ì•„ë‹Œ ê²½ìš° í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬ ì‹œë„
            try:
                print(f"ğŸ”„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì²˜ë¦¬ ì‹œë„: {file_path}")
                return self._process_html_as_text(file_path)
            except Exception as e2:
                print(f"í…ìŠ¤íŠ¸ ì²˜ë¦¬ë„ ì‹¤íŒ¨: {e2}")
                return []
    
    def _refine_text_with_unstructured(self, text: str) -> str:
        """ê° í–‰ì˜ í…ìŠ¤íŠ¸ë¥¼ Unstructuredë¡œ ì •ì œ"""
        try:
            from unstructured.partition.text import partition_text
            
            # í…ìŠ¤íŠ¸ë¥¼ Unstructuredë¡œ ì •ì œ
            elements = partition_text(text=text)
            
            # ì •ì œëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            refined_parts = []
            for element in elements:
                if hasattr(element, 'text') and element.text:
                    refined_parts.append(element.text.strip())
            
            if refined_parts:
                refined_text = ' '.join(refined_parts)
                if len(refined_text) > len(text) * 0.8:  # ì›ë³¸ì˜ 80% ì´ìƒì´ë©´ ì‚¬ìš©
                    return refined_text
            
            # Unstructured ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
            return text
            
        except Exception as e:
            print(f"   âš ï¸ Unstructured ì •ì œ ì‹¤íŒ¨: {e}")
            return text

    def _process_html_table_by_rows(self, file_path: str) -> List[ProcessedPage]:
        """HTML í…Œì´ë¸”ì„ í–‰ë³„ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬ (ê° í‹°ì¼“ì„ ê°œë³„ ì²­í¬ë¡œ)"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            print(f"ğŸ” HTML íŒŒì¼ ë‚´ìš© ê¸¸ì´: {len(content)}ì")
            print(f"ğŸ” HTML íŒŒì¼ ì²« 200ì: {content[:200]}")
            
            # BeautifulSoupìœ¼ë¡œ HTML í…Œì´ë¸” íŒŒì‹±
            from bs4 import BeautifulSoup
            
            print("ğŸ”§ BeautifulSoupìœ¼ë¡œ HTML í…Œì´ë¸” íŒŒì‹± ì‹œë„...")
            soup = BeautifulSoup(content, 'html.parser')
            
            # í…Œì´ë¸” ì°¾ê¸° (ëª¨ë“  í…Œì´ë¸” ì¤‘ ê°€ì¥ í° ê²ƒ ì„ íƒ)
            tables = soup.find_all('table')
            if not tables:
                print("âš ï¸ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬")
                raise Exception("No table found")
            
            # ê°€ì¥ ë§ì€ í–‰ì„ ê°€ì§„ í…Œì´ë¸” ì°¾ê¸° (ì‹¤ì œ ë°ì´í„° í…Œì´ë¸”)
            table_info = [(i, t, len(t.find_all('tr'))) for i, t in enumerate(tables)]
            table_info.sort(key=lambda x: x[2], reverse=True)  # í–‰ ìˆ˜ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            
            print(f"ğŸ” í…Œì´ë¸” ë¶„ì„:")
            for i, (table_idx, table, row_count) in enumerate(table_info):
                print(f"   í…Œì´ë¸” {table_idx+1}: {row_count}í–‰")
            
            # ê°€ì¥ ë§ì€ í–‰ì„ ê°€ì§„ í…Œì´ë¸” ì„ íƒ
            table = table_info[0][1]
            selected_table_idx = table_info[0][0]
            selected_row_count = table_info[0][2]
            print(f"âœ… ì„ íƒëœ í…Œì´ë¸”: í…Œì´ë¸” {selected_table_idx+1} ({selected_row_count}í–‰)")
            
            # í…Œì´ë¸” í–‰ë“¤ ì¶”ì¶œ
            rows = table.find_all('tr')
            print(f"ğŸ” ë°œê²¬ëœ í…Œì´ë¸” í–‰ ìˆ˜: {len(rows)}")
            
            if len(rows) < 2:
                print("âš ï¸ ë°ì´í„° í–‰ì´ ì—†ìŒ, ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬")
                raise Exception("No data rows found")
            
            # í—¤ë” í–‰ê³¼ ë°ì´í„° í–‰ ë¶„ë¦¬
            header_row = rows[0]
            data_rows = rows[1:]
            
            # í—¤ë” ì¶”ì¶œ (ë” ê°•ë ¥í•œ ë°©ë²•)
            headers = []
            for cell in header_row.find_all(['td', 'th']):
                header_text = cell.get_text(strip=True)
                if header_text:
                    headers.append(header_text)
            
            # í—¤ë”ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ë°ì´í„° í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©
            if not headers and data_rows:
                print("âš ï¸ í—¤ë”ê°€ ë¹„ì–´ìˆìŒ, ì²« ë²ˆì§¸ ë°ì´í„° í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©")
                first_data_row = data_rows[0]
                for cell in first_data_row.find_all(['td', 'th']):
                    header_text = cell.get_text(strip=True)
                    if header_text:
                        headers.append(header_text)
                data_rows = data_rows[1:]  # ì²« ë²ˆì§¸ ë°ì´í„° í–‰ ì œê±°
            
            # ì—¬ì „íˆ í—¤ë”ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í—¤ë” ì‚¬ìš©
            if not headers:
                print("âš ï¸ í—¤ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, ê¸°ë³¸ í—¤ë” ì‚¬ìš©")
                headers = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']
            
            print(f"ğŸ” í…Œì´ë¸” í—¤ë”: {headers}")
            print(f"ğŸ” ë°ì´í„° í–‰ ìˆ˜: {len(data_rows)}")
            
            # ê° í–‰ì˜ ì…€ ìˆ˜ í™•ì¸
            if data_rows:
                first_data_cells = data_rows[0].find_all(['td', 'th'])
                print(f"ğŸ” ì²« ë²ˆì§¸ ë°ì´í„° í–‰ì˜ ì…€ ìˆ˜: {len(first_data_cells)}")
                print(f"ğŸ” ì²« ë²ˆì§¸ ë°ì´í„° í–‰ ë‚´ìš©: {[cell.get_text(strip=True) for cell in first_data_cells]}")
            
            # ê° ë°ì´í„° í–‰ì„ ê°œë³„ ì²­í¬ë¡œ ì²˜ë¦¬
            processed_elements = []
            
            for row_idx, row in enumerate(data_rows):
                # í–‰ì˜ ì…€ë“¤ ì¶”ì¶œ
                cells = row.find_all(['td', 'th'])
                if len(cells) == 0:
                    continue
                
                # ì…€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                row_data = []
                for cell in cells:
                    cell_text = cell.get_text(strip=True)
                    if cell_text:
                        row_data.append(cell_text)
                
                if len(row_data) == 0:
                    continue
                
                # í—¤ë”ì™€ ë°ì´í„°ë¥¼ ë§¤í•‘í•˜ì—¬ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ìƒì„±
                ticket_text = ""
                for i, cell_text in enumerate(row_data):
                    if i < len(headers):
                        ticket_text += f"{headers[i]}: {cell_text} "
                    else:
                        ticket_text += f"{cell_text} "
                
                ticket_text = ticket_text.strip()
                
                if len(ticket_text) > 10:  # ì˜ë¯¸ìˆëŠ” ë°ì´í„°ë§Œ ì²˜ë¦¬
                    # ê° í–‰ì— Unstructured ì ìš©í•˜ì—¬ ì •ì œ
                    refined_text = self._refine_text_with_unstructured(ticket_text)
                    
                    print(f"   ğŸ“ í–‰ {row_idx + 1}: {refined_text[:100]}...")
                    
                    # ê° í‹°ì¼“ì„ ê°œë³„ ìš”ì†Œë¡œ ìƒì„±
                    element = DocumentElement(
                        ElementType.TEXT,
                        refined_text,
                        {
                            "source": "html_table_row",
                            "row_index": row_idx + 1,
                            "headers": headers,
                            "cell_count": len(row_data),
                            "unstructured_refined": True
                        }
                    )
                    processed_elements.append(element)
            
            if len(processed_elements) == 0:
                print("âš ï¸ ì²˜ë¦¬ëœ í–‰ì´ ì—†ìŒ, ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬")
                raise Exception("No processed rows")
            
            print(f"âœ… {len(processed_elements)}ê°œ í‹°ì¼“ í–‰ ì²˜ë¦¬ ì™„ë£Œ")
            
            # ê²°ê³¼ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            import tempfile
            import json
            from datetime import datetime
            temp_dir = "temp_results"
            os.makedirs(temp_dir, exist_ok=True)
            
            result = {
                "file_path": file_path,
                "file_type": "html",
                "content_type": "text_based",
                "processed_pages": [{
                    "page_number": 1,
                    "page_type": "table",
                    "elements": [{
                        "element_type": "text",
                        "content": elem.content,
                        "metadata": elem.metadata
                    } for elem in processed_elements],
                    "metadata": {"file_type": "html", "table_rows": len(processed_elements)}
                }],
                "total_pages": 1,
                "processing_timestamp": datetime.now().isoformat()
            }
            
            temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='_result.json', delete=False, dir=temp_dir)
            json.dump(result, temp_file, ensure_ascii=False, indent=2)
            temp_file.close()
            print(f"ê²°ê³¼ê°€ ì„ì‹œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {temp_file.name}")
            
            return [ProcessedPage(
                page_number=1, 
                elements=processed_elements, 
                page_type="table",
                metadata={"file_type": "html", "table_rows": len(processed_elements)}
            )]
            
        except Exception as e:
            print(f"âŒ HTML í…Œì´ë¸” í–‰ë³„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            import traceback
            print(f"âŒ ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
            traceback.print_exc()
            return []

    def _process_html_as_text(self, file_path: str) -> List[ProcessedPage]:
        """HTML íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬ (Jira í…Œì´ë¸” ìµœì í™”)"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            print(f"ğŸ” HTML íŒŒì¼ ë‚´ìš© ê¸¸ì´: {len(content)}ì")
            print(f"ğŸ” HTML íŒŒì¼ ì²« 200ì: {content[:200]}")
            
            # Unstructured ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì •êµí•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
            try:
                from unstructured.partition.html import partition_html
                from unstructured.staging.base import elements_to_json
                
                print("ğŸ”§ Unstructured ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ HTML íŒŒì‹± ì‹œë„...")
                
                # HTMLì„ êµ¬ì¡°í™”ëœ ìš”ì†Œë¡œ ë¶„í• 
                elements = partition_html(text=content)
                
                # í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                text_parts = []
                for element in elements:
                    if hasattr(element, 'text') and element.text:
                        text_parts.append(element.text.strip())
                
                unstructured_text = ' '.join(text_parts)
                
                print(f"ğŸ” Unstructured ì¶”ì¶œ ê²°ê³¼: {len(unstructured_text)}ì")
                print(f"ğŸ” Unstructured ì²« 200ì: {unstructured_text[:200]}")
                
                # Unstructured ê²°ê³¼ê°€ ì¶©ë¶„í•œì§€ í™•ì¸ (ìµœì†Œ 500ì ì´ìƒ)
                if unstructured_text and len(unstructured_text) > 500:
                    # Unstructured ê²°ê³¼ê°€ ì¢‹ìœ¼ë©´ ì‚¬ìš©
                    text_content = unstructured_text
                    print("âœ… Unstructured ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©")
                else:
                    print(f"âš ï¸ Unstructured ê²°ê³¼ ë¶€ì¡± ({len(unstructured_text)}ì), BeautifulSoupìœ¼ë¡œ í´ë°±")
                    raise Exception("Unstructured ê²°ê³¼ê°€ ë¶€ì¡±í•¨")
                    
            except Exception as e:
                print(f"âš ï¸ Unstructured ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‹¤íŒ¨, BeautifulSoupìœ¼ë¡œ í´ë°±: {e}")
                
                # BeautifulSoupìœ¼ë¡œ í…Œì´ë¸” í–‰ë³„ ë¶„í•  ì‹œë„
                try:
                    from bs4 import BeautifulSoup
                    
                    print("ğŸ”§ BeautifulSoupìœ¼ë¡œ HTML í…Œì´ë¸” íŒŒì‹± ì‹œë„...")
                    soup = BeautifulSoup(content, 'html.parser')
                    
                    # í…Œì´ë¸” ì°¾ê¸°
                    table = soup.find('table')
                    if table:
                        # í…Œì´ë¸” í–‰ë“¤ ì¶”ì¶œ
                        rows = table.find_all('tr')
                        print(f"ğŸ” ë°œê²¬ëœ í…Œì´ë¸” í–‰ ìˆ˜: {len(rows)}")
                        
                        if len(rows) >= 2:
                            # í—¤ë” í–‰ê³¼ ë°ì´í„° í–‰ ë¶„ë¦¬
                            header_row = rows[0]
                            data_rows = rows[1:]
                            
                            # í—¤ë” ì¶”ì¶œ
                            headers = []
                            for cell in header_row.find_all(['td', 'th']):
                                header_text = cell.get_text(strip=True)
                                if header_text:
                                    headers.append(header_text)
                            
                            print(f"ğŸ” í…Œì´ë¸” í—¤ë”: {headers}")
                            print(f"ğŸ” ë°ì´í„° í–‰ ìˆ˜: {len(data_rows)}")
                            
                            # ê° ë°ì´í„° í–‰ì„ ê°œë³„ ì²­í¬ë¡œ ì²˜ë¦¬
                            processed_elements = []
                            
                            for row_idx, row in enumerate(data_rows):
                                # í–‰ì˜ ì…€ë“¤ ì¶”ì¶œ
                                cells = row.find_all(['td', 'th'])
                                if len(cells) == 0:
                                    continue
                                
                                # ì…€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                                row_data = []
                                for cell in cells:
                                    cell_text = cell.get_text(strip=True)
                                    if cell_text:
                                        row_data.append(cell_text)
                                
                                if len(row_data) == 0:
                                    continue
                                
                                # í—¤ë”ì™€ ë°ì´í„°ë¥¼ ë§¤í•‘í•˜ì—¬ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ìƒì„±
                                ticket_text = ""
                                for i, cell_text in enumerate(row_data):
                                    if i < len(headers):
                                        ticket_text += f"{headers[i]}: {cell_text} "
                                    else:
                                        ticket_text += f"{cell_text} "
                                
                                ticket_text = ticket_text.strip()
                                
                                if len(ticket_text) > 10:  # ì˜ë¯¸ìˆëŠ” ë°ì´í„°ë§Œ ì²˜ë¦¬
                                    print(f"   ğŸ“ í–‰ {row_idx + 1}: {ticket_text[:100]}...")
                                    
                                    # ê° í‹°ì¼“ì„ ê°œë³„ ìš”ì†Œë¡œ ìƒì„±
                                    element = DocumentElement(
                                        ElementType.TEXT,
                                        ticket_text,
                                        {
                                            "source": "html_table_row",
                                            "row_index": row_idx + 1,
                                            "headers": headers,
                                            "cell_count": len(row_data)
                                        }
                                    )
                                    processed_elements.append(element)
                            
                            if len(processed_elements) > 0:
                                print(f"âœ… {len(processed_elements)}ê°œ í‹°ì¼“ í–‰ ì²˜ë¦¬ ì™„ë£Œ")
                                
                                # ê²°ê³¼ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                                import tempfile
                                import json
                                from datetime import datetime
                                temp_dir = "temp_results"
                                os.makedirs(temp_dir, exist_ok=True)
                                
                                result = {
                                    "file_path": file_path,
                                    "file_type": "html",
                                    "content_type": "text_based",
                                    "processed_pages": [{
                                        "page_number": 1,
                                        "page_type": "table",
                                        "elements": [{
                                            "element_type": "text",
                                            "content": elem.content,
                                            "metadata": elem.metadata
                                        } for elem in processed_elements],
                                        "metadata": {"file_type": "html", "table_rows": len(processed_elements)}
                                    }],
                                    "total_pages": 1,
                                    "processing_timestamp": datetime.now().isoformat()
                                }
                                
                                temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='_result.json', delete=False, dir=temp_dir)
                                json.dump(result, temp_file, ensure_ascii=False, indent=2)
                                temp_file.close()
                                print(f"ê²°ê³¼ê°€ ì„ì‹œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {temp_file.name}")
                                
                                return [ProcessedPage(
                                    1, 
                                    processed_elements, 
                                    "table",
                                    {"file_type": "html", "table_rows": len(processed_elements)}
                                )]
                            else:
                                print("âš ï¸ ì²˜ë¦¬ëœ í–‰ì´ ì—†ìŒ, ì •ê·œì‹ìœ¼ë¡œ ì²˜ë¦¬")
                                raise Exception("No processed rows")
                        else:
                            print("âš ï¸ í…Œì´ë¸” ë°ì´í„° í–‰ì´ ì—†ìŒ, ì •ê·œì‹ìœ¼ë¡œ ì²˜ë¦¬")
                            raise Exception("No data rows")
                    else:
                        print("âš ï¸ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ì •ê·œì‹ìœ¼ë¡œ ì²˜ë¦¬")
                        raise Exception("No table found")
                        
                except Exception as e2:
                    print(f"âš ï¸ BeautifulSoup ì²˜ë¦¬ë„ ì‹¤íŒ¨, ì •ê·œì‹ìœ¼ë¡œ ì²˜ë¦¬: {e2}")
                
                # HTML íƒœê·¸ ì œê±° (ë” ê°•ë ¥í•œ ë°©ë²•)
                import re
                
                # 1. CSS ìŠ¤íƒ€ì¼ ë¸”ë¡ ì œê±° (Jira í…Œì´ë¸” ìŠ¤íƒ€ì¼)
                text_content = re.sub(r'<style[^>]*>.*?</style>', '', content, flags=re.DOTALL | re.IGNORECASE)
                
                # 2. HTML íƒœê·¸ ì œê±°
                text_content = re.sub(r'<[^>]+>', '', text_content)
                
                # 3. HTML ì—”í‹°í‹° ë””ì½”ë”©
                text_content = text_content.replace('&nbsp;', ' ')
                text_content = text_content.replace('&amp;', '&')
                text_content = text_content.replace('&lt;', '<')
                text_content = text_content.replace('&gt;', '>')
                text_content = text_content.replace('&quot;', '"')
                text_content = text_content.replace('&#39;', "'")
                
                # 4. Jira í…Œì´ë¸” ê´€ë ¨ CSS ì†ì„± ì œê±°
                text_content = re.sub(r'mso-[^;]+;?', '', text_content)
                text_content = re.sub(r'@page[^}]+}', '', text_content)
                text_content = re.sub(r'body\s*{[^}]*}', '', text_content)
                text_content = re.sub(r'table\s*{[^}]*}', '', text_content)
                
                # 5. ì—°ì† ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
                text_content = re.sub(r'\s+', ' ', text_content)
                text_content = re.sub(r'[{}();]', ' ', text_content)
                text_content = re.sub(r'\s+', ' ', text_content).strip()
                
                # 6. ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (ë„ˆë¬´ ì§§ì€ ë‹¨ì–´ ì œê±°)
                words = text_content.split()
                meaningful_words = [word for word in words if len(word) > 2 or word.isdigit()]
                text_content = ' '.join(meaningful_words)
            
            print(f"ğŸ” ìµœì¢… í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text_content)}ì")
            print(f"ğŸ” ìµœì¢… í…ìŠ¤íŠ¸ ì²« 200ì: {text_content[:200]}")
            
            if text_content and len(text_content) > 50:  # ìµœì†Œ ê¸¸ì´ ì²´í¬ (50ì ì´ìƒ)
                elements = [DocumentElement(
                    ElementType.TEXT,
                    text_content,
                    {"content_type": "jira_table_text", "original_length": len(content), "processed": True}
                )]
                
                return [ProcessedPage(
                    1, elements, "text",
                    {"file_type": "jira_table", "original_type": "xls", "text_length": len(text_content)}
                )]
            else:
                print(f"âš ï¸ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìŒ: {len(text_content)}ì")
                return []
                
        except Exception as e:
            print(f"HTML í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []
    
    def process_html(self, file_path: str) -> List[ProcessedPage]:
        """HTML íŒŒì¼ì„ ì²˜ë¦¬ (í…Œì´ë¸” í–‰ë³„ ë¶„í•  ìš°ì„  ì‹œë„)"""
        # ë¨¼ì € í…Œì´ë¸” í–‰ë³„ ë¶„í•  ì‹œë„
        try:
            result = self._process_html_table_by_rows(file_path)
            if result and len(result) > 0 and len(result[0].elements) > 0:
                print("âœ… HTML í…Œì´ë¸” í–‰ë³„ ë¶„í•  ì„±ê³µ")
                return result
        except Exception as e:
            print(f"âš ï¸ HTML í…Œì´ë¸” í–‰ë³„ ë¶„í•  ì‹¤íŒ¨, ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬: {e}")
        
        # í´ë°±: ì¼ë°˜ HTML í…ìŠ¤íŠ¸ ì²˜ë¦¬
        return self._process_html_as_text(file_path)
    
    def _extract_pptx_image(self, shape, slide_num: int, element_index: int) -> str:
        """PPTXì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        try:
            image = shape.image
            image_bytes = image.blob
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥
            temp_dir = "temp_images"
            os.makedirs(temp_dir, exist_ok=True)
            
            image_filename = f"pptx_slide{slide_num}_img{element_index}.png"
            image_path = os.path.join(temp_dir, image_filename)
            
            with open(image_path, "wb") as f:
                f.write(image_bytes)
            
            return image_path
            
        except Exception as e:
            raise Exception(f"ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    def _process_xml(self, file_path: str) -> List[ProcessedPage]:
        """
        XML íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ProcessedPage ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
        
        Args:
            file_path: XML íŒŒì¼ ê²½ë¡œ
            
        Returns:
            XML íŒŒì‹± ê²°ê³¼ë¥¼ í¬í•¨í•œ ProcessedPage ë¦¬ìŠ¤íŠ¸
        """
        try:
            print(f"ğŸ” XML íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path}")
            
            # XML íŒŒì‹±
            tree = ET.parse(file_path)
            root = tree.getroot()
            
            print(f"ğŸ“‹ XML ë£¨íŠ¸ ìš”ì†Œ: {root.tag}")
            
            processed_elements = []
            
            # RSS í˜•ì‹ì¸ì§€ í™•ì¸
            if root.tag == 'rss':
                processed_elements = self._process_rss_xml(root, file_path)
            else:
                # ì¼ë°˜ XML ì²˜ë¦¬
                processed_elements = self._process_generic_xml(root, file_path)
            
            if not processed_elements:
                print("âš ï¸ ì²˜ë¦¬ëœ ìš”ì†Œê°€ ì—†ìŒ, ì „ì²´ XMLì„ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬")
                processed_elements = self._process_xml_as_text(file_path)
            
            print(f"âœ… XML ì²˜ë¦¬ ì™„ë£Œ: {len(processed_elements)}ê°œ ìš”ì†Œ")
            
            # ê²°ê³¼ë¥¼ ProcessedPageë¡œ ë³€í™˜
            page = ProcessedPage(
                page_number=1,
                page_type="xml_content",
                elements=processed_elements,
                metadata={
                    "file_type": "xml",
                    "root_element": root.tag,
                    "total_elements": len(processed_elements),
                    "processing_method": "xml_parser"
                }
            )
            
            return [page]
            
        except ET.ParseError as e:
            print(f"âŒ XML íŒŒì‹± ì˜¤ë¥˜: {e}")
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
            return self._process_xml_as_text_fallback(file_path)
        except Exception as e:
            print(f"âŒ XML ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return self._process_xml_as_text_fallback(file_path)
    
    def _process_rss_xml(self, root, file_path: str) -> List[DocumentElement]:
        """RSS XML ì²˜ë¦¬ (JIRA RSS íŠ¹í™”)"""
        processed_elements = []
        
        # ì±„ë„ ì •ë³´ ì¶”ì¶œ
        channel = root.find('channel')
        if channel is not None:
            title_elem = channel.find('title')
            channel_title = title_elem.text if title_elem is not None else "Unknown"
            
            print(f"ğŸ“‹ RSS ì±„ë„: {channel_title}")
            
            # ì´ìŠˆ ì •ë³´ ì¶”ì¶œ
            issue_elem = channel.find('issue')
            if issue_elem is not None:
                total_issues = issue_elem.get('total', '0')
                print(f"ğŸ“‹ ì´ ì´ìŠˆ ìˆ˜: {total_issues}")
            
            # ê° ì•„ì´í…œ(ì´ìŠˆ) ì²˜ë¦¬
            items = channel.findall('item')
            print(f"ğŸ“‹ ì²˜ë¦¬í•  ì•„ì´í…œ ìˆ˜: {len(items)}")
            
            for idx, item in enumerate(items):
                try:
                    # ì´ìŠˆ ì •ë³´ ì¶”ì¶œ
                    issue_data = self._extract_jira_issue_data(item)
                    
                    if issue_data:
                        # êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ìƒì„±
                        structured_text = self._create_structured_issue_text(issue_data)
                        
                        # Unstructuredë¡œ ì •ì œ
                        refined_text = self._refine_text_with_unstructured(structured_text)
                        
                        # DocumentElement ìƒì„±
                        element = DocumentElement(
                            ElementType.TEXT,
                            refined_text,
                            {
                                "source": "jira_rss_item",
                                "issue_key": issue_data.get('key', ''),
                                "issue_type": issue_data.get('type', ''),
                                "status": issue_data.get('status', ''),
                                "priority": issue_data.get('priority', ''),
                                "assignee": issue_data.get('assignee', ''),
                                "reporter": issue_data.get('reporter', ''),
                                "created": issue_data.get('created', ''),
                                "updated": issue_data.get('updated', ''),
                                "item_index": idx + 1,
                                "unstructured_refined": True
                            }
                        )
                        processed_elements.append(element)
                        
                        if (idx + 1) % 100 == 0:
                            print(f"   ğŸ“ {idx + 1}ê°œ ì´ìŠˆ ì²˜ë¦¬ ì™„ë£Œ...")
                
                except Exception as e:
                    print(f"âš ï¸ ì•„ì´í…œ {idx + 1} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    continue
        
        return processed_elements
    
    def _extract_jira_issue_data(self, item) -> Dict[str, str]:
        """JIRA ì´ìŠˆ ë°ì´í„° ì¶”ì¶œ"""
        issue_data = {}
        
        try:
            # ê¸°ë³¸ ì •ë³´
            title_elem = item.find('title')
            if title_elem is not None:
                issue_data['title'] = title_elem.text or ''
            
            key_elem = item.find('key')
            if key_elem is not None:
                issue_data['key'] = key_elem.text or ''
            
            summary_elem = item.find('summary')
            if summary_elem is not None:
                issue_data['summary'] = summary_elem.text or ''
            
            # ì„¤ëª… (HTML ë””ì½”ë”©)
            description_elem = item.find('description')
            if description_elem is not None and description_elem.text:
                # HTML ì—”í‹°í‹° ë””ì½”ë”©
                description = html.unescape(description_elem.text)
                # HTML íƒœê·¸ ì œê±° (ê°„ë‹¨í•œ ë°©ë²•)
                import re
                description = re.sub(r'<[^>]+>', '', description)
                issue_data['description'] = description.strip()
            
            # í”„ë¡œì íŠ¸ ì •ë³´
            project_elem = item.find('project')
            if project_elem is not None:
                issue_data['project'] = project_elem.text or ''
                issue_data['project_key'] = project_elem.get('key', '')
            
            # ì´ìŠˆ íƒ€ì…
            type_elem = item.find('type')
            if type_elem is not None:
                issue_data['type'] = type_elem.text or ''
            
            # ìƒíƒœ
            status_elem = item.find('status')
            if status_elem is not None:
                issue_data['status'] = status_elem.text or ''
            
            # ìš°ì„ ìˆœìœ„
            priority_elem = item.find('priority')
            if priority_elem is not None:
                issue_data['priority'] = priority_elem.text or ''
            
            # ë‹´ë‹¹ì
            assignee_elem = item.find('assignee')
            if assignee_elem is not None:
                issue_data['assignee'] = assignee_elem.text or ''
            
            # ë³´ê³ ì
            reporter_elem = item.find('reporter')
            if reporter_elem is not None:
                issue_data['reporter'] = reporter_elem.text or ''
            
            # ë‚ ì§œ ì •ë³´
            created_elem = item.find('created')
            if created_elem is not None:
                issue_data['created'] = created_elem.text or ''
            
            updated_elem = item.find('updated')
            if updated_elem is not None:
                issue_data['updated'] = updated_elem.text or ''
            
            resolved_elem = item.find('resolved')
            if resolved_elem is not None:
                issue_data['resolved'] = resolved_elem.text or ''
            
            # ë§í¬
            link_elem = item.find('link')
            if link_elem is not None:
                issue_data['link'] = link_elem.text or ''
            
        except Exception as e:
            print(f"âš ï¸ ì´ìŠˆ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        return issue_data
    
    def _create_structured_issue_text(self, issue_data: Dict[str, str]) -> str:
        """êµ¬ì¡°í™”ëœ ì´ìŠˆ í…ìŠ¤íŠ¸ ìƒì„±"""
        text_parts = []
        
        # ì´ìŠˆ í‚¤ì™€ ì œëª©
        if issue_data.get('key'):
            text_parts.append(f"ì´ìŠˆ í‚¤: {issue_data['key']}")
        if issue_data.get('title'):
            text_parts.append(f"ì œëª©: {issue_data['title']}")
        
        # ìš”ì•½
        if issue_data.get('summary'):
            text_parts.append(f"ìš”ì•½: {issue_data['summary']}")
        
        # ì„¤ëª…
        if issue_data.get('description'):
            text_parts.append(f"ì„¤ëª…: {issue_data['description']}")
        
        # ë©”íƒ€ë°ì´í„°
        metadata_parts = []
        if issue_data.get('type'):
            metadata_parts.append(f"íƒ€ì…: {issue_data['type']}")
        if issue_data.get('status'):
            metadata_parts.append(f"ìƒíƒœ: {issue_data['status']}")
        if issue_data.get('priority'):
            metadata_parts.append(f"ìš°ì„ ìˆœìœ„: {issue_data['priority']}")
        if issue_data.get('assignee'):
            metadata_parts.append(f"ë‹´ë‹¹ì: {issue_data['assignee']}")
        if issue_data.get('reporter'):
            metadata_parts.append(f"ë³´ê³ ì: {issue_data['reporter']}")
        if issue_data.get('created'):
            metadata_parts.append(f"ìƒì„±ì¼: {issue_data['created']}")
        if issue_data.get('updated'):
            metadata_parts.append(f"ìˆ˜ì •ì¼: {issue_data['updated']}")
        
        if metadata_parts:
            text_parts.append("ë©”íƒ€ë°ì´í„°: " + ", ".join(metadata_parts))
        
        return "\n".join(text_parts)
    
    def _process_generic_xml(self, root, file_path: str) -> List[DocumentElement]:
        """ì¼ë°˜ XML ì²˜ë¦¬"""
        processed_elements = []
        
        def extract_text_recursive(element, depth: int = 0) -> str:
            """XML ìš”ì†Œì—ì„œ í…ìŠ¤íŠ¸ ì¬ê·€ì ìœ¼ë¡œ ì¶”ì¶œ"""
            text_parts = []
            
            # í˜„ì¬ ìš”ì†Œì˜ í…ìŠ¤íŠ¸
            if element.text and element.text.strip():
                text_parts.append(element.text.strip())
            
            # ìì‹ ìš”ì†Œë“¤ ì²˜ë¦¬
            for child in element:
                child_text = extract_text_recursive(child, depth + 1)
                if child_text:
                    text_parts.append(child_text)
            
            # í˜„ì¬ ìš”ì†Œì˜ tail í…ìŠ¤íŠ¸
            if element.tail and element.tail.strip():
                text_parts.append(element.tail.strip())
            
            return " ".join(text_parts)
        
        # ë£¨íŠ¸ ìš”ì†Œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        full_text = extract_text_recursive(root)
        
        if full_text.strip():
            # Unstructuredë¡œ ì •ì œ
            refined_text = self._refine_text_with_unstructured(full_text)
            
            element = DocumentElement(
                ElementType.TEXT,
                refined_text,
                {
                    "source": "generic_xml",
                    "root_element": root.tag,
                    "unstructured_refined": True
                }
            )
            processed_elements.append(element)
        
        return processed_elements
    
    def _process_xml_as_text(self, file_path: str) -> List[DocumentElement]:
        """XMLì„ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # HTML ì—”í‹°í‹° ë””ì½”ë”©
            content = html.unescape(content)
            
            # Unstructuredë¡œ ì •ì œ
            refined_text = self._refine_text_with_unstructured(content)
            
            element = DocumentElement(
                ElementType.TEXT,
                refined_text,
                {
                    "source": "xml_as_text",
                    "unstructured_refined": True
                }
            )
            return [element]
            
        except Exception as e:
            print(f"âŒ XML í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []
    
    def _process_xml_as_text_fallback(self, file_path: str) -> List[ProcessedPage]:
        """XML íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬í•˜ëŠ” fallback"""
        try:
            elements = self._process_xml_as_text(file_path)
            
            page = ProcessedPage(
                page_number=1,
                page_type="xml_text_fallback",
                elements=elements,
                metadata={
                    "file_type": "xml",
                    "processing_method": "text_fallback",
                    "error": "xml_parse_failed"
                }
            )
            
            return [page]
            
        except Exception as e:
            print(f"âŒ XML fallback ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []

class LayoutBasedProcessor:
    """Layout-based íŒŒì¼ ì²˜ë¦¬ê¸° (PDF ë³€í™˜ í›„ ì´ë¯¸ì§€ ì²˜ë¦¬)"""
    
    def __init__(self, azure_processor: AzureOpenAIImageProcessor):
        self.azure_processor = azure_processor
    
    def process_file(self, file_path: str, doc_type: DocumentType) -> List[ProcessedPage]:
        """Layout-based íŒŒì¼ì„ PDFë¡œ ë³€í™˜ í›„ ì²˜ë¦¬"""
        try:
            # PDFë¡œ ë³€í™˜
            pdf_path = self._convert_to_pdf(file_path, doc_type)
            
            # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬
            return self._process_pdf_as_images(pdf_path)
            
        except Exception as e:
            print(f"Layout-based ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []
    
    def _convert_to_pdf(self, file_path: str, doc_type: DocumentType) -> str:
        """íŒŒì¼ì„ PDFë¡œ ë³€í™˜"""
        try:
            if doc_type == DocumentType.PDF:
                return file_path
            
            # ì„ì‹œ PDF íŒŒì¼ ê²½ë¡œ
            temp_dir = "temp_pdfs"
            os.makedirs(temp_dir, exist_ok=True)
            
            pdf_filename = f"converted_{Path(file_path).stem}.pdf"
            pdf_path = os.path.join(temp_dir, pdf_filename)
            
            if doc_type == DocumentType.DOCX:
                self._convert_docx_to_pdf(file_path, pdf_path)
            elif doc_type == DocumentType.PPTX:
                self._convert_pptx_to_pdf(file_path, pdf_path)
            elif doc_type == DocumentType.XLSX:
                self._convert_xlsx_to_pdf(file_path, pdf_path)
            
            return pdf_path
            
        except Exception as e:
            raise Exception(f"PDF ë³€í™˜ ì‹¤íŒ¨: {e}")
    
    def _convert_docx_to_pdf(self, docx_path: str, pdf_path: str):
        """DOCXë¥¼ PDFë¡œ ë³€í™˜ (LibreOffice ì‚¬ìš©)"""
        try:
            import subprocess
            # LibreOfficeë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í™˜
            cmd = ["soffice", "--headless", "--convert-to", "pdf", "--outdir", 
                   os.path.dirname(pdf_path), docx_path]
            subprocess.run(cmd, check=True, capture_output=True)
            
            # ë³€í™˜ëœ íŒŒì¼ ì´ë¦„ ë³€ê²½
            converted_path = docx_path.replace('.docx', '.pdf')
            if os.path.exists(converted_path):
                shutil.move(converted_path, pdf_path)
                
        except Exception as e:
            print(f"LibreOffice ë³€í™˜ ì‹¤íŒ¨, ëŒ€ì•ˆ ë°©ë²• ì‚¬ìš©: {e}")
            # ëŒ€ì•ˆ: python-docx2pdf ì‚¬ìš©
            try:
                from docx2pdf import convert
                convert(docx_path, pdf_path)
            except ImportError:
                raise Exception("PDF ë³€í™˜ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def _convert_pptx_to_pdf(self, pptx_path: str, pdf_path: str):
        """PPTXë¥¼ PDFë¡œ ë³€í™˜"""
        try:
            from pptx2pdf import convert
            convert(pptx_path, pdf_path)
        except ImportError:
            # ëŒ€ì•ˆ: LibreOffice ì‚¬ìš©
            self._convert_docx_to_pdf(pptx_path, pdf_path)
    
    def _convert_xlsx_to_pdf(self, xlsx_path: str, pdf_path: str):
        """XLSXë¥¼ PDFë¡œ ë³€í™˜"""
        try:
            # pandasë¥¼ ì‚¬ìš©í•˜ì—¬ HTMLë¡œ ë³€í™˜ í›„ PDF ë³€í™˜
            df = pd.read_excel(xlsx_path)
            html_path = xlsx_path.replace('.xlsx', '.html')
            df.to_html(html_path)
            
            # HTMLì„ PDFë¡œ ë³€í™˜ (weasyprint ì‚¬ìš©)
            try:
                from weasyprint import HTML
                HTML(html_path).write_pdf(pdf_path)
                os.remove(html_path)
            except ImportError:
                # ëŒ€ì•ˆ: LibreOffice ì‚¬ìš©
                self._convert_docx_to_pdf(xlsx_path, pdf_path)
                
        except Exception as e:
            print(f"XLSX ë³€í™˜ ì‹¤íŒ¨, LibreOffice ì‚¬ìš©: {e}")
            self._convert_docx_to_pdf(xlsx_path, pdf_path)
    
    def _process_pdf_as_images(self, pdf_path: str) -> List[ProcessedPage]:
        """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ GPT Visionìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            doc = fitz.open(pdf_path)
            processed_pages = []
            
            for page_num in range(len(doc)):
                page = doc[page_num]
                
                # í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                mat = fitz.Matrix(2.0, 2.0)  # 2ë°° í™•ëŒ€
                pix = page.get_pixmap(matrix=mat)
                
                # ì´ë¯¸ì§€ ì €ì¥
                temp_dir = "temp_images"
                os.makedirs(temp_dir, exist_ok=True)
                
                image_filename = f"pdf_page{page_num + 1}.png"
                image_path = os.path.join(temp_dir, image_filename)
                pix.save(image_path)
                
                # GPT Visionìœ¼ë¡œ ì´ë¯¸ì§€ ì²˜ë¦¬
                prompt = "ì´ í˜ì´ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œí•˜ê³ , í‘œë‚˜ ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                text_content = self.azure_processor.image_to_text(image_path, prompt)
                
                # ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ ìš”ì†Œë¡œ ì €ì¥
                elements = [DocumentElement(
                    ElementType.TEXT,
                    text_content,
                    {"page_number": page_num + 1, "source": "gpt_vision"}
                )]
                
                processed_pages.append(ProcessedPage(
                    page_num + 1, elements, "page",
                    {"file_type": "pdf", "processing_method": "gpt_vision"}
                ))
            
            doc.close()
            return processed_pages
            
        except Exception as e:
            raise Exception(f"PDF ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

class FileProcessor:
    """ë©”ì¸ íŒŒì¼ ì²˜ë¦¬ê¸°"""
    
    def __init__(self, azure_processor: AzureOpenAIImageProcessor):
        self.azure_processor = azure_processor
        self.text_processor = TextBasedProcessor(azure_processor)
        self.layout_processor = LayoutBasedProcessor(azure_processor)
        self.temp_storage = {}
    
    def process_file(self, file_path: str) -> Dict[str, Any]:
        """íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜"""
        try:
            # 1. íŒŒì¼ íƒ€ì… íŒë³„
            doc_type = FileTypeDetector.detect_file_type(file_path)
            content_type = FileTypeDetector.detect_content_type(file_path, doc_type)
            
            print(f"íŒŒì¼ íƒ€ì…: {doc_type.value}, ì½˜í…ì¸  íƒ€ì…: {content_type.value}")
            
            # 2. ì½˜í…ì¸  íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
            if content_type == ContentType.TEXT_BASED:
                processed_pages = self._process_text_based(file_path, doc_type)
            else:
                processed_pages = self._process_layout_based(file_path, doc_type)
            
            # 3. ê²°ê³¼ë¥¼ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì„ì‹œ ì €ì¥
            result = {
                "file_path": file_path,
                "file_type": doc_type.value,
                "content_type": content_type.value,
                "processed_pages": [page.to_dict() for page in processed_pages],
                "total_pages": len(processed_pages),
                "processing_timestamp": str(pd.Timestamp.now())
            }
            
            # ì„ì‹œ ì €ì¥
            self._save_to_temp_storage(file_path, result)
            
            return result

        except Exception as e:
            print(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def _process_text_based(self, file_path: str, doc_type: DocumentType) -> List[ProcessedPage]:
        """Text-based íŒŒì¼ ì²˜ë¦¬"""
        if doc_type == DocumentType.DOCX:
            return self.text_processor.process_docx(file_path)
        elif doc_type == DocumentType.PPTX:
            return self.text_processor.process_pptx(file_path)
        elif doc_type == DocumentType.XLSX:
            return self.text_processor.process_xlsx(file_path)
        elif doc_type == DocumentType.XLS:
            return self.text_processor.process_xls(file_path)
        elif doc_type == DocumentType.HTML:
            return self.text_processor.process_html(file_path)
        elif doc_type == DocumentType.XML:
            return self.text_processor._process_xml(file_path)
        elif doc_type == DocumentType.PDF:
            # PDFëŠ” ë³„ë„ ì²˜ë¦¬
            return self._process_pdf_text_based(file_path)
        else:
            return []

    def _process_layout_based(self, file_path: str, doc_type: DocumentType) -> List[ProcessedPage]:
        """Layout-based íŒŒì¼ ì²˜ë¦¬"""
        return self.layout_processor.process_file(file_path, doc_type)
    
    def _process_pdf_text_based(self, file_path: str) -> List[ProcessedPage]:
        """Text-based PDF ì²˜ë¦¬"""
        try:
            doc = fitz.open(file_path)
            processed_pages = []
            
            for page_num in range(len(doc)):
                page = doc[page_num]
                elements = []
                
                # í…ìŠ¤íŠ¸ ë¸”ë¡ ì¶”ì¶œ
                text_blocks = page.get_text("blocks")
                for block in text_blocks:
                    x0, y0, x1, y1, text, block_no, block_type = block[:7]
                    
                    if block_type == 0 and text.strip():  # í…ìŠ¤íŠ¸ ë¸”ë¡
                            elements.append(DocumentElement(
                                ElementType.TEXT, 
                                text.strip(),
                            {"page": page_num + 1, "bbox": (x0, y0, x1, y1)}
                        ))
                
                if elements:
                    processed_pages.append(ProcessedPage(
                        page_num + 1, elements, "page",
                        {"file_type": "pdf", "processing_method": "text_extraction"}
                        ))
            
            doc.close()
            return processed_pages
            
        except Exception as e:
            print(f"PDF í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []
    
    def _save_to_temp_storage(self, file_path: str, result: Dict[str, Any]):
        """ê²°ê³¼ë¥¼ ì„ì‹œ ì €ì¥ì†Œì— ì €ì¥"""
        file_key = Path(file_path).name
        self.temp_storage[file_key] = result
        
        # JSON íŒŒì¼ë¡œë„ ì €ì¥
        temp_dir = "temp_results"
        os.makedirs(temp_dir, exist_ok=True)
        
        json_filename = f"{Path(file_path).stem}_result.json"
        json_path = os.path.join(temp_dir, json_filename)
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"ê²°ê³¼ê°€ ì„ì‹œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {json_path}")
    
    def get_temp_result(self, file_name: str) -> Optional[Dict[str, Any]]:
        """ì„ì‹œ ì €ì¥ëœ ê²°ê³¼ ì¡°íšŒ"""
        return self.temp_storage.get(file_name)
    
    def clear_temp_storage(self):
        """ì„ì‹œ ì €ì¥ì†Œ ì •ë¦¬"""
        self.temp_storage.clear()
    
    def process_with_structured_chunking(self, file_path: str) -> List[StructuredChunk]:
        """
        êµ¬ì¡°ì  ì²­í‚¹ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ì²˜ë¦¬
        
        Args:
            file_path: ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            êµ¬ì¡°í™”ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        try:
            file_extension = Path(file_path).suffix.lower()
            file_name = Path(file_path).name
            
            print(f"ğŸ”§ êµ¬ì¡°ì  ì²­í‚¹ ì‹œì‘: {file_name}")
            
            # Jira HTML íŒŒì¼ì¸ ê²½ìš°
            if file_extension in ['.xls', '.html'] and self._is_jira_html(file_path):
                print("ğŸ“‹ Jira HTML íŒŒì¼ ê°ì§€ - êµ¬ì¡°ì  ì²­í‚¹ ì ìš©")
                with open(file_path, 'r', encoding='utf-8') as f:
                    html_content = f.read()
                
                chunker = JiraStructuredChunker()
                return chunker.chunk_jira_html(html_content, file_name)
            
            # CSV íŒŒì¼ì¸ ê²½ìš°
            elif file_extension == '.csv':
                print("ğŸ“‹ CSV íŒŒì¼ ê°ì§€ - êµ¬ì¡°ì  ì²­í‚¹ ì ìš©")
                try:
                    df = pd.read_csv(file_path)
                    csv_data = df.to_dict('records')
                    
                    chunker = JiraStructuredChunker()
                    return chunker.chunk_csv_data(csv_data, file_name)
                except Exception as e:
                    print(f"âŒ CSV êµ¬ì¡°ì  ì²­í‚¹ ì‹¤íŒ¨: {str(e)}")
                    return []
            
            else:
                print(f"âš ï¸ êµ¬ì¡°ì  ì²­í‚¹ ë¯¸ì§€ì› íŒŒì¼: {file_extension}")
                return []
                
        except Exception as e:
            print(f"âŒ êµ¬ì¡°ì  ì²­í‚¹ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _is_jira_html(self, file_path: str) -> bool:
        """íŒŒì¼ì´ Jira HTMLì¸ì§€ í™•ì¸"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read(1000)  # ì²« 1000ìë§Œ ì½ê¸°
            
            # Jira HTMLì˜ íŠ¹ì§•ì ì¸ íŒ¨í„´ë“¤ í™•ì¸
            jira_indicators = [
                'Jira',
                'issuerow',
                'issue-link',
                'BTVO-',
                'í”„ë¡œì íŠ¸:',
                'í‚¤:',
                'ìš”ì•½:'
            ]
            
            return any(indicator in content for indicator in jira_indicators)
            
        except Exception:
            return False
        
        # ì„ì‹œ íŒŒì¼ë“¤ë„ ì •ë¦¬
        temp_dirs = ["temp_images", "temp_pdfs", "temp_results"]
        for temp_dir in temp_dirs:
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
                print(f"ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ë¨: {temp_dir}")
