#!/usr/bin/env python3
"""
MultiQueryRetriever êµ¬í˜„
ì‚¬ìš©ìì˜ ë‹¨ì¼ ì§ˆë¬¸ì„ LLMì„ ì´ìš©í•´ ì—¬ëŸ¬ ê°œì˜ ë‹¤ë¥¸ ê´€ì ì„ ê°€ì§„ ì§ˆë¬¸ìœ¼ë¡œ í™•ì¥í•˜ì—¬
ë” ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ì°¾ì•„ë‚´ëŠ” RAG ê²€ìƒ‰ ê°œì„  ëª¨ë“ˆ
"""

import os
import logging
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LangChain imports - LangChain 1.0 í˜¸í™˜
try:
    # LangChain 1.0+ - retrieversê°€ langchain_communityë¡œ ì´ë™
    try:
        from langchain_community.retrievers import MultiQueryRetriever
    except ImportError:
        # LangChain 0.2.x - êµ¬ë²„ì „ ê²½ë¡œ
        from langchain.retrievers.multi_query import MultiQueryRetriever

    from langchain_openai import AzureChatOpenAI
    from langchain_core.documents import Document
    from langchain_core.retrievers import BaseRetriever
    LANGCHAIN_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ LangChain ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    LANGCHAIN_AVAILABLE = False
    # Import ì‹¤íŒ¨ ì‹œ íƒ€ì… íŒíŠ¸ìš© ë”ë¯¸ í´ë˜ìŠ¤
    BaseRetriever = Any
    MultiQueryRetriever = None
    AzureChatOpenAI = None
    Document = None

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MultiQueryRetrieverWrapper:
    """MultiQueryRetriever ë˜í¼ í´ë˜ìŠ¤"""
    
    def __init__(self, base_retriever: BaseRetriever, llm: Optional[Any] = None):
        """
        MultiQueryRetriever ì´ˆê¸°í™”
        
        Args:
            base_retriever: ê¸°ë³¸ ê²€ìƒ‰ê¸° (ChromaDB ë“±)
            llm: AzureChatOpenAI LLM ì¸ìŠ¤í„´ìŠ¤
        """
        self.base_retriever = base_retriever
        self.llm = llm
        self.multi_query_retriever = None
        
        if LANGCHAIN_AVAILABLE and self.llm:
            self._setup_multi_query_retriever()
        else:
            logger.warning("LangChain ë˜ëŠ” LLMì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ê¸°ë³¸ ê²€ìƒ‰ê¸°ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    def _setup_multi_query_retriever(self):
        """MultiQueryRetriever ì„¤ì •"""
        try:
            # MultiQueryRetriever ìƒì„±
            self.multi_query_retriever = MultiQueryRetriever.from_llm(
                retriever=self.base_retriever,
                llm=self.llm
            )
            
            # ë¡œê¹… í™œì„±í™” (ìƒì„±ëœ ì§ˆë¬¸ë“¤ í™•ì¸ìš©)
            logging.getLogger("langchain.retrievers.multi_query").setLevel(logging.INFO)
            
            logger.info("âœ… MultiQueryRetriever ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ MultiQueryRetriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.multi_query_retriever = None
    
    def search(self, query: str, k: int = 5) -> List[Document]:
        """
        MultiQueryRetrieverë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        try:
            if self.multi_query_retriever:
                logger.info(f"ğŸ” MultiQueryRetriever ê²€ìƒ‰ ì‹œì‘: '{query}'")
                
                # MultiQueryRetriever ì‚¬ìš©
                documents = self.multi_query_retriever.invoke(query)
                
                # ê²°ê³¼ ìˆ˜ ì œí•œ
                if len(documents) > k:
                    documents = documents[:k]
                
                logger.info(f"âœ… MultiQueryRetriever ê²€ìƒ‰ ì™„ë£Œ: {len(documents)}ê°œ ê²°ê³¼")
                return documents
                
            else:
                # í´ë°±: ê¸°ë³¸ ê²€ìƒ‰ê¸° ì‚¬ìš©
                logger.warning("MultiQueryRetriever ì‚¬ìš© ë¶ˆê°€, ê¸°ë³¸ ê²€ìƒ‰ê¸°ë¡œ í´ë°±")
                documents = self.base_retriever.invoke(query)
                
                # ê²°ê³¼ ìˆ˜ ì œí•œ
                if len(documents) > k:
                    documents = documents[:k]
                
                return documents
                
        except Exception as e:
            logger.error(f"âŒ MultiQueryRetriever ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ê²€ìƒ‰ê¸° ì‚¬ìš©
            try:
                documents = self.base_retriever.invoke(query)
                if len(documents) > k:
                    documents = documents[:k]
                return documents
            except Exception as fallback_error:
                logger.error(f"âŒ ê¸°ë³¸ ê²€ìƒ‰ê¸°ë„ ì‹¤íŒ¨: {fallback_error}")
                return []


class ChromaDBRetriever(BaseRetriever):
    """ChromaDBë¥¼ ìœ„í•œ BaseRetriever êµ¬í˜„"""
    
    vector_db_manager: Any
    collection_name: str
    k: int
    
    def __init__(self, vector_db_manager, collection_name: str = "mail_collection", **kwargs):
        """
        ChromaDB Retriever ì´ˆê¸°í™”
        
        Args:
            vector_db_manager: VectorDBManager ì¸ìŠ¤í„´ìŠ¤
            collection_name: ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ ì´ë¦„
        """
        super().__init__(
            vector_db_manager=vector_db_manager,
            collection_name=collection_name,
            k=5,
            **kwargs
        )
    
    def _get_relevant_documents(self, query: str) -> List[Document]:
        """
        ChromaDBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            
        Returns:
            Document ë¦¬ìŠ¤íŠ¸
        """
        try:
            # VectorDBManagerê°€ Noneì¸ ê²½ìš° ë¹ˆ ê²°ê³¼ ë°˜í™˜
            if self.vector_db_manager is None:
                logger.warning("VectorDBManagerê°€ Noneì…ë‹ˆë‹¤. ë¹ˆ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return []
            
            # ChromaDBì—ì„œ ê²€ìƒ‰
            if self.collection_name == "mail_collection":
                results = self.vector_db_manager.search_similar_mails(query, n_results=self.k)
            elif self.collection_name == "file_chunks":
                results = self.vector_db_manager.search_similar_file_chunks(query, n_results=self.k)
            elif self.collection_name == "structured_chunks":
                results = self.vector_db_manager.search_structured_chunks(query, n_results=self.k)
            else:
                logger.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ì»¬ë ‰ì…˜: {self.collection_name}")
                return []
            
            # ê²°ê³¼ë¥¼ Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            documents = []
            for result in results:
                if isinstance(result, dict):
                    # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ê²°ê³¼
                    content = result.get('content', '')
                    metadata = result.get('metadata', {})
                    metadata['similarity_score'] = result.get('similarity_score', 0.0)
                    metadata['source'] = result.get('source', 'unknown')
                else:
                    # ê°ì²´ í˜•íƒœì˜ ê²°ê³¼ (Mail ë“±)
                    content = getattr(result, 'refined_content', str(result))
                    metadata = {
                        'message_id': getattr(result, 'message_id', ''),
                        'sender': getattr(result, 'sender', ''),
                        'subject': getattr(result, 'subject', ''),
                        'status': getattr(result, 'status', ''),
                        'similarity_score': getattr(result, 'similarity_score', 0.0),
                        'source': 'mail'
                    }
                
                if content:
                    doc = Document(page_content=content, metadata=metadata)
                    documents.append(doc)
            
            return documents
            
        except Exception as e:
            logger.error(f"ChromaDB ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def invoke(self, query: str, config: Optional[Dict] = None) -> List[Document]:
        """invoke ë©”ì„œë“œ (LangChain í˜¸í™˜ì„±)"""
        return self._get_relevant_documents(query)
    
    def get_relevant_documents(self, query: str, config: Optional[Dict] = None) -> List[Document]:
        """get_relevant_documents ë©”ì„œë“œ (LangChain í˜¸í™˜ì„±)"""
        return self._get_relevant_documents(query)


class AzureChatOpenAIManager:
    """AzureChatOpenAI LLM ê´€ë¦¬ì"""
    
    def __init__(self):
        self.llm = None
        self._init_llm()
    
    def _init_llm(self):
        """AzureChatOpenAI LLM ì´ˆê¸°í™”"""
        try:
            if not LANGCHAIN_AVAILABLE:
                logger.warning("LangChainì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
                return
            
            # Azure OpenAI ì„¤ì •
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-4")
            
            if not all([api_key, azure_endpoint, deployment_name]):
                logger.warning("Azure OpenAI ì„¤ì •ì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤.")
                return
            
            # AzureChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.llm = AzureChatOpenAI(
                azure_deployment=deployment_name,
                azure_endpoint=azure_endpoint,
                api_key=api_key,
                api_version=api_version,
                temperature=0,  # ì¼ê´€ëœ ì§ˆë¬¸ ìƒì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
                max_tokens=1000
            )
            
            logger.info("âœ… AzureChatOpenAI LLM ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ AzureChatOpenAI LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.llm = None
    
    def get_llm(self) -> Optional[Any]:
        """LLM ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        return self.llm


class MultiQuerySearchManager:
    """MultiQuery ê²€ìƒ‰ ê´€ë¦¬ì"""
    
    def __init__(self, vector_db_manager):
        """
        MultiQuery ê²€ìƒ‰ ê´€ë¦¬ì ì´ˆê¸°í™”
        
        Args:
            vector_db_manager: VectorDBManager ì¸ìŠ¤í„´ìŠ¤
        """
        self.vector_db_manager = vector_db_manager
        self.llm_manager = AzureChatOpenAIManager()
        self.retrievers = {}
        self._setup_retrievers()
    
    def _setup_retrievers(self):
        """ê° ì»¬ë ‰ì…˜ë³„ MultiQueryRetriever ì„¤ì •"""
        try:
            llm = self.llm_manager.get_llm()
            
            # ì œí•œëœ MultiQuery ì‚¬ìš©: ë©”ì¼ ê²€ìƒ‰ì—ë§Œ ì ìš©
            mail_retriever = ChromaDBRetriever(self.vector_db_manager, "mail_collection")
            self.retrievers["mail"] = MultiQueryRetrieverWrapper(mail_retriever, llm)
            logger.info("âœ… ë©”ì¼ MultiQueryRetriever ì´ˆê¸°í™” ì™„ë£Œ")
            
            # íŒŒì¼ ì²­í¬ì™€ êµ¬ì¡°ì  ì²­í¬ëŠ” ê¸°ë³¸ ê²€ìƒ‰ ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½)
            logger.info("âš ï¸ íŒŒì¼ ì²­í¬ì™€ êµ¬ì¡°ì  ì²­í¬ëŠ” ê¸°ë³¸ ê²€ìƒ‰ ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½)")
            
            logger.info("âœ… MultiQuery ê²€ìƒ‰ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ (ì œí•œëœ MultiQuery í™œì„±í™”)")
            
        except Exception as e:
            logger.error(f"âŒ MultiQuery ê²€ìƒ‰ ê´€ë¦¬ì ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.info("âš ï¸ ê¸°ë³¸ ê²€ìƒ‰ ëª¨ë“œë¡œ í´ë°±í•©ë‹ˆë‹¤")
    
    def search_mails(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """ë©”ì¼ ê²€ìƒ‰ (MultiQuery ì ìš©)"""
        try:
            if "mail" in self.retrievers:
                logger.info(f"ğŸ” MultiQuery ë©”ì¼ ê²€ìƒ‰ ì‹œì‘: '{query}'")
                documents = self.retrievers["mail"].search(query, k)
                results = self._documents_to_dict_list(documents, "mail")
                logger.info(f"âœ… MultiQuery ë©”ì¼ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                return results
            else:
                # í´ë°±: ê¸°ë³¸ ê²€ìƒ‰
                logger.info(f"ğŸ” ë©”ì¼ ê²€ìƒ‰ ì‹œì‘: '{query}' (ê¸°ë³¸ ê²€ìƒ‰ ì‚¬ìš©)")
                results = self.vector_db_manager.search_similar_mails(query, n_results=k)
                logger.info(f"âœ… ë©”ì¼ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                return results
                
        except Exception as e:
            logger.error(f"ë©”ì¼ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ê²€ìƒ‰
            try:
                logger.info("ê¸°ë³¸ ë©”ì¼ ê²€ìƒ‰ìœ¼ë¡œ í´ë°± ì‹œë„")
                return self.vector_db_manager.search_similar_mails(query, n_results=k)
            except Exception as fallback_error:
                logger.error(f"ê¸°ë³¸ ë©”ì¼ ê²€ìƒ‰ë„ ì‹¤íŒ¨: {fallback_error}")
                return []
    
    def search_file_chunks(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """íŒŒì¼ ì²­í¬ ê²€ìƒ‰ (MultiQuery ì ìš©)"""
        try:
            if "file_chunks" in self.retrievers:
                logger.info(f"ğŸ” MultiQuery íŒŒì¼ ì²­í¬ ê²€ìƒ‰ ì‹œì‘: '{query}'")
                documents = self.retrievers["file_chunks"].search(query, k)
                results = self._documents_to_dict_list(documents, "file_chunks")
                logger.info(f"âœ… MultiQuery íŒŒì¼ ì²­í¬ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                return results
            else:
                # í´ë°±: ê¸°ë³¸ ê²€ìƒ‰
                logger.info(f"ğŸ” íŒŒì¼ ì²­í¬ ê²€ìƒ‰ ì‹œì‘: '{query}' (ê¸°ë³¸ ê²€ìƒ‰ ì‚¬ìš©)")
                results = self.vector_db_manager.search_similar_file_chunks(query, n_results=k)
                logger.info(f"âœ… íŒŒì¼ ì²­í¬ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                return results
                
        except Exception as e:
            logger.error(f"íŒŒì¼ ì²­í¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ê²€ìƒ‰
            try:
                logger.info("ê¸°ë³¸ íŒŒì¼ ì²­í¬ ê²€ìƒ‰ìœ¼ë¡œ í´ë°± ì‹œë„")
                return self.vector_db_manager.search_similar_file_chunks(query, n_results=k)
            except Exception as fallback_error:
                logger.error(f"ê¸°ë³¸ íŒŒì¼ ì²­í¬ ê²€ìƒ‰ë„ ì‹¤íŒ¨: {fallback_error}")
                return []
    
    def search_structured_chunks(self, query: str, k: int = 5, 
                                chunk_types: List[str] = None, 
                                ticket_ids: List[str] = None,
                                priority_filter: int = None) -> List[Dict[str, Any]]:
        """êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰ (MultiQuery ì ìš©)"""
        try:
            if "structured_chunks" in self.retrievers:
                logger.info(f"ğŸ” MultiQuery êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰ ì‹œì‘: '{query}'")
                documents = self.retrievers["structured_chunks"].search(query, k)
                results = self._documents_to_dict_list(documents, "structured_chunks")
                
                # í•„í„° ì ìš©
                if chunk_types or ticket_ids or priority_filter:
                    results = self._apply_filters(results, chunk_types, ticket_ids, priority_filter)
                
                logger.info(f"âœ… MultiQuery êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                return results
            else:
                # í´ë°±: ê¸°ë³¸ ê²€ìƒ‰
                logger.info(f"ğŸ” êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰ ì‹œì‘: '{query}' (ê¸°ë³¸ ê²€ìƒ‰ ì‚¬ìš©)")
                results = self.vector_db_manager.search_structured_chunks(
                    query, n_results=k, chunk_types=chunk_types, 
                    ticket_ids=ticket_ids, priority_filter=priority_filter
                )
                logger.info(f"âœ… êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                return results
                
        except Exception as e:
            logger.error(f"êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ê²€ìƒ‰
            try:
                logger.info("ê¸°ë³¸ êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰ìœ¼ë¡œ í´ë°± ì‹œë„")
                return self.vector_db_manager.search_structured_chunks(
                    query, n_results=k, chunk_types=chunk_types, 
                    ticket_ids=ticket_ids, priority_filter=priority_filter
                )
            except Exception as fallback_error:
                logger.error(f"ê¸°ë³¸ êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰ë„ ì‹¤íŒ¨: {fallback_error}")
                return []
    
    def _documents_to_dict_list(self, documents: List[Document], source_type: str) -> List[Dict[str, Any]]:
        """Document ë¦¬ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        results = []
        for i, doc in enumerate(documents):
            result = {
                "id": f"multi_query_{source_type}_{i}",
                "content": doc.page_content,
                "source": f"multi_query_{source_type}",
                "similarity_score": doc.metadata.get("similarity_score", 0.0),
                "metadata": doc.metadata
            }
            results.append(result)
        return results
    
    def _apply_filters(self, results: List[Dict[str, Any]], 
                      chunk_types: List[str] = None, 
                      ticket_ids: List[str] = None,
                      priority_filter: int = None) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ê²°ê³¼ì— í•„í„° ì ìš©"""
        filtered_results = []
        
        for result in results:
            metadata = result.get("metadata", {})
            
            # ì²­í¬ íƒ€ì… í•„í„°
            if chunk_types and metadata.get("chunk_type") not in chunk_types:
                continue
            
            # í‹°ì¼“ ID í•„í„°
            if ticket_ids and metadata.get("ticket_id") not in ticket_ids:
                continue
            
            # ìš°ì„ ìˆœìœ„ í•„í„°
            if priority_filter and metadata.get("priority", 3) > priority_filter:
                continue
            
            filtered_results.append(result)
        
        return filtered_results


def create_multi_query_search_manager(vector_db_manager) -> MultiQuerySearchManager:
    """
    MultiQuery ê²€ìƒ‰ ê´€ë¦¬ì ìƒì„± (í¸ì˜ í•¨ìˆ˜)
    
    Args:
        vector_db_manager: VectorDBManager ì¸ìŠ¤í„´ìŠ¤
        
    Returns:
        MultiQuerySearchManager ì¸ìŠ¤í„´ìŠ¤
    """
    return MultiQuerySearchManager(vector_db_manager)


def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ§ª MultiQueryRetriever í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    try:
        # Vector DB ë§¤ë‹ˆì € ì´ˆê¸°í™”
        from vector_db_models import VectorDBManager
        vector_db = VectorDBManager()
        
        # MultiQuery ê²€ìƒ‰ ê´€ë¦¬ì ìƒì„±
        search_manager = create_multi_query_search_manager(vector_db)
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_query = "ì„œë²„ ì ‘ì† ë¬¸ì œ í•´ê²° ë°©ë²•"
        print(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {test_query}")
        
        # ë©”ì¼ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\n--- ë©”ì¼ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ---")
        mail_results = search_manager.search_mails(test_query, k=3)
        print(f"ë©”ì¼ ê²€ìƒ‰ ê²°ê³¼: {len(mail_results)}ê°œ")
        for i, result in enumerate(mail_results, 1):
            print(f"  {i}. {result['content'][:100]}...")
        
        # íŒŒì¼ ì²­í¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\n--- íŒŒì¼ ì²­í¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ---")
        chunk_results = search_manager.search_file_chunks(test_query, k=3)
        print(f"íŒŒì¼ ì²­í¬ ê²€ìƒ‰ ê²°ê³¼: {len(chunk_results)}ê°œ")
        for i, result in enumerate(chunk_results, 1):
            print(f"  {i}. {result['content'][:100]}...")
        
        # êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\n--- êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ---")
        structured_results = search_manager.search_structured_chunks(test_query, k=3)
        print(f"êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰ ê²°ê³¼: {len(structured_results)}ê°œ")
        for i, result in enumerate(structured_results, 1):
            print(f"  {i}. {result['content'][:100]}...")
        
        print("\nâœ… MultiQueryRetriever í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
