#!/usr/bin/env python3
"""
ì§ˆë¬¸ í™•ì¥ + ìˆœì°¨ ê²€ìƒ‰ Retriever
MultiQueryì˜ ì§ˆë¬¸ í™•ì¥ ê¸°ëŠ¥ë§Œ ì‚¬ìš©í•˜ê³ , í™•ì¥ëœ ì§ˆë¬¸ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ê²€ìƒ‰
"""

import logging
from typing import List, Dict, Any, Optional
from langchain_openai import AzureChatOpenAI
from langchain_core.documents import Document
from dotenv import load_dotenv
import os

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

logger = logging.getLogger(__name__)

class QueryExpansionRetriever:
    """ì§ˆë¬¸ í™•ì¥ + ìˆœì°¨ ê²€ìƒ‰ Retriever"""
    
    def __init__(self, vector_db_manager, llm=None):
        """
        QueryExpansionRetriever ì´ˆê¸°í™”
        
        Args:
            vector_db_manager: VectorDBManager ì¸ìŠ¤í„´ìŠ¤
            llm: AzureChatOpenAI LLM ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒì‚¬í•­)
        """
        self.vector_db_manager = vector_db_manager
        self.llm = llm or self._init_llm()
        logger.info("âœ… QueryExpansionRetriever ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_llm(self):
        """AzureChatOpenAI LLM ì´ˆê¸°í™”"""
        try:
            llm = AzureChatOpenAI(
                azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-4.1"),
                azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
                api_key=os.getenv("AZURE_OPENAI_API_KEY"),
                api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-10-21"),
                temperature=0,  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
                max_tokens=1000
            )
            logger.info("âœ… AzureChatOpenAI LLM ì´ˆê¸°í™” ì™„ë£Œ")
            return llm
        except Exception as e:
            logger.error(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    
    def expand_query(self, query: str) -> List[str]:
        """
        ë‹¨ì¼ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê´€ì ì˜ ì§ˆë¬¸ìœ¼ë¡œ í™•ì¥
        
        Args:
            query: ì›ë³¸ ì§ˆë¬¸
            
        Returns:
            í™•ì¥ëœ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        if not self.llm:
            logger.warning("LLMì´ ì—†ì–´ì„œ ì›ë³¸ ì§ˆë¬¸ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤")
            return [query]
        
        try:
            # ì§ˆë¬¸ í™•ì¥ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
            prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì„ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ 3ê°œì˜ ë‹¤ë¥¸ ì§ˆë¬¸ìœ¼ë¡œ í™•ì¥í•´ì£¼ì„¸ìš”.
ê° ì§ˆë¬¸ì€ ì›ë³¸ ì§ˆë¬¸ì˜ í•µì‹¬ì„ ìœ ì§€í•˜ë©´ì„œë„ ì„œë¡œ ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.

ì›ë³¸ ì§ˆë¬¸: {query}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ 3ê°œì˜ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
1. [ì²« ë²ˆì§¸ í™•ì¥ ì§ˆë¬¸]
2. [ë‘ ë²ˆì§¸ í™•ì¥ ì§ˆë¬¸]  
3. [ì„¸ ë²ˆì§¸ í™•ì¥ ì§ˆë¬¸]

ê° ì§ˆë¬¸ì€ í•œ ì¤„ë¡œ ì‘ì„±í•˜ê³ , ë²ˆí˜¸ì™€ ëŒ€ê´„í˜¸ëŠ” ì œì™¸í•´ì£¼ì„¸ìš”.
"""
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ í™•ì¥
            response = self.llm.invoke(prompt)
            expanded_text = response.content.strip()
            
            # í™•ì¥ëœ ì§ˆë¬¸ë“¤ì„ íŒŒì‹±
            expanded_queries = []
            lines = expanded_text.split('\n')
            
            for line in lines:
                line = line.strip()
                if line and not line.startswith(('1.', '2.', '3.')):
                    # ë²ˆí˜¸ì™€ ëŒ€ê´„í˜¸ ì œê±°
                    clean_query = line.replace('[', '').replace(']', '').strip()
                    if clean_query:
                        expanded_queries.append(clean_query)
            
            # ìµœì†Œ 1ê°œ, ìµœëŒ€ 3ê°œì˜ ì§ˆë¬¸ ë³´ì¥
            if not expanded_queries:
                expanded_queries = [query]
            elif len(expanded_queries) > 3:
                expanded_queries = expanded_queries[:3]
            
            logger.info(f"âœ… ì§ˆë¬¸ í™•ì¥ ì™„ë£Œ: {len(expanded_queries)}ê°œ ì§ˆë¬¸ ìƒì„±")
            for i, q in enumerate(expanded_queries, 1):
                logger.info(f"   {i}. {q}")
            
            return expanded_queries
            
        except Exception as e:
            logger.error(f"âŒ ì§ˆë¬¸ í™•ì¥ ì‹¤íŒ¨: {e}")
            return [query]
    
    def search_with_expansion(self, query: str, k: int = 5, 
                            search_type: str = "all") -> List[Dict[str, Any]]:
        """
        ì§ˆë¬¸ í™•ì¥ + ìˆœì°¨ ê²€ìƒ‰ ìˆ˜í–‰
        
        Args:
            query: ì›ë³¸ ì§ˆë¬¸
            k: ê° ê²€ìƒ‰ì—ì„œ ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            search_type: ê²€ìƒ‰ íƒ€ì… ("all", "mails", "file_chunks", "structured_chunks")
            
        Returns:
            í†µí•©ëœ ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            logger.info(f"ğŸ” ì§ˆë¬¸ í™•ì¥ ê²€ìƒ‰ ì‹œì‘: '{query}'")
            
            # 1ë‹¨ê³„: ì§ˆë¬¸ í™•ì¥
            expanded_queries = self.expand_query(query)
            logger.info(f"ğŸ“ {len(expanded_queries)}ê°œì˜ í™•ì¥ëœ ì§ˆë¬¸ ìƒì„±")
            
            # 2ë‹¨ê³„: ê° í™•ì¥ëœ ì§ˆë¬¸ìœ¼ë¡œ ìˆœì°¨ ê²€ìƒ‰
            all_results = []
            seen_ids = set()  # ì¤‘ë³µ ì œê±°ìš©
            
            for i, expanded_query in enumerate(expanded_queries, 1):
                logger.info(f"ğŸ” í™•ì¥ ì§ˆë¬¸ {i}/{len(expanded_queries)} ê²€ìƒ‰: '{expanded_query}'")
                
                # ê²€ìƒ‰ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ ê²€ìƒ‰ ìˆ˜í–‰
                if search_type == "all":
                    results = self._search_all_types(expanded_query, k)
                elif search_type == "mails":
                    results = self._search_mails(expanded_query, k)
                elif search_type == "file_chunks":
                    results = self._search_file_chunks(expanded_query, k)
                elif search_type == "structured_chunks":
                    results = self._search_structured_chunks(expanded_query, k)
                else:
                    results = self._search_all_types(expanded_query, k)
                
                # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ê²°ê³¼ ì¶”ê°€
                for result in results:
                    result_id = result.get('id', '')
                    if result_id and result_id not in seen_ids:
                        seen_ids.add(result_id)
                        result['expanded_query'] = expanded_query
                        result['query_rank'] = i
                        all_results.append(result)
                
                logger.info(f"âœ… í™•ì¥ ì§ˆë¬¸ {i} ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            
            # 3ë‹¨ê³„: ê²°ê³¼ ì •ë ¬ ë° ì œí•œ
            # ìœ ì‚¬ë„ ì ìˆ˜ì™€ ì¿¼ë¦¬ ìˆœìœ„ë¥¼ ê³ ë ¤í•œ ì •ë ¬
            all_results.sort(key=lambda x: (
                x.get('similarity_score', 0) * 0.7 +  # ìœ ì‚¬ë„ ì ìˆ˜ 70%
                (1.0 / x.get('query_rank', 1)) * 0.3   # ì¿¼ë¦¬ ìˆœìœ„ 30% (ì²« ë²ˆì§¸ ì§ˆë¬¸ì´ ë” ì¤‘ìš”)
            ), reverse=True)
            
            # ìµœì¢… ê²°ê³¼ ìˆ˜ ì œí•œ
            final_results = all_results[:k]
            
            logger.info(f"âœ… ì§ˆë¬¸ í™•ì¥ ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ ìµœì¢… ê²°ê³¼")
            return final_results
            
        except Exception as e:
            logger.error(f"âŒ ì§ˆë¬¸ í™•ì¥ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ê²€ìƒ‰
            return self._search_all_types(query, k)
    
    def _search_all_types(self, query: str, k: int) -> List[Dict[str, Any]]:
        """ëª¨ë“  íƒ€ì… ê²€ìƒ‰"""
        results = []
        
        # ë©”ì¼ ê²€ìƒ‰
        mail_results = self._search_mails(query, k//3 + 1)
        results.extend(mail_results)
        
        # íŒŒì¼ ì²­í¬ ê²€ìƒ‰
        file_results = self._search_file_chunks(query, k//3 + 1)
        results.extend(file_results)
        
        # êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰
        structured_results = self._search_structured_chunks(query, k//3 + 1)
        results.extend(structured_results)
        
        return results
    
    def _search_mails(self, query: str, k: int) -> List[Dict[str, Any]]:
        """ë©”ì¼ ê²€ìƒ‰"""
        try:
            results = self.vector_db_manager.search_similar_mails(query, n_results=k)
            formatted_results = []
            
            for i, result in enumerate(results):
                formatted_results.append({
                    'id': getattr(result, 'message_id', f'mail_{i}'),
                    'content': getattr(result, 'refined_content', ''),
                    'metadata': {
                        'type': 'mail',
                        'subject': getattr(result, 'subject', ''),
                        'sender': getattr(result, 'sender', ''),
                        'status': getattr(result, 'status', ''),
                        'created_at': getattr(result, 'created_at', ''),
                    },
                    'similarity_score': getattr(result, 'similarity_score', 0.0),
                    'source': 'mail'
                })
            
            return formatted_results
            
        except Exception as e:
            logger.error(f"ë©”ì¼ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _search_file_chunks(self, query: str, k: int) -> List[Dict[str, Any]]:
        """íŒŒì¼ ì²­í¬ ê²€ìƒ‰"""
        try:
            results = self.vector_db_manager.search_similar_file_chunks(query, n_results=k)
            formatted_results = []
            
            for i, result in enumerate(results):
                # resultëŠ” ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ get() ë©”ì„œë“œ ì‚¬ìš©
                formatted_results.append({
                    'id': result.get('chunk_id', f'file_chunk_{i}'),
                    'content': result.get('content', ''),
                    'metadata': {
                        'type': 'file_chunk',
                        'file_name': result.get('file_name', ''),
                        'chunk_index': result.get('chunk_index', 0),
                        'created_at': result.get('created_at', ''),
                    },
                    'similarity_score': result.get('similarity_score', 0.0),
                    'source': 'file_chunk'
                })
            
            return formatted_results
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì²­í¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _search_structured_chunks(self, query: str, k: int) -> List[Dict[str, Any]]:
        """êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰"""
        try:
            results = self.vector_db_manager.search_structured_chunks(query, n_results=k)
            formatted_results = []
            
            for i, result in enumerate(results):
                formatted_results.append({
                    'id': getattr(result, 'chunk_id', f'structured_chunk_{i}'),
                    'content': getattr(result, 'content', ''),
                    'metadata': {
                        'type': 'structured_chunk',
                        'chunk_type': getattr(result, 'chunk_type', ''),
                        'ticket_id': getattr(result, 'ticket_id', ''),
                        'field_type': getattr(result, 'field_type', ''),
                        'created_at': getattr(result, 'created_at', ''),
                    },
                    'similarity_score': getattr(result, 'similarity_score', 0.0),
                    'source': 'structured_chunk'
                })
            
            return formatted_results
            
        except Exception as e:
            logger.error(f"êµ¬ì¡°ì  ì²­í¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []


def create_query_expansion_retriever(vector_db_manager, llm=None):
    """
    QueryExpansionRetriever ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    
    Args:
        vector_db_manager: VectorDBManager ì¸ìŠ¤í„´ìŠ¤
        llm: AzureChatOpenAI LLM ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒì‚¬í•­)
        
    Returns:
        QueryExpansionRetriever ì¸ìŠ¤í„´ìŠ¤
    """
    return QueryExpansionRetriever(vector_db_manager, llm)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    try:
        from vector_db_models import VectorDBManager
        
        # VectorDBManager ìƒì„±
        vector_db_manager = VectorDBManager()
        
        # QueryExpansionRetriever ìƒì„±
        retriever = create_query_expansion_retriever(vector_db_manager)
        
        # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
        test_query = "ì„œë²„ ì ‘ì† ë¬¸ì œ"
        results = retriever.search_with_expansion(test_query, k=5)
        
        print(f"\nğŸ‰ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
        for i, result in enumerate(results, 1):
            print(f"\n{i}. {result['content'][:100]}...")
            print(f"   ìœ ì‚¬ë„: {result['similarity_score']:.3f}")
            print(f"   ì†ŒìŠ¤: {result['source']}")
            print(f"   í™•ì¥ ì§ˆë¬¸: {result.get('expanded_query', 'N/A')}")
        
    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
