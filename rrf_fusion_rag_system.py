#!/usr/bin/env python3
"""
RRF (Reciprocal Rank Fusion) ê¸°ë°˜ RAG ì‹œìŠ¤í…œ
Multi-Query, HyDE, BM25 ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìˆœìœ„ ê¸°ë°˜ìœ¼ë¡œ ì§€ëŠ¥ì  ìœµí•© (Hybrid Search)
"""

import os
import sys
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import chromadb
from chromadb.config import Settings
import numpy as np
from collections import defaultdict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ëª¨ë“ˆë“¤ import
from intelligent_chunk_weighting import IntelligentChunkWeighting
from hyde_rag_system_mock import MockHyDEGenerator, HyDEConfig

# BM25 ê´€ë ¨ import
try:
    from rank_bm25 import BM25Okapi
    BM25_AVAILABLE = True
except ImportError:
    BM25_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning("âš ï¸ rank_bm25 ë¯¸ì„¤ì¹˜. BM25 ê²€ìƒ‰ ë¹„í™œì„±í™”. ì„¤ì¹˜: pip install rank-bm25")

# í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° import
try:
    from kiwipiepy import Kiwi
    KIWI_AVAILABLE = True
except ImportError:
    KIWI_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning("âš ï¸ kiwipiepy ë¯¸ì„¤ì¹˜. ê¸°ë³¸ í† í¬ë‚˜ì´ì € ì‚¬ìš©. ì„¤ì¹˜: pip install kiwipiepy")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class KoreanTokenizer:
    """í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ í† í¬ë‚˜ì´ì € (Kiwipiepy ê¸°ë°˜)"""

    def __init__(self, use_kiwi: bool = True):
        """
        í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”

        Args:
            use_kiwi: Kiwipiepy ì‚¬ìš© ì—¬ë¶€
        """
        self.use_kiwi = use_kiwi and KIWI_AVAILABLE
        self.kiwi = None

        if self.use_kiwi:
            try:
                self.kiwi = Kiwi()
                logger.info("âœ… Kiwipiepy í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ Kiwipiepy ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ë³¸ í† í¬ë‚˜ì´ì € ì‚¬ìš©: {e}")
                self.use_kiwi = False

    def tokenize(self, text: str) -> List[str]:
        """
        í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë¶„ë¦¬ (í•˜ì´í”ˆ ë³µí•©ì–´ ë³´ì¡´)

        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸

        Returns:
            í† í° ë¦¬ìŠ¤íŠ¸
        """
        if not text:
            return []

        if self.use_kiwi and self.kiwi:
            try:
                # Kiwipiepy í˜•íƒœì†Œ ë¶„ì„
                result = self.kiwi.tokenize(text)

                # í•˜ì´í”ˆ ë³µí•©ì–´ ì¬ê²°í•© (ì˜ˆ: NCMS-EUXP)
                tokens = []
                i = 0
                while i < len(result):
                    token = result[i]

                    # ì˜ì–´/ìˆ«ì + í•˜ì´í”ˆ + ì˜ì–´/ìˆ«ì íŒ¨í„´ ê°ì§€
                    if (token.tag in ['SL', 'SN'] and
                        i + 2 < len(result) and
                        result[i + 1].form == '-' and
                        result[i + 2].tag in ['SL', 'SN']):
                        # ë³µí•©ì–´ë¡œ ê²°í•©: "NCMS" + "-" + "EUXP" â†’ "ncms-euxp"
                        compound = token.form.lower() + '-' + result[i + 2].form.lower()
                        tokens.append(compound)
                        i += 3  # 3ê°œ í† í° ê±´ë„ˆë›°ê¸°
                    elif token.tag in ['NNG', 'NNP', 'VV', 'VA', 'SL', 'SN', 'XR', 'SH']:
                        # ì¼ë°˜ í† í°
                        form = token.form.lower() if token.tag in ['SL', 'SN'] else token.form
                        tokens.append(form)
                        i += 1
                    else:
                        i += 1

                return tokens

            except Exception as e:
                logger.warning(f"âš ï¸ Kiwipiepy í† í¬ë‚˜ì´ì§• ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©: {e}")

        # ê¸°ë³¸ í† í¬ë‚˜ì´ì € (ê³µë°± ë¶„ë¦¬)
        return text.lower().split()


@dataclass
class RRFConfig:
    """RRF ì‹œìŠ¤í…œ ì„¤ì • (Hybrid Search ì§€ì›)"""
    # RRF ì„¤ì •
    rrf_k: int = 60  # RRF ìƒìˆ˜ (ì¼ë°˜ì ìœ¼ë¡œ 60 ì‚¬ìš©)
    multi_query_results: int = 20  # ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
    hyde_results: int = 20  # HyDE ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
    bm25_results: int = 20  # BM25 ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
    final_candidates: int = 30  # ìµœì¢… í›„ë³´ ìˆ˜

    # ê¸°ì¡´ HyDE ì„¤ì •
    multi_query_count: int = 3
    top_k_per_query: int = 15

    # BM25 ì„¤ì •
    enable_bm25: bool = True  # BM25 ê²€ìƒ‰ í™œì„±í™” ì—¬ë¶€
    bm25_tokenizer: str = "korean"  # simple ë˜ëŠ” korean (ê¸°ë³¸: í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„)

    # í‹°ì¼“ ì¤‘ë³µ ì œê±° ì„¤ì •
    deduplicate_tickets: bool = True  # í‹°ì¼“ ì¤‘ë³µ ì œê±° í™œì„±í™”
    deduplication_strategy: str = "max_score"  # max_score, first, merge, all_scores

class RRFFusionEngine:
    """RRF (Reciprocal Rank Fusion) ìœµí•© ì—”ì§„"""

    def __init__(self, config: RRFConfig):
        """
        RRF ìœµí•© ì—”ì§„ ì´ˆê¸°í™”

        Args:
            config: RRF ì„¤ì •
        """
        self.config = config
        logger.info(f"âœ… RRF ìœµí•© ì—”ì§„ ì´ˆê¸°í™” (k={config.rrf_k})")

    def calculate_rrf_scores(self, multi_query_results: List[Dict[str, Any]],
                           hyde_results: List[Dict[str, Any]],
                           bm25_results: Optional[List[Dict[str, Any]]] = None) -> Dict[str, float]:
        """
        RRF ì ìˆ˜ ê³„ì‚° (3-way: Multi-Query + HyDE + BM25)

        Args:
            multi_query_results: ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ ê²°ê³¼ (ìˆœìœ„ ìˆœ)
            hyde_results: HyDE ê²€ìƒ‰ ê²°ê³¼ (ìˆœìœ„ ìˆœ)
            bm25_results: BM25 ê²€ìƒ‰ ê²°ê³¼ (ìˆœìœ„ ìˆœ, optional)

        Returns:
            ë¬¸ì„œ IDë³„ RRF ì ìˆ˜ ë”•ì…”ë„ˆë¦¬
        """
        rrf_scores = defaultdict(float)

        # 1. Multi-Query ê²°ê³¼ ì²˜ë¦¬
        logger.info(f"ğŸ”„ Multi-Query ê²°ê³¼ RRF ì ìˆ˜ ê³„ì‚°: {len(multi_query_results)}ê°œ")
        for rank, doc in enumerate(multi_query_results, 1):
            doc_id = doc['id']
            rrf_score = 1.0 / (self.config.rrf_k + rank)
            rrf_scores[doc_id] += rrf_score

            logger.debug(f"  Multi-Query {rank}ìœ„: {doc_id} â†’ +{rrf_score:.6f}")

        # 2. HyDE ê²°ê³¼ ì²˜ë¦¬
        logger.info(f"ğŸ”„ HyDE ê²°ê³¼ RRF ì ìˆ˜ ê³„ì‚°: {len(hyde_results)}ê°œ")
        for rank, doc in enumerate(hyde_results, 1):
            doc_id = doc['id']
            rrf_score = 1.0 / (self.config.rrf_k + rank)
            rrf_scores[doc_id] += rrf_score

            logger.debug(f"  HyDE {rank}ìœ„: {doc_id} â†’ +{rrf_score:.6f}")

        # 3. BM25 ê²°ê³¼ ì²˜ë¦¬ (ìˆëŠ” ê²½ìš°) - í‚¤ì›Œë“œ ì •í™• ë§¤ì¹­ì´ë¯€ë¡œ 6ë°° ê°€ì¤‘ì¹˜
        if bm25_results:
            logger.info(f"ğŸ”„ BM25 ê²°ê³¼ RRF ì ìˆ˜ ê³„ì‚°: {len(bm25_results)}ê°œ (ê°€ì¤‘ì¹˜ 6.0x)")
            for rank, doc in enumerate(bm25_results, 1):
                doc_id = doc['id']
                rrf_score = 1.0 / (self.config.rrf_k + rank)
                # BM25ëŠ” í‚¤ì›Œë“œ ì •í™• ë§¤ì¹­ì´ë¯€ë¡œ 6ë°° ê°€ì¤‘ì¹˜ ì ìš©
                weighted_score = rrf_score * 6.0
                rrf_scores[doc_id] += weighted_score

                logger.debug(f"  BM25 {rank}ìœ„: {doc_id} â†’ +{weighted_score:.6f} (ê¸°ë³¸:{rrf_score:.6f} x6)")

        logger.info(f"âœ… RRF ì ìˆ˜ ê³„ì‚° ì™„ë£Œ: {len(rrf_scores)}ê°œ ê³ ìœ  ë¬¸ì„œ")
        return dict(rrf_scores)

    def fuse_results(self, multi_query_results: List[Dict[str, Any]],
                    hyde_results: List[Dict[str, Any]],
                    bm25_results: Optional[List[Dict[str, Any]]] = None) -> Tuple[List[str], Dict[str, float]]:
        """
        ê²€ìƒ‰ ê²°ê³¼ë“¤ì„ RRFë¡œ ìœµí•©í•˜ì—¬ ìµœì¢… í›„ë³´êµ° ìƒì„± (Hybrid Search)

        Args:
            multi_query_results: ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ ê²°ê³¼
            hyde_results: HyDE ê²€ìƒ‰ ê²°ê³¼
            bm25_results: BM25 ê²€ìƒ‰ ê²°ê³¼ (optional)

        Returns:
            (RRF ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸, RRF ì ìˆ˜ ë”•ì…”ë„ˆë¦¬)
        """
        try:
            # RRF ì ìˆ˜ ê³„ì‚°
            rrf_scores = self.calculate_rrf_scores(multi_query_results, hyde_results, bm25_results)

            # RRF ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            sorted_doc_ids = sorted(rrf_scores.keys(), key=lambda doc_id: rrf_scores[doc_id], reverse=True)

            # ìƒìœ„ Nê°œ ì„ íƒ
            final_candidates = sorted_doc_ids[:self.config.final_candidates]

            search_methods = "Multi-Query + HyDE"
            if bm25_results:
                search_methods += " + BM25"
            logger.info(f"ğŸ¯ RRF ìœµí•© ì™„ë£Œ ({search_methods}): {len(final_candidates)}ê°œ ìµœì¢… í›„ë³´")

            # ìƒìœ„ 5ê°œ RRF ì ìˆ˜ ì¶œë ¥
            logger.info("ğŸ“Š ìƒìœ„ 5ê°œ RRF ì ìˆ˜:")
            for i, doc_id in enumerate(final_candidates[:5], 1):
                score = rrf_scores[doc_id]
                logger.info(f"  {i}. {doc_id[:12]}... â†’ {score:.6f}")

            return final_candidates, rrf_scores

        except Exception as e:
            logger.error(f"âŒ RRF ìœµí•© ì‹¤íŒ¨: {e}")
            return [], {}

    def analyze_fusion_effect(self, multi_query_results: List[Dict[str, Any]],
                            hyde_results: List[Dict[str, Any]],
                            final_candidates: List[str]) -> Dict[str, Any]:
        """
        RRF ìœµí•© íš¨ê³¼ ë¶„ì„

        Args:
            multi_query_results: ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ ê²°ê³¼
            hyde_results: HyDE ê²€ìƒ‰ ê²°ê³¼
            final_candidates: ìµœì¢… í›„ë³´ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸

        Returns:
            ìœµí•© íš¨ê³¼ ë¶„ì„ ê²°ê³¼
        """
        try:
            # ê° ë°©ë²•ë³„ ë¬¸ì„œ ID ì§‘í•©
            multi_ids = set(doc['id'] for doc in multi_query_results)
            hyde_ids = set(doc['id'] for doc in hyde_results)
            final_ids = set(final_candidates)

            # êµì§‘í•© ë° ê³ ìœ  ë¬¸ì„œ ë¶„ì„
            both_methods = multi_ids & hyde_ids  # ë‘ ë°©ë²• ëª¨ë‘ì—ì„œ ë°œê²¬
            multi_only = multi_ids - hyde_ids   # ë©€í‹°ì¿¼ë¦¬ì—ë§Œ ìˆìŒ
            hyde_only = hyde_ids - multi_ids    # HyDEì—ë§Œ ìˆìŒ

            # ìµœì¢… í›„ë³´ì—ì„œì˜ êµ¬ì„± ë¶„ì„
            final_from_both = final_ids & both_methods
            final_from_multi_only = final_ids & multi_only
            final_from_hyde_only = final_ids & hyde_only

            analysis = {
                'original_stats': {
                    'multi_query_count': len(multi_ids),
                    'hyde_count': len(hyde_ids),
                    'both_methods': len(both_methods),
                    'multi_only': len(multi_only),
                    'hyde_only': len(hyde_only)
                },
                'final_composition': {
                    'total_candidates': len(final_candidates),
                    'from_both_methods': len(final_from_both),
                    'from_multi_only': len(final_from_multi_only),
                    'from_hyde_only': len(final_from_hyde_only)
                },
                'fusion_effectiveness': {
                    'coverage_improvement': len(final_ids) / max(len(multi_ids | hyde_ids), 1),
                    'balance_score': min(len(final_from_multi_only), len(final_from_hyde_only)) / max(len(final_candidates), 1)
                }
            }

            return analysis

        except Exception as e:
            logger.error(f"âŒ ìœµí•© íš¨ê³¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

class RRFRAGSystem:
    """RRF ê¸°ë°˜ RAG ì‹œìŠ¤í…œ"""

    def __init__(self, collection_name: str = "file_chunks",
                 rrf_config: Optional[RRFConfig] = None):
        """
        RRF RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”

        Args:
            collection_name: ChromaDB ì»¬ë ‰ì…˜ ì´ë¦„
            rrf_config: RRF ì„¤ì •
        """
        self.collection_name = collection_name
        self.config = rrf_config or RRFConfig()

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.client = None
        self.collection = None
        self.hyde_generator = None
        self.weighting_system = None
        self.rrf_engine = None

        # BM25 ê´€ë ¨
        self.bm25_index = None
        self.bm25_documents = []  # (doc_id, content) ë¦¬ìŠ¤íŠ¸
        self.bm25_corpus_tokenized = []  # í† í¬ë‚˜ì´ì¦ˆëœ ì½”í¼ìŠ¤
        self.tokenizer = None  # í•œêµ­ì–´ í† í¬ë‚˜ì´ì €

        self._init_components()

    def _init_components(self):
        """ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (Hybrid Search ì§€ì›)"""
        try:
            # ChromaDB ì—°ê²°
            self.client = chromadb.PersistentClient(
                path='./vector_db',
                settings=Settings(anonymized_telemetry=False, allow_reset=True)
            )
            self.collection = self.client.get_collection(self.collection_name)

            # Mock HyDE ìƒì„±ê¸°
            hyde_config = HyDEConfig()
            self.hyde_generator = MockHyDEGenerator(hyde_config)

            # ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ
            self.weighting_system = IntelligentChunkWeighting()

            # RRF ìœµí•© ì—”ì§„
            self.rrf_engine = RRFFusionEngine(self.config)

            # í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”
            use_korean_tokenizer = self.config.bm25_tokenizer == "korean"
            self.tokenizer = KoreanTokenizer(use_kiwi=use_korean_tokenizer)

            # BM25 ì¸ë±ìŠ¤ ì´ˆê¸°í™”
            if self.config.enable_bm25 and BM25_AVAILABLE:
                self._init_bm25_index()

            logger.info(f"âœ… RRF RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ: {self.collection.count()}ê°œ ë¬¸ì„œ")

        except Exception as e:
            logger.error(f"âŒ RRF RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise e

    def _init_bm25_index(self):
        """BM25 ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ”¨ BM25 ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘...")

            # ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
            all_docs = self.collection.get(include=["documents", "metadatas"])

            if not all_docs['ids']:
                logger.warning("âš ï¸ BM25: ë¬¸ì„œê°€ ì—†ì–´ ì¸ë±ìŠ¤ êµ¬ì¶• ë¶ˆê°€")
                return

            # ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ êµ¬ì¶•
            for i, doc_id in enumerate(all_docs['ids']):
                content = all_docs['documents'][i] if all_docs['documents'] else ""
                if content:
                    self.bm25_documents.append((doc_id, content))

            # í† í¬ë‚˜ì´ì§• (í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ ë˜ëŠ” ê³µë°± ê¸°ë°˜)
            for doc_id, content in self.bm25_documents:
                tokens = self.tokenizer.tokenize(content)
                self.bm25_corpus_tokenized.append(tokens)

            # BM25 ì¸ë±ìŠ¤ ìƒì„±
            if self.bm25_corpus_tokenized:
                self.bm25_index = BM25Okapi(self.bm25_corpus_tokenized)
                logger.info(f"âœ… BM25 ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(self.bm25_documents)}ê°œ ë¬¸ì„œ")
            else:
                logger.warning("âš ï¸ BM25: í† í¬ë‚˜ì´ì§•ëœ ë¬¸ì„œê°€ ì—†ìŒ")

        except Exception as e:
            logger.warning(f"âš ï¸ BM25 ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {e}")
            self.bm25_index = None

    def multi_query_search(self, query: str) -> List[Dict[str, Any]]:
        """
        ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ (ë…ë¦½ ì‹¤í–‰)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬

        Returns:
            ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ ê²°ê³¼ (ìˆœìœ„ ìˆœ)
        """
        try:
            # ë©€í‹° ì¿¼ë¦¬ ìƒì„±
            multi_queries = self.hyde_generator.generate_multi_queries(query)
            all_texts = [query] + multi_queries

            # ê° ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ë° ê²°ê³¼ ìˆ˜ì§‘
            all_results = []
            for i, text in enumerate(all_texts):
                results = self.collection.query(
                    query_texts=[text],
                    n_results=self.config.top_k_per_query
                )

                if results['ids'][0]:
                    for j in range(len(results['ids'][0])):
                        distance = results['distances'][0][j] if results['distances'][0] else 1.0
                        cosine_score = max(0.0, 1.0 - distance)

                        result = {
                            'id': results['ids'][0][j],
                            'content': results['documents'][0][j] if results['documents'][0] else "",
                            'distance': distance,
                            'cosine_score': cosine_score,
                            'query_index': i,
                            'source_text': text[:50] + "..." if len(text) > 50 else text
                        }
                        all_results.append(result)

            # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ í†µí•© (ìµœëŒ€ê°’ ì‚¬ìš©)
            unique_results = self._deduplicate_and_score(all_results)

            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ Nê°œ ë°˜í™˜
            sorted_results = sorted(unique_results, key=lambda x: x['cosine_score'], reverse=True)
            final_results = sorted_results[:self.config.multi_query_results]

            logger.info(f"âœ… ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ ê²°ê³¼")
            return final_results

        except Exception as e:
            logger.error(f"âŒ ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def hyde_search(self, query: str) -> List[Dict[str, Any]]:
        """
        HyDE ê²€ìƒ‰ (ë…ë¦½ ì‹¤í–‰)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬

        Returns:
            HyDE ê²€ìƒ‰ ê²°ê³¼ (ìˆœìœ„ ìˆœ)
        """
        try:
            # HyDE ë¬¸ì„œ ìƒì„±
            hypothetical_doc = self.hyde_generator.generate_hypothetical_document(query)
            all_texts = [query, hypothetical_doc]

            # ê° í…ìŠ¤íŠ¸ë¡œ ê²€ìƒ‰ ë° ê²°ê³¼ ìˆ˜ì§‘
            all_results = []
            for i, text in enumerate(all_texts):
                results = self.collection.query(
                    query_texts=[text],
                    n_results=self.config.top_k_per_query
                )

                if results['ids'][0]:
                    for j in range(len(results['ids'][0])):
                        distance = results['distances'][0][j] if results['distances'][0] else 1.0
                        cosine_score = max(0.0, 1.0 - distance)

                        result = {
                            'id': results['ids'][0][j],
                            'content': results['documents'][0][j] if results['documents'][0] else "",
                            'distance': distance,
                            'cosine_score': cosine_score,
                            'query_index': i,
                            'source_text': text[:100] + "..." if len(text) > 100 else text
                        }
                        all_results.append(result)

            # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ í†µí•©
            unique_results = self._deduplicate_and_score(all_results)

            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ Nê°œ ë°˜í™˜
            sorted_results = sorted(unique_results, key=lambda x: x['cosine_score'], reverse=True)
            final_results = sorted_results[:self.config.hyde_results]

            logger.info(f"âœ… HyDE ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ ê²°ê³¼")
            return final_results

        except Exception as e:
            logger.error(f"âŒ HyDE ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def bm25_search(self, query: str) -> List[Dict[str, Any]]:
        """
        BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ (ë…ë¦½ ì‹¤í–‰)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬

        Returns:
            BM25 ê²€ìƒ‰ ê²°ê³¼ (ìˆœìœ„ ìˆœ)
        """
        if not self.bm25_index:
            logger.warning("âš ï¸ BM25 ì¸ë±ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            return []

        try:
            # ì¿¼ë¦¬ í† í¬ë‚˜ì´ì§• (í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„)
            query_tokens = self.tokenizer.tokenize(query)

            # BM25 ì ìˆ˜ ê³„ì‚°
            bm25_scores = self.bm25_index.get_scores(query_tokens)

            # ê²°ê³¼ êµ¬ì„±
            results = []
            for idx, score in enumerate(bm25_scores):
                if score > 0:  # ì ìˆ˜ê°€ 0ë³´ë‹¤ í° ê²ƒë§Œ
                    doc_id, content = self.bm25_documents[idx]
                    results.append({
                        'id': doc_id,
                        'content': content,
                        'bm25_score': float(score),
                        'cosine_score': float(score),  # í˜¸í™˜ì„±ì„ ìœ„í•´
                        'distance': 1.0 - min(float(score), 1.0)  # í˜¸í™˜ì„±ì„ ìœ„í•´
                    })

            # BM25 ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_results = sorted(results, key=lambda x: x['bm25_score'], reverse=True)
            final_results = sorted_results[:self.config.bm25_results]

            logger.info(f"âœ… BM25 ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ ê²°ê³¼")
            return final_results

        except Exception as e:
            logger.error(f"âŒ BM25 ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _deduplicate_and_score(self, all_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ê²°ê³¼ ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ í†µí•©"""
        unique_docs = {}

        for result in all_results:
            doc_id = result['id']
            cosine_score = result['cosine_score']

            if doc_id not in unique_docs:
                unique_docs[doc_id] = {
                    'id': doc_id,
                    'content': result['content'],
                    'distance': result['distance'],
                    'cosine_score': cosine_score,
                    'scores': [cosine_score],
                    'query_indices': [result['query_index']],
                    'source_texts': [result['source_text']]
                }
            else:
                # ìµœëŒ€ ì ìˆ˜ë¡œ ì—…ë°ì´íŠ¸
                if cosine_score > unique_docs[doc_id]['cosine_score']:
                    unique_docs[doc_id]['cosine_score'] = cosine_score
                    unique_docs[doc_id]['distance'] = result['distance']

                unique_docs[doc_id]['scores'].append(cosine_score)
                unique_docs[doc_id]['query_indices'].append(result['query_index'])
                unique_docs[doc_id]['source_texts'].append(result['source_text'])

        return list(unique_docs.values())

    def load_documents_by_ids(self, doc_ids: List[str]) -> List[Dict[str, Any]]:
        """
        ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸ë¡œ ì „ì²´ ë¬¸ì„œ ì •ë³´ ë¡œë“œ

        Args:
            doc_ids: ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸

        Returns:
            ë¬¸ì„œ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (ID ìˆœì„œ ìœ ì§€)
        """
        try:
            if not doc_ids:
                return []

            # ChromaDBì—ì„œ ë¬¸ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            results = self.collection.get(ids=doc_ids, include=['documents', 'metadatas'])

            # ê²°ê³¼ë¥¼ ID ìˆœì„œì— ë§ê²Œ ì •ë ¬
            id_to_data = {}
            for i, doc_id in enumerate(results['ids']):
                id_to_data[doc_id] = {
                    'id': doc_id,
                    'content': results['documents'][i] if results['documents'] else "",
                    'metadata': results['metadatas'][i] if results['metadatas'] else {}
                }

            # ì›ë˜ ìˆœì„œ ìœ ì§€
            ordered_documents = []
            for doc_id in doc_ids:
                if doc_id in id_to_data:
                    ordered_documents.append(id_to_data[doc_id])

            return ordered_documents

        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    def rrf_search(self, query: str) -> List[Dict[str, Any]]:
        """
        RRF ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Multi-Query + HyDE + BM25)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬

        Returns:
            RRF ìœµí•©ëœ ìµœì¢… ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            search_methods = []
            logger.info(f"ğŸš€ RRF ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘: '{query}'")

            # 1. ë©€í‹°ì¿¼ë¦¬, HyDE, BM25 ê²€ìƒ‰ì„ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰
            logger.info("ğŸ“Š 1ë‹¨ê³„: ë…ë¦½ ê²€ìƒ‰ ì‹¤í–‰")
            multi_query_results = self.multi_query_search(query)
            if multi_query_results:
                search_methods.append("Multi-Query")

            hyde_results = self.hyde_search(query)
            if hyde_results:
                search_methods.append("HyDE")

            # BM25 ê²€ìƒ‰ (í™œì„±í™”ëœ ê²½ìš°)
            bm25_results = []
            if self.config.enable_bm25 and self.bm25_index:
                bm25_results = self.bm25_search(query)
                if bm25_results:
                    search_methods.append("BM25")

            if not multi_query_results and not hyde_results and not bm25_results:
                logger.warning("âš ï¸ ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
                return []

            logger.info(f"ğŸ” ì‚¬ìš©ëœ ê²€ìƒ‰ ë°©ì‹: {' + '.join(search_methods)}")

            # 2. RRFë¡œ ê²°ê³¼ ìœµí•©
            logger.info("ğŸ”„ 2ë‹¨ê³„: RRF ìœµí•©")
            final_candidate_ids, rrf_scores = self.rrf_engine.fuse_results(
                multi_query_results,
                hyde_results,
                bm25_results if bm25_results else None
            )

            if not final_candidate_ids:
                logger.warning("âš ï¸ RRF ìœµí•© ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
                return []

            # 3. ìµœì¢… í›„ë³´ ë¬¸ì„œ ì •ë³´ ë¡œë“œ
            logger.info("ğŸ“„ 3ë‹¨ê³„: í›„ë³´ ë¬¸ì„œ ë¡œë“œ")
            final_documents = self.load_documents_by_ids(final_candidate_ids)

            # 4. ê°€ì¤‘ì¹˜ ì ìš©
            logger.info("âš–ï¸ 4ë‹¨ê³„: RRF ì ìˆ˜ ì ìš©")
            weighted_results = self._apply_weighting_to_documents(final_documents, query, rrf_scores)

            # 5. ìœµí•© íš¨ê³¼ ë¶„ì„
            fusion_analysis = self.rrf_engine.analyze_fusion_effect(
                multi_query_results, hyde_results, final_candidate_ids
            )

            logger.info("ğŸ“ˆ RRF ìœµí•© íš¨ê³¼ ë¶„ì„:")
            if fusion_analysis:
                orig_stats = fusion_analysis['original_stats']
                final_comp = fusion_analysis['final_composition']
                logger.info(f"  ì›ë³¸: Multi({orig_stats['multi_query_count']}) + HyDE({orig_stats['hyde_count']}) â†’ ê³ ìœ ({orig_stats['both_methods'] + orig_stats['multi_only'] + orig_stats['hyde_only']})")
                logger.info(f"  ìµœì¢…: {final_comp['total_candidates']}ê°œ (ì–‘ìª½:{final_comp['from_both_methods']}, Multië§Œ:{final_comp['from_multi_only']}, HyDEë§Œ:{final_comp['from_hyde_only']})")

            # 6. í‹°ì¼“ ì¤‘ë³µ ì œê±° (ì˜µì…˜)
            final_results = weighted_results
            if self.config.deduplicate_tickets:
                logger.info("ğŸ¯ 5ë‹¨ê³„: í‹°ì¼“ ì¤‘ë³µ ì œê±°")
                final_results = self.deduplicate_by_ticket(
                    weighted_results,
                    strategy=self.config.deduplication_strategy
                )

            logger.info(f"âœ… RRF ê¸°ë°˜ ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ ê²°ê³¼")
            return final_results

        except Exception as e:
            logger.error(f"âŒ RRF ê¸°ë°˜ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _apply_weighting_to_documents(self, documents: List[Dict[str, Any]], query: str,
                                     rrf_scores: Dict[str, float]) -> List[Dict[str, Any]]:
        """ë¬¸ì„œì— RRF ì ìˆ˜ ì ìš© (ì²­í¬ íƒ€ì… ê°€ì¤‘ì¹˜ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)"""
        try:
            if not documents:
                return []

            # RRF ì ìˆ˜ë¥¼ ì§ì ‘ ì‚¬ìš© (ì²­í¬ íƒ€ì… ê°€ì¤‘ì¹˜ ë¬´ì‹œ)
            final_results = []
            for i, doc in enumerate(documents):
                doc_id = doc['id']
                rrf_score = rrf_scores.get(doc_id, 0.0)
                chunk_type = self._estimate_chunk_type(doc['content'])

                result = {
                    'id': doc_id,
                    'content': doc['content'],
                    'score': rrf_score,  # RRF ì ìˆ˜ ì§ì ‘ ì‚¬ìš©
                    'chunk_type': chunk_type,
                    'rrf_rank': i + 1,  # RRF ìˆœìœ„ ì¶”ê°€
                    'method': 'rrf_fusion',
                    'source': 'rrf_rag_system',
                    'metadata': {
                        **doc.get('metadata', {}),
                        'rrf_enhanced': True,
                        'rrf_score': rrf_score
                    }
                }
                final_results.append(result)

            return final_results

        except Exception as e:
            logger.error(f"âŒ ê°€ì¤‘ì¹˜ ì ìš© ì‹¤íŒ¨: {e}")
            return []

    def deduplicate_by_ticket(self, results: List[Dict[str, Any]],
                             strategy: str = 'max_score') -> List[Dict[str, Any]]:
        """
        í‹°ì¼“ ë‹¨ìœ„ë¡œ ì¤‘ë³µ ì œê±°

        Args:
            results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            strategy: ì¤‘ë³µ ì œê±° ì „ëµ
                - 'max_score': ìµœê³  ì ìˆ˜ ì²­í¬ë§Œ ì„ íƒ (ê¸°ë³¸)
                - 'first': ì²« ë²ˆì§¸ ì²­í¬ë§Œ ì„ íƒ
                - 'merge': ëª¨ë“  ì²­í¬ë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©
                - 'all_scores': ëª¨ë“  ì²­í¬ ì ìˆ˜ í•©ì‚°

        Returns:
            í‹°ì¼“ ë‹¨ìœ„ë¡œ ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼
        """
        from collections import defaultdict

        # í‹°ì¼“ IDë³„ë¡œ ê·¸ë£¹í™”
        ticket_groups = defaultdict(list)

        for result in results:
            metadata = result.get('metadata', {})
            # ticket_id ì¶”ì¶œ
            ticket_id = None
            for key in ['ticket_id', 'ticket_key', 'jira_key', 'issue_key', 'key']:
                if key in metadata:
                    ticket_id = metadata[key]
                    break

            if ticket_id:
                ticket_groups[ticket_id].append(result)
            else:
                # ticket_idê°€ ì—†ëŠ” ê²½ìš° chunk_idë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                ticket_groups[result['id']].append(result)

        # ì „ëµì— ë”°ë¼ ëŒ€í‘œ ì²­í¬ ì„ íƒ
        deduplicated_results = []

        for ticket_id, chunks in ticket_groups.items():
            if strategy == 'max_score':
                # ìµœê³  ì ìˆ˜ ì²­í¬ ì„ íƒ
                best_chunk = max(chunks, key=lambda x: x.get('score', 0.0))
                deduplicated_results.append(best_chunk)

            elif strategy == 'first':
                # ì²« ë²ˆì§¸ ì²­í¬ ì„ íƒ
                deduplicated_results.append(chunks[0])

            elif strategy == 'all_scores':
                # ì ìˆ˜ í•©ì‚°
                best_chunk = max(chunks, key=lambda x: x.get('score', 0.0))
                total_score = sum(c.get('score', 0.0) for c in chunks)
                best_chunk['score'] = total_score
                best_chunk['metadata']['aggregated_chunks'] = len(chunks)
                best_chunk['metadata']['original_score'] = best_chunk.get('score', 0.0)
                deduplicated_results.append(best_chunk)

            elif strategy == 'merge':
                # ëª¨ë“  ì²­í¬ ë‚´ìš© ë³‘í•©
                best_chunk = chunks[0].copy()
                merged_content = '\n\n'.join([c['content'] for c in chunks])
                best_chunk['content'] = merged_content
                best_chunk['score'] = max(c.get('score', 0.0) for c in chunks)
                best_chunk['metadata']['merged_chunks'] = len(chunks)
                deduplicated_results.append(best_chunk)

        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì¬ì •ë ¬
        deduplicated_results.sort(key=lambda x: x.get('score', 0.0), reverse=True)

        logger.info(f"ğŸ”„ í‹°ì¼“ ì¤‘ë³µ ì œê±°: {len(results)}ê°œ ì²­í¬ â†’ {len(deduplicated_results)}ê°œ í‹°ì¼“ (ì „ëµ: {strategy})")

        return deduplicated_results

    def _estimate_chunk_type(self, content: str) -> str:
        """chunk_type ì¶”ì •"""
        content_lower = content.lower()

        if any(pattern in content_lower for pattern in ['ì œëª©:', 'title:', 'ì´ìŠˆ í‚¤:']):
            return 'title'
        elif any(pattern in content_lower for pattern in ['ìš”ì•½:', 'summary:']):
            return 'summary'
        elif any(pattern in content_lower for pattern in ['ì„¤ëª…:', 'description:']):
            return 'description'
        elif any(pattern in content_lower for pattern in ['ëŒ“ê¸€:', 'comment:']):
            return 'comment'
        elif len(content.strip()) < 30:
            return 'title'
        elif len(content.strip()) < 100:
            return 'summary'
        elif len(content.strip()) > 1000:
            return 'body'
        else:
            return 'description'

def compare_rrf_vs_hybrid():
    """RRF vs ê¸°ì¡´ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ ë¹„êµ"""
    print("ğŸ”¬ RRF vs í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°©ì‹ ë¹„êµ")
    print("="*80)

    try:
        # RRF ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rrf_system = RRFRAGSystem()

        # ê¸°ì¡´ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ (ë¹„êµìš©)
        from comprehensive_hyde_golden_set_test import ComprehensiveHyDETestSystem
        hybrid_system = ComprehensiveHyDETestSystem()

        test_questions = [
            "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ê°€ ë³µì¡í•´ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤",
            "ì„œë²„ì— ì ‘ì†í•  ìˆ˜ ì—†ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì‹¶ì–´ìš”",
            "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ìì£¼ ëŠì–´ì§€ëŠ” í˜„ìƒì„ ì¡°ì‚¬í•´ì£¼ì„¸ìš”"
        ]

        for i, query in enumerate(test_questions, 1):
            print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ {i}: {query}")
            print("-" * 60)

            # RRF ê²€ìƒ‰
            print("ğŸ”„ RRF ë°©ì‹:")
            rrf_results = rrf_system.rrf_search(query)
            print(f"   ê²°ê³¼: {len(rrf_results)}ê°œ")

            # ê¸°ì¡´ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
            print("ğŸ”„ ê¸°ì¡´ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹:")
            hybrid_results = hybrid_system.hybrid_search(query, n_results=10)
            print(f"   ê²°ê³¼: {len(hybrid_results)}ê°œ")

            # ìƒìœ„ 3ê°œ ê²°ê³¼ ë¹„êµ
            print(f"\nğŸ† ìƒìœ„ 3ê°œ ê²°ê³¼ ë¹„êµ:")

            print("RRF ë°©ì‹:")
            for j, result in enumerate(rrf_results[:3], 1):
                score = result.get('score', 0)
                rrf_rank = result.get('rrf_rank', j)
                chunk_type = result.get('chunk_type', 'unknown')
                content_preview = result['content'][:80].replace('\n', ' ') + "..."
                print(f"  {j}. [{chunk_type}] RRFìˆœìœ„:{rrf_rank} ì ìˆ˜:{score:.4f}")
                print(f"     {content_preview}")

            print("\nê¸°ì¡´ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹:")
            for j, result in enumerate(hybrid_results[:3], 1):
                score = result.get('score', result.get('raw_score', 0))
                chunk_type = result.get('chunk_type', 'unknown')
                content_preview = result['content'][:80].replace('\n', ' ') + "..."
                print(f"  {j}. [{chunk_type}] ì ìˆ˜:{score:.4f}")
                print(f"     {content_preview}")

        return True

    except Exception as e:
        print(f"âŒ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_rrf_system():
    """RRF ì‹œìŠ¤í…œ ë‹¨ë… í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ RRF RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("="*80)

    try:
        # RRF ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rrf_system = RRFRAGSystem()

        test_questions = [
            "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ê°€ ë³µì¡í•´ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤",
            "API ì‘ë‹µ ì‹œê°„ì´ ë„ˆë¬´ ëŠë ¤ì„œ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤"
        ]

        for i, query in enumerate(test_questions, 1):
            print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ {i}: {query}")
            print("="*60)

            # RRF ê²€ìƒ‰ ìˆ˜í–‰
            results = rrf_system.rrf_search(query)

            if results:
                print(f"âœ… {len(results)}ê°œ ê²°ê³¼ (RRF + ê°€ì¤‘ì¹˜)")

                # ìƒìœ„ 5ê°œ ê²°ê³¼ í‘œì‹œ
                for j, result in enumerate(results[:5], 1):
                    score = result.get('score', 0)
                    raw_score = result.get('raw_score', 0)
                    weight = result.get('weight', 1.0)
                    chunk_type = result.get('chunk_type', 'unknown')
                    rrf_rank = result.get('rrf_rank', j)

                    print(f"  {j}. [{chunk_type.upper()}] (RRFìˆœìœ„: {rrf_rank}, ê°€ì¤‘ì¹˜: {weight:.1f})")
                    print(f"     ì ìˆ˜: {raw_score:.4f} â†’ {score:.4f}")

                    content_preview = result['content'][:100].replace('\n', ' ') + "..."
                    print(f"     ë‚´ìš©: {content_preview}")
                    print()
            else:
                print("âŒ ê²°ê³¼ ì—†ìŒ")

        return True

    except Exception as e:
        print(f"âŒ RRF ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("RRF RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì„ íƒ:")
    print("1. RRF ì‹œìŠ¤í…œ ë‹¨ë… í…ŒìŠ¤íŠ¸")
    print("2. RRF vs í•˜ì´ë¸Œë¦¬ë“œ ë¹„êµ í…ŒìŠ¤íŠ¸")

    choice = input("\nì„ íƒ (1/2): ").strip()

    if choice == "1":
        test_rrf_system()
    elif choice == "2":
        compare_rrf_vs_hybrid()
    else:
        print("RRF ì‹œìŠ¤í…œ ë‹¨ë… í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        test_rrf_system()