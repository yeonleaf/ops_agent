"""
êµ¬ì¡°ì  ë°ì´í„° ì²­í‚¹ ëª¨ë“ˆ
Jira í‹°ì¼“ê³¼ ê°™ì€ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ì˜ë¯¸ ìˆëŠ” ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from bs4 import BeautifulSoup
import logging

logger = logging.getLogger(__name__)

@dataclass
class StructuredChunk:
    """êµ¬ì¡°í™”ëœ ì²­í¬ ë°ì´í„° í´ë˜ìŠ¤"""
    content: str
    chunk_type: str  # 'header', 'comment'
    ticket_id: str
    field_name: str
    field_value: str
    metadata: Dict[str, Any]
    priority: int = 1  # 1: ë†’ìŒ, 2: ì¤‘ê°„, 3: ë‚®ìŒ
    commenter: Optional[str] = None  # ëŒ“ê¸€ ì‘ì„±ì (comment íƒ€ì…ì¼ ë•Œë§Œ)

class JiraStructuredChunker:
    """Jira ë°ì´í„°ì˜ êµ¬ì¡°ì  ì²­í‚¹ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤
    
    ìƒˆë¡œìš´ ì²­í‚¹ ì „ëµ:
    1. 'í—¤ë”(Header)' ì²­í¬: Summary + Descriptionì„ í•©ì³ì„œ í•˜ë‚˜ì˜ í•µì‹¬ ì²­í¬ ìƒì„±
    2. 'ëŒ“ê¸€(Comment)' ì²­í¬: ê° ëŒ“ê¸€ì„ ê°œë³„ì ì¸ ì²­í¬ë¡œ ìƒì„±
    """
    
    def __init__(self):
        self.chunk_types = {
            'header': 'í—¤ë” (Summary + Description)',
            'comment': 'ëŒ“ê¸€'
        }
    
    def chunk_jira_html(self, html_content: str, file_name: str) -> List[StructuredChunk]:
        """
        Jira HTML íŒŒì¼ì„ êµ¬ì¡°ì  ì²­í¬ë¡œ ë¶„í• 
        
        Args:
            html_content: Jira HTML ë‚´ìš©
            file_name: íŒŒì¼ëª…
            
        Returns:
            êµ¬ì¡°í™”ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            chunks = []
            
            # í…Œì´ë¸”ì—ì„œ í‹°ì¼“ í–‰ë“¤ì„ ì°¾ê¸°
            ticket_rows = soup.find_all('tr', class_='issuerow')
            
            print(f"ğŸ” Jira HTMLì—ì„œ {len(ticket_rows)}ê°œì˜ í‹°ì¼“ í–‰ ë°œê²¬")
            
            for row in ticket_rows:
                ticket_chunks = self._extract_ticket_chunks_from_html(row, file_name)
                chunks.extend(ticket_chunks)
            
            print(f"âœ… êµ¬ì¡°ì  ì²­í‚¹ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
            return chunks
            
        except Exception as e:
            logger.error(f"Jira HTML ì²­í‚¹ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _extract_ticket_chunks_from_html(self, row, file_name: str) -> List[StructuredChunk]:
        """HTML í–‰ì—ì„œ ìƒˆë¡œìš´ ì²­í‚¹ ì „ëµì— ë”°ë¼ ì²­í¬ë“¤ì„ ì¶”ì¶œ"""
        chunks = []
        
        try:
            # í‹°ì¼“ ID ì¶”ì¶œ
            ticket_id = row.get('data-issuekey', 'UNKNOWN')
            if not ticket_id or ticket_id == 'UNKNOWN':
                return chunks
            
            cells = row.find_all('td')
            if len(cells) < 3:  # ìµœì†Œ í•„ìˆ˜ í•„ë“œ ìˆ˜ í™•ì¸
                return chunks
            
            # 1. í—¤ë” ì²­í¬ ìƒì„± (Summary + Description)
            summary_text = ""
            description_text = ""
            
            # Summary ì¶”ì¶œ (ì¼ë°˜ì ìœ¼ë¡œ 3ë²ˆì§¸ ì…€)
            if len(cells) > 2:
                summary_cell = cells[2]
                summary_text = summary_cell.get_text(strip=True)
            
            # Descriptionì€ HTML í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¶”ì¶œí•˜ê¸° ì–´ë ¤ìš°ë¯€ë¡œ 
            # Summaryë§Œìœ¼ë¡œ í—¤ë” ì²­í¬ ìƒì„± (ì‹¤ì œ Descriptionì€ APIë‚˜ ìƒì„¸ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
            if summary_text:
                header_content = f"ìš”ì•½: {summary_text}"
                if description_text:
                    header_content += f"\nì„¤ëª…: {description_text}"
                
                chunk = StructuredChunk(
                    content=header_content,
                    chunk_type="header",
                    ticket_id=ticket_id,
                    field_name="header",
                    field_value=header_content,
                    metadata={
                        "file_name": file_name,
                        "ticket_id": ticket_id,
                        "field_type": "header",
                        "summary": summary_text,
                        "description": description_text
                    },
                    priority=1
                )
                chunks.append(chunk)
            
            # 2. ëŒ“ê¸€ ì²­í¬ ìƒì„± (HTMLì—ì„œëŠ” ëŒ“ê¸€ ì •ë³´ê°€ í…Œì´ë¸”ì— ì§ì ‘ í¬í•¨ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ 
            # ì‹¤ì œë¡œëŠ” APIë¥¼ í†µí•´ ë³„ë„ë¡œ ê°€ì ¸ì™€ì•¼ í•¨)
            # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Jira APIë¥¼ í†µí•´ ëŒ“ê¸€ì„ ê°€ì ¸ì™€ì•¼ í•¨
            
            print(f"ğŸ“ í‹°ì¼“ {ticket_id}: {len(chunks)}ê°œ ì²­í¬ ìƒì„± (í—¤ë”: {len([c for c in chunks if c.chunk_type == 'header'])}, ëŒ“ê¸€: {len([c for c in chunks if c.chunk_type == 'comment'])})")
            
        except Exception as e:
            logger.error(f"í‹°ì¼“ ì²­í‚¹ ì‹¤íŒ¨: {str(e)}")
        
        return chunks
    
    def chunk_csv_data(self, csv_data: List[Dict[str, Any]], file_name: str) -> List[StructuredChunk]:
        """
        CSV ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ ì²­í‚¹ ì „ëµì— ë”°ë¼ êµ¬ì¡°ì  ì²­í¬ë¡œ ë¶„í• 
        
        Args:
            csv_data: CSV ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            file_name: íŒŒì¼ëª…
            
        Returns:
            êµ¬ì¡°í™”ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        chunks = []
        
        try:
            for row in csv_data:
                ticket_id = row.get('Key', 'UNKNOWN')
                
                # 1. í—¤ë” ì²­í¬ ìƒì„± (Summary + Description)
                summary = row.get('Summary', '')
                description = row.get('Description', '')
                
                if summary or description:
                    # Summaryì™€ Descriptionì„ í•©ì³ì„œ í•˜ë‚˜ì˜ í—¤ë” ì²­í¬ ìƒì„±
                    header_content = ""
                    if summary:
                        header_content += f"ìš”ì•½: {summary}"
                    if description:
                        if header_content:
                            header_content += f"\nì„¤ëª…: {description}"
                        else:
                            header_content = f"ì„¤ëª…: {description}"
                    
                    chunk = StructuredChunk(
                        content=header_content,
                        chunk_type="header",
                        ticket_id=ticket_id,
                        field_name="header",
                        field_value=header_content,
                        metadata={
                            "file_name": file_name,
                            "ticket_id": ticket_id,
                            "field_type": "header",
                            "summary": summary,
                            "description": description
                        },
                        priority=1
                    )
                    chunks.append(chunk)
                
                # 2. ëŒ“ê¸€ ì²­í¬ ìƒì„± (ê° ëŒ“ê¸€ì„ ê°œë³„ ì²­í¬ë¡œ)
                comments = self._extract_comments_from_csv_row(row)
                for comment in comments:
                    chunk = StructuredChunk(
                        content=comment['content'],
                        chunk_type="comment",
                        ticket_id=ticket_id,
                        field_name="comment",
                        field_value=comment['content'],
                        metadata={
                            "file_name": file_name,
                            "ticket_id": ticket_id,
                            "field_type": "comment",
                            "comment_id": comment.get('id', ''),
                            "comment_date": comment.get('date', '')
                        },
                        priority=2,
                        commenter=comment.get('author', 'Unknown')
                    )
                    chunks.append(chunk)
            
            print(f"âœ… CSV êµ¬ì¡°ì  ì²­í‚¹ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
            print(f"   - í—¤ë” ì²­í¬: {len([c for c in chunks if c.chunk_type == 'header'])}ê°œ")
            print(f"   - ëŒ“ê¸€ ì²­í¬: {len([c for c in chunks if c.chunk_type == 'comment'])}ê°œ")
            
        except Exception as e:
            logger.error(f"CSV ì²­í‚¹ ì‹¤íŒ¨: {str(e)}")
        
        return chunks
    
    def _extract_comments_from_csv_row(self, row: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        CSV í–‰ì—ì„œ ëŒ“ê¸€ ì •ë³´ë¥¼ ì¶”ì¶œ
        
        Args:
            row: CSV í–‰ ë°ì´í„°
            
        Returns:
            ëŒ“ê¸€ ë¦¬ìŠ¤íŠ¸
        """
        comments = []
        
        # Comments í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
        comments_field = row.get('Comments', '')
        if not comments_field or comments_field.strip() == '':
            return comments
        
        # ëŒ“ê¸€ì„ íŒŒì‹± (ì—¬ëŸ¬ ëŒ“ê¸€ì´ ìˆì„ ìˆ˜ ìˆìŒ)
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” CSVì˜ Comments í•„ë“œ í˜•ì‹ì— ë”°ë¼ íŒŒì‹± ë¡œì§ì„ ì¡°ì •í•´ì•¼ í•¨
        try:
            # ê°„ë‹¨í•œ ëŒ“ê¸€ ë¶„ë¦¬ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ íŒŒì‹±ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ)
            comment_texts = comments_field.split('\n---\n')  # ëŒ“ê¸€ êµ¬ë¶„ìë¡œ ê°€ì •
            
            for i, comment_text in enumerate(comment_texts):
                if comment_text.strip():
                    comments.append({
                        'id': f"comment_{i+1}",
                        'content': comment_text.strip(),
                        'author': 'Unknown',  # CSVì—ì„œ ì‘ì„±ì ì •ë³´ ì¶”ì¶œì´ ì–´ë ¤ì›€
                        'date': ''  # CSVì—ì„œ ë‚ ì§œ ì •ë³´ ì¶”ì¶œì´ ì–´ë ¤ì›€
                    })
        except Exception as e:
            logger.warning(f"ëŒ“ê¸€ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        
        return comments

def test_structured_chunking():
    """êµ¬ì¡°ì  ì²­í‚¹ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§ª ìƒˆë¡œìš´ êµ¬ì¡°ì  ì²­í‚¹ ì „ëµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # CSV ë°ì´í„° í…ŒìŠ¤íŠ¸ (ëŒ“ê¸€ í¬í•¨)
    csv_data = [
        {
            "Key": "T-001",
            "Summary": "ì„œë²„ ì ‘ì† ë¶ˆê°€ ë¬¸ì œ",
            "Description": "ë©”ì¸ ì„œë²„ì— ì ‘ì†ì´ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. HTTP 500 ì˜¤ë¥˜ê°€ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "Comments": "ê¹€ê°œë°œ: ë¡œê·¸ë¥¼ í™•ì¸í•´ë³´ë‹ˆ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œë¡œ ë³´ì…ë‹ˆë‹¤.\n---\nì´ì‚¬ìš©: ë„¤íŠ¸ì›Œí¬ ì„¤ì •ë„ í™•ì¸í•´ì£¼ì„¸ìš”.",
            "Issue Type": "Bug",
            "Priority": "High",
            "Status": "Open",
            "Assignee": "ê¹€ê°œë°œ",
            "Reporter": "ì´ì‚¬ìš©",
            "Created": "2024-01-15",
            "Updated": "2024-01-15"
        },
        {
            "Key": "T-002",
            "Summary": "UI ê°œì„  ìš”ì²­",
            "Description": "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ê°€ ì§ê´€ì ì´ì§€ ì•Šì•„ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.",
            "Comments": "í™ê¸¸ë™: íŠ¹íˆ ë¡œê·¸ì¸ í™”ë©´ì˜ ë²„íŠ¼ ë°°ì¹˜ë¥¼ ê°œì„ í•˜ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.",
            "Issue Type": "Improvement",
            "Priority": "Medium",
            "Status": "Open",
            "Assignee": "ë°•ë””ìì¸",
            "Reporter": "í™ê¸¸ë™",
            "Created": "2024-01-16",
            "Updated": "2024-01-16"
        }
    ]
    
    chunker = JiraStructuredChunker()
    csv_chunks = chunker.chunk_csv_data(csv_data, "test.csv")
    
    print(f"\nğŸ“Š CSV ì²­í‚¹ ê²°ê³¼: {len(csv_chunks)}ê°œ")
    
    # ì²­í¬ íƒ€ì…ë³„ë¡œ ê·¸ë£¹í™”
    header_chunks = [c for c in csv_chunks if c.chunk_type == 'header']
    comment_chunks = [c for c in csv_chunks if c.chunk_type == 'comment']
    
    print(f"   - í—¤ë” ì²­í¬: {len(header_chunks)}ê°œ")
    print(f"   - ëŒ“ê¸€ ì²­í¬: {len(comment_chunks)}ê°œ")
    
    # í—¤ë” ì²­í¬ ì¶œë ¥
    print(f"\nğŸ“‹ í—¤ë” ì²­í¬ë“¤:")
    for i, chunk in enumerate(header_chunks, 1):
        print(f"\n--- í—¤ë” ì²­í¬ {i} ---")
        print(f"í‹°ì¼“ ID: {chunk.ticket_id}")
        print(f"ìš°ì„ ìˆœìœ„: {chunk.priority}")
        print(f"ë‚´ìš©: {chunk.content}")
        print(f"ëŒ“ê¸€ ì‘ì„±ì: {chunk.commenter or 'N/A'}")
    
    # ëŒ“ê¸€ ì²­í¬ ì¶œë ¥
    print(f"\nğŸ’¬ ëŒ“ê¸€ ì²­í¬ë“¤:")
    for i, chunk in enumerate(comment_chunks, 1):
        print(f"\n--- ëŒ“ê¸€ ì²­í¬ {i} ---")
        print(f"í‹°ì¼“ ID: {chunk.ticket_id}")
        print(f"ëŒ“ê¸€ ì‘ì„±ì: {chunk.commenter}")
        print(f"ìš°ì„ ìˆœìœ„: {chunk.priority}")
        print(f"ë‚´ìš©: {chunk.content}")

if __name__ == "__main__":
    test_structured_chunking()
