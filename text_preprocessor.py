#!/usr/bin/env python3
"""
ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ëª¨ë“ˆ
RAG ì‹œìŠ¤í…œì˜ 1ì°¨ ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì •ì œ
"""

import re
from typing import Optional
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TextPreprocessor:
    """ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        """ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”"""
        self._compile_patterns()
        logger.info("í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _compile_patterns(self):
        """ì •ê·œì‹ íŒ¨í„´ ì»´íŒŒì¼"""
        # 1. ëŒ€ê´„í˜¸ë¡œ ë¬¶ì¸ í”„ë¡œì íŠ¸ ì½”ë“œ ë° í‹°ì¼“ ID íŒ¨í„´
        self.bracket_patterns = [
            r'\[NCMS\]',                    # [NCMS]
            r'\[BTVO[-\s]*\d+\]',          # [BTVO-12345] ë˜ëŠ” [BTVO 12345]
            r'\[[A-Z]{2,}[-\s]*\d+\]',     # [PROJ-123] í˜•íƒœì˜ í”„ë¡œì íŠ¸ ì½”ë“œ
            r'\[[A-Z]{2,}\]',              # [PROJ] í˜•íƒœì˜ í”„ë¡œì íŠ¸ ì½”ë“œ
            r'\[T-\d+\]',                  # [T-123] í˜•íƒœì˜ í‹°ì¼“ ID
            r'\[[A-Z]+-\d+\]',             # [ABC-123] í˜•íƒœì˜ ì¼ë°˜ì ì¸ í‹°ì¼“ ID
        ]
        
        # 2. í•„ë“œ ì´ë¦„ ì ‘ë‘ì‚¬ íŒ¨í„´
        self.field_prefix_patterns = [
            r'^ìš”ì•½\s*[:ï¼š]\s*',           # ìš”ì•½: ë˜ëŠ” ìš”ì•½ï¼š
            r'^ì„¤ëª…\s*[:ï¼š]\s*',           # ì„¤ëª…: ë˜ëŠ” ì„¤ëª…ï¼š
            r'^ì œëª©\s*[:ï¼š]\s*',           # ì œëª©: ë˜ëŠ” ì œëª©ï¼š
            r'^ë‚´ìš©\s*[:ï¼š]\s*',           # ë‚´ìš©: ë˜ëŠ” ë‚´ìš©ï¼š
            r'^ëŒ“ê¸€\s*[:ï¼š]\s*',           # ëŒ“ê¸€: ë˜ëŠ” ëŒ“ê¸€ï¼š
            r'^ì½”ë©˜íŠ¸\s*[:ï¼š]\s*',         # ì½”ë©˜íŠ¸: ë˜ëŠ” ì½”ë©˜íŠ¸ï¼š
            r'^Summary\s*[:ï¼š]\s*',        # Summary: ë˜ëŠ” Summaryï¼š
            r'^Description\s*[:ï¼š]\s*',    # Description: ë˜ëŠ” Descriptionï¼š
            r'^Title\s*[:ï¼š]\s*',          # Title: ë˜ëŠ” Titleï¼š
            r'^Content\s*[:ï¼š]\s*',        # Content: ë˜ëŠ” Contentï¼š
            r'^Comment\s*[:ï¼š]\s*',        # Comment: ë˜ëŠ” Commentï¼š
        ]
        
        # 3. ê´„í˜¸ë¡œ ë¬¶ì¸ ë‚ ì§œ ì •ë³´ íŒ¨í„´
        self.date_patterns = [
            r'\(\d{1,2}/\d{1,2}~\d{1,2}\)',     # (5/8~12)
            r'\(\d{1,2}/\d{1,2}\)',             # (5/8)
            r'\(\d{4}-\d{1,2}-\d{1,2}\)',       # (2024-01-15)
            r'\(\d{1,2}ì›”\s*\d{1,2}ì¼\)',       # (1ì›” 15ì¼)
            r'\(\d{1,2}/\d{1,2}/\d{4}\)',       # (1/15/2024)
            r'\(\d{4}\.\d{1,2}\.\d{1,2}\)',     # (2024.01.15)
        ]
        
        # 4. ê¸°íƒ€ ë…¸ì´ì¦ˆ íŒ¨í„´
        self.noise_patterns = [
            r'https?://[^\s]+',              # URL ì œê±°
            r'www\.[^\s]+',                  # www.ë¡œ ì‹œì‘í•˜ëŠ” ë§í¬
            r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}',  # ì´ë©”ì¼ ì£¼ì†Œ
            r'#\d+',                         # #123 í˜•íƒœì˜ í•´ì‹œíƒœê·¸
            r'@\w+',                         # @username í˜•íƒœì˜ ë©˜ì…˜
            r'\s+',                          # ì—°ì†ëœ ê³µë°± (ë‚˜ì¤‘ì— ì²˜ë¦¬)
        ]
        
        # ëª¨ë“  íŒ¨í„´ì„ í•˜ë‚˜ì˜ ì •ê·œì‹ìœ¼ë¡œ ì»´íŒŒì¼
        all_patterns = (
            self.bracket_patterns + 
            self.field_prefix_patterns + 
            self.date_patterns + 
            self.noise_patterns[:-1]  # ê³µë°± íŒ¨í„´ì€ ë³„ë„ ì²˜ë¦¬
        )
        
        self.compiled_patterns = [re.compile(pattern, re.IGNORECASE) for pattern in all_patterns]
        self.whitespace_pattern = re.compile(r'\s+')
    
    def preprocess_for_embedding(self, text: str) -> str:
        """
        ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            ì „ì²˜ë¦¬ëœ ê¹¨ë—í•œ í…ìŠ¤íŠ¸
        """
        if not text or not isinstance(text, str):
            return ""
        
        # ì›ë³¸ í…ìŠ¤íŠ¸ ë¡œê¹… (ë””ë²„ê¹…ìš©)
        original_text = text.strip()
        if len(original_text) > 100:
            logger.debug(f"ì „ì²˜ë¦¬ ì „: {original_text[:100]}...")
        else:
            logger.debug(f"ì „ì²˜ë¦¬ ì „: {original_text}")
        
        # 1. ê¸°ë³¸ ì •ë¦¬
        cleaned_text = original_text
        
        # 2. ëŒ€ê´„í˜¸ íŒ¨í„´ ì œê±°
        for pattern in self.compiled_patterns[:len(self.bracket_patterns)]:
            cleaned_text = pattern.sub('', cleaned_text)
        
        # 3. í•„ë“œ ì ‘ë‘ì‚¬ ì œê±°
        for pattern in self.compiled_patterns[len(self.bracket_patterns):len(self.bracket_patterns) + len(self.field_prefix_patterns)]:
            cleaned_text = pattern.sub('', cleaned_text)
        
        # 4. ë‚ ì§œ íŒ¨í„´ ì œê±°
        date_start = len(self.bracket_patterns) + len(self.field_prefix_patterns)
        date_end = date_start + len(self.date_patterns)
        for pattern in self.compiled_patterns[date_start:date_end]:
            cleaned_text = pattern.sub('', cleaned_text)
        
        # 5. ê¸°íƒ€ ë…¸ì´ì¦ˆ ì œê±° (URL, ì´ë©”ì¼ ë“±)
        noise_start = date_end
        for pattern in self.compiled_patterns[noise_start:]:
            cleaned_text = pattern.sub('', cleaned_text)
        
        # 6. ì—°ì†ëœ ê³µë°± ì •ë¦¬
        cleaned_text = self.whitespace_pattern.sub(' ', cleaned_text)
        
        # 7. ì•ë’¤ ê³µë°± ì œê±°
        cleaned_text = cleaned_text.strip()
        
        # ì „ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹… (ë””ë²„ê¹…ìš©)
        if len(cleaned_text) > 100:
            logger.debug(f"ì „ì²˜ë¦¬ í›„: {cleaned_text[:100]}...")
        else:
            logger.debug(f"ì „ì²˜ë¦¬ í›„: {cleaned_text}")
        
        # ì „ì²˜ë¦¬ íš¨ê³¼ ë¡œê¹…
        if len(original_text) != len(cleaned_text):
            reduction_ratio = (len(original_text) - len(cleaned_text)) / len(original_text) * 100
            logger.info(f"í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì™„ë£Œ: {len(original_text)} â†’ {len(cleaned_text)} ë¬¸ì ({reduction_ratio:.1f}% ê°ì†Œ)")
        
        return cleaned_text
    
    def preprocess_batch(self, texts: list) -> list:
        """
        ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ì¼ê´„ ì „ì²˜ë¦¬
        
        Args:
            texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        return [self.preprocess_for_embedding(text) for text in texts]
    
    def get_preprocessing_stats(self, original_text: str, cleaned_text: str) -> dict:
        """
        ì „ì²˜ë¦¬ í†µê³„ ì •ë³´ ë°˜í™˜
        
        Args:
            original_text: ì›ë³¸ í…ìŠ¤íŠ¸
            cleaned_text: ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
            
        Returns:
            ì „ì²˜ë¦¬ í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        if not original_text:
            return {}
        
        original_length = len(original_text)
        cleaned_length = len(cleaned_text)
        reduction_ratio = (original_length - cleaned_length) / original_length * 100 if original_length > 0 else 0
        
        # ì œê±°ëœ íŒ¨í„´ë“¤ ë¶„ì„
        removed_patterns = []
        
        # ëŒ€ê´„í˜¸ íŒ¨í„´ ì œê±° í™•ì¸
        for pattern in self.bracket_patterns:
            if re.search(pattern, original_text, re.IGNORECASE):
                removed_patterns.append(f"ëŒ€ê´„í˜¸ íŒ¨í„´: {pattern}")
        
        # í•„ë“œ ì ‘ë‘ì‚¬ ì œê±° í™•ì¸
        for pattern in self.field_prefix_patterns:
            if re.search(pattern, original_text, re.IGNORECASE):
                removed_patterns.append(f"í•„ë“œ ì ‘ë‘ì‚¬: {pattern}")
        
        # ë‚ ì§œ íŒ¨í„´ ì œê±° í™•ì¸
        for pattern in self.date_patterns:
            if re.search(pattern, original_text, re.IGNORECASE):
                removed_patterns.append(f"ë‚ ì§œ íŒ¨í„´: {pattern}")
        
        return {
            "original_length": original_length,
            "cleaned_length": cleaned_length,
            "reduction_ratio": reduction_ratio,
            "removed_patterns": removed_patterns,
            "text_shortened": original_length > cleaned_length
        }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
text_preprocessor = TextPreprocessor()


def preprocess_for_embedding(text: str) -> str:
    """
    ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬ ì œê±°ë¨)
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        
    Returns:
        ì›ë¬¸ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì „ì²˜ë¦¬ ì—†ìŒ)
    """
    # ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬ ì œê±°: ì›ë¬¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
    return text.strip() if text else ""
    
    # ê¸°ì¡´ ì „ì²˜ë¦¬ ì½”ë“œ (ì£¼ì„ ì²˜ë¦¬ë¨)
    # return text_preprocessor.preprocess_for_embedding(text)


def preprocess_batch_for_embedding(texts: list) -> list:
    """
    ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ì¼ê´„ ì „ì²˜ë¦¬ (ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬ ì œê±°ë¨)
    
    Args:
        texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ì›ë¬¸ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì „ì²˜ë¦¬ ì—†ìŒ)
    """
    # ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬ ì œê±°: ì›ë¬¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
    return [text.strip() if text else "" for text in texts]
    
    # ê¸°ì¡´ ì „ì²˜ë¦¬ ì½”ë“œ (ì£¼ì„ ì²˜ë¦¬ë¨)
    # return text_preprocessor.preprocess_batch(texts)


def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ§ª í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        "[NCMS] ì„œë²„ ì ‘ì† ë¶ˆê°€ ë¬¸ì œ",
        "ìš”ì•½: [BTVO-12345] ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìµœì í™” (5/8~12)",
        "ì„¤ëª…: ë©”ì¸ ì„œë²„ì— ì ‘ì†ì´ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. HTTP 500 ì˜¤ë¥˜ê°€ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        "[T-001] ì œëª©: ì‚¬ìš©ì ì¸ì¦ ì‹œìŠ¤í…œ ì˜¤ë¥˜ (2024-01-15)",
        "ëŒ“ê¸€: ê¹€ê°œë°œë‹˜ì´ ì‘ì„±í•œ ì½”ë©˜íŠ¸ì…ë‹ˆë‹¤. https://example.com ì°¸ê³ í•˜ì„¸ìš”.",
        "Summary: [PROJ-456] API ë¬¸ì„œ ì—…ë°ì´íŠ¸ (1ì›” 15ì¼)",
        "Description: ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸ì— ëŒ€í•œ ë¬¸ì„œë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. @admin í™•ì¸ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
        "ì´ìŠˆ í‚¤: BTVO-39373 ì œëª©: [BTVO-39373] [NCMS] release/5.3.44 Admin/API BMT (12/22)",
        "ë‚´ìš©: â€¢ ì´ìŠˆ ë° ë¬¸ì œì  release/5.3.44 Admin/API BMT (12/22) ìƒì„¸ ìš”ì²­ ë‚´ì—­ https://confluence.example.com",
        "Comment: ì´ ì‘ì—…ì€ ìš°ì„ ìˆœìœ„ê°€ ë†’ìŠµë‹ˆë‹¤. #urgent #bug"
    ]
    
    for i, test_text in enumerate(test_cases, 1):
        print(f"\n--- í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i} ---")
        print(f"ì›ë³¸: {test_text}")
        
        cleaned_text = preprocess_for_embedding(test_text)
        print(f"ì •ì œ: {cleaned_text}")
        
        # í†µê³„ ì •ë³´
        stats = text_preprocessor.get_preprocessing_stats(test_text, cleaned_text)
        if stats:
            print(f"í†µê³„: {stats['original_length']} â†’ {stats['cleaned_length']} ë¬¸ì ({stats['reduction_ratio']:.1f}% ê°ì†Œ)")
            if stats['removed_patterns']:
                print(f"ì œê±°ëœ íŒ¨í„´: {', '.join(stats['removed_patterns'][:3])}")  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
    
    print("\n" + "=" * 60)
    print("âœ… í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")


if __name__ == "__main__":
    main()
