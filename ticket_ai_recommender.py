#!/usr/bin/env python3
"""
í‹°ì¼“ AI ì¶”ì²œ ì‹œìŠ¤í…œ
ì •ì œëœ ë©”ì¼ + description + ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì—ê²Œ ë„˜ê²¨ì„œ 
í‹°ì¼“ ì²˜ë¦¬ ë°©ì•ˆì„ ì¶”ì²œí•˜ëŠ” ê¸°ëŠ¥
"""

import os
import json
from typing import Dict, Any, List, Optional
from datetime import datetime
from dotenv import load_dotenv

# Azure OpenAI ì„¤ì •
load_dotenv()

try:
    from openai import AzureOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# Multi-Vector + Cross-Encoder RAG import
try:
    from multi_vector_cross_encoder_rag import MultiVectorCrossEncoderRAG
    MULTI_VECTOR_RAG_AVAILABLE = True
except ImportError:
    MULTI_VECTOR_RAG_AVAILABLE = False

# MultiQueryRetriever import (fallback)
try:
    from multi_query_retriever import create_multi_query_search_manager
    MULTI_QUERY_AVAILABLE = True
except ImportError:
    MULTI_QUERY_AVAILABLE = False

# QueryExpansionRetriever import (fallback)
try:
    from query_expansion_retriever import create_query_expansion_retriever
    QUERY_EXPANSION_AVAILABLE = True
except ImportError:
    QUERY_EXPANSION_AVAILABLE = False

# HybridSearchRetriever import (fallback)
try:
    from retrieve_rerank_retriever_whoosh import create_retrieve_rerank_retriever_whoosh
    HYBRID_SEARCH_AVAILABLE = True
except ImportError:
    HYBRID_SEARCH_AVAILABLE = False

class TicketAIRecommender:
    """í‹°ì¼“ AI ì¶”ì²œ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.client = None
        self.multi_vector_rag = None
        self.multi_query_search_manager = None
        self.query_expansion_retriever = None
        self.retrieve_rerank_retriever = None
        
        if OPENAI_AVAILABLE:
            self._init_azure_openai()
        
        # Multi-Vector + Cross-Encoder RAG ìš°ì„  ì´ˆê¸°í™”
        if MULTI_VECTOR_RAG_AVAILABLE:
            self._init_multi_vector_rag()
        
        # í´ë°± ê²€ìƒ‰ ì‹œìŠ¤í…œë“¤
        if MULTI_QUERY_AVAILABLE:
            self._init_multi_query_search()
        
        if QUERY_EXPANSION_AVAILABLE:
            self._init_query_expansion_search()
        
        if HYBRID_SEARCH_AVAILABLE:
            self._init_hybrid_search()
    
    def _init_azure_openai(self):
        """Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            self.client = AzureOpenAI(
                api_key=os.getenv("AZURE_OPENAI_API_KEY"),
                api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview"),
                azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
            )
            print("âœ… Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.client = None
    
    def _init_multi_vector_rag(self):
        """Multi-Vector + Cross-Encoder RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self.multi_vector_rag = MultiVectorCrossEncoderRAG()
            print("âœ… Multi-Vector + Cross-Encoder RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ Multi-Vector + Cross-Encoder RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.multi_vector_rag = None
    
    def _init_multi_query_search(self):
        """MultiQuery ê²€ìƒ‰ ê´€ë¦¬ì ì´ˆê¸°í™”"""
        try:
            from vector_db_models import VectorDBManager
            vector_db = VectorDBManager()
            self.multi_query_search_manager = create_multi_query_search_manager(vector_db)
            print("âœ… MultiQuery ê²€ìƒ‰ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ MultiQuery ê²€ìƒ‰ ê´€ë¦¬ì ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.multi_query_search_manager = None
    
    def _init_query_expansion_search(self):
        """QueryExpansion ê²€ìƒ‰ ê´€ë¦¬ì ì´ˆê¸°í™”"""
        try:
            from vector_db_models import VectorDBManager
            vector_db = VectorDBManager()
            self.query_expansion_retriever = create_query_expansion_retriever(vector_db)
            print("âœ… QueryExpansion ê²€ìƒ‰ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ QueryExpansion ê²€ìƒ‰ ê´€ë¦¬ì ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.query_expansion_retriever = None
    
    def _init_hybrid_search(self):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê´€ë¦¬ì ì´ˆê¸°í™” (Whoosh ê¸°ë°˜)"""
        try:
            from vector_db_models import VectorDBManager
            vector_db = VectorDBManager()
            self.retrieve_rerank_retriever = create_retrieve_rerank_retriever_whoosh(vector_db)
            print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ (Whoosh ê¸°ë°˜)")
        except Exception as e:
            print(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê´€ë¦¬ì ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.retrieve_rerank_retriever = None
    
    def get_similar_tickets_with_rag(self, ticket_description: str, limit: int = 5) -> List[Dict[str, Any]]:
        """Multi-Vector + Cross-Encoder RAGë¥¼ ì‚¬ìš©í•œ ìœ ì‚¬ í‹°ì¼“ ê²€ìƒ‰"""
        try:
            if not self.multi_vector_rag:
                print("âš ï¸ Multi-Vector RAG ì‚¬ìš© ë¶ˆê°€, í´ë°± ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
                return self.get_similar_emails(ticket_description, limit)
            
            print(f"ğŸ” Multi-Vector + Cross-Encoder RAG ê²€ìƒ‰ ì‹œì‘: '{ticket_description}'")
            
            # Multi-Vector + Cross-Encoder RAG ê²€ìƒ‰
            results = self.multi_vector_rag.search(
                query=ticket_description,
                n_candidates=30,  # 1ë‹¨ê³„ í›„ë³´ ìˆ˜
                top_k=limit       # ìµœì¢… ê²°ê³¼ ìˆ˜
            )
            
            if not results:
                print("âš ï¸ RAG ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, í´ë°± ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
                return self.get_similar_emails(ticket_description, limit)
            
            print(f"âœ… Multi-Vector + Cross-Encoder RAG ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            
            # ê²°ê³¼ë¥¼ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            formatted_results = []
            for result in results:
                formatted_results.append({
                    "id": result.get("id", ""),
                    "content": result.get("content", ""),
                    "source": "multi_vector_rag",
                    "similarity_score": result.get("similarity_score", 0.0),
                    "metadata": result.get("metadata", {}),
                    "search_type": "multi_vector_cross_encoder",
                    "ticket_id": result.get("metadata", {}).get("ticket_id", ""),
                    "parent_ticket_id": result.get("metadata", {}).get("parent_ticket_id", ""),
                    "chunk_type": result.get("metadata", {}).get("chunk_type", ""),
                    "cross_encoder_score": result.get("metadata", {}).get("cross_encoder_score", 0.0)
                })
            
            return formatted_results
            
        except Exception as e:
            print(f"âŒ Multi-Vector RAG ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            print("ğŸ”„ í´ë°± ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜...")
            return self.get_similar_emails(ticket_description, limit)
    
    def get_similar_emails(self, ticket_description: str, limit: int = 5) -> List[Dict[str, Any]]:
        """Vector DBì—ì„œ ìœ ì‚¬í•œ ë©”ì¼ë“¤ì„ ê²€ìƒ‰ (QueryExpansion ìš°ì„  ì ìš©)"""
        try:
            # QueryExpansion ê²€ìƒ‰ ì‚¬ìš© (ìš°ì„ )
            if self.query_expansion_retriever:
                print(f"ğŸ” QueryExpansion ë©”ì¼ ê²€ìƒ‰ ì‹œì‘: '{ticket_description}'")
                results = self.query_expansion_retriever.search_with_expansion(
                    ticket_description, k=limit, search_type="mails"
                )
                print(f"âœ… QueryExpansion ë©”ì¼ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                
                # ê²°ê³¼ë¥¼ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                formatted_results = []
                for result in results:
                    formatted_results.append({
                        "message_id": result.get("id", ""),
                        "subject": result.get("metadata", {}).get("subject", ""),
                        "sender": result.get("metadata", {}).get("sender", ""),
                        "refined_content": result.get("content", ""),
                        "content_summary": result.get("metadata", {}).get("content_summary", ""),
                        "key_points": result.get("metadata", {}).get("key_points", []),
                        "similarity_score": result.get("similarity_score", 0.0),
                        "created_at": result.get("metadata", {}).get("created_at", ""),
                        "source_type": "email",
                        "expanded_query": result.get("expanded_query", ""),
                        "query_rank": result.get("query_rank", 1)
                    })
                return formatted_results
            
            # í´ë°±: MultiQuery ê²€ìƒ‰ ì‚¬ìš©
            elif self.multi_query_search_manager:
                print(f"ğŸ” MultiQuery ë©”ì¼ ê²€ìƒ‰ ì‹œì‘: '{ticket_description}'")
                results = self.multi_query_search_manager.search_mails(ticket_description, k=limit)
                print(f"âœ… MultiQuery ë©”ì¼ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                
                # ê²°ê³¼ë¥¼ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                formatted_results = []
                for result in results:
                    formatted_results.append({
                        "message_id": result.get("id", ""),
                        "subject": result.get("metadata", {}).get("subject", ""),
                        "sender": result.get("metadata", {}).get("sender", ""),
                        "refined_content": result.get("content", ""),
                        "content_summary": result.get("metadata", {}).get("content_summary", ""),
                        "key_points": result.get("metadata", {}).get("key_points", []),
                        "similarity_score": result.get("similarity_score", 0.0),
                        "created_at": result.get("metadata", {}).get("created_at", ""),
                        "source_type": "email"
                    })
                return formatted_results
            
            # í´ë°±: ê¸°ë³¸ ê²€ìƒ‰
            print("âš ï¸ MultiQuery ì‚¬ìš© ë¶ˆê°€, ê¸°ë³¸ ë©”ì¼ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±")
            from vector_db_models import VectorDBManager
            
            vector_db = VectorDBManager()
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
            similar_emails = vector_db.search_similar_mails(
                query=ticket_description,
                n_results=limit
            )
            
            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
            results = []
            for i, email in enumerate(similar_emails):
                # ìœ ì‚¬ë„ ì ìˆ˜ëŠ” ìˆœì„œì— ë”°ë¼ ê³„ì‚° (ì²« ë²ˆì§¸ê°€ ê°€ì¥ ìœ ì‚¬)
                similarity_score = max(0.0, 1.0 - (i * 0.1))
                
                results.append({
                    "message_id": email.message_id,
                    "subject": email.subject,
                    "sender": email.sender,
                    "refined_content": email.refined_content,
                    "content_summary": email.content_summary,
                    "key_points": email.key_points,
                    "similarity_score": similarity_score,
                    "created_at": email.created_at,
                    "source_type": "email"  # ì†ŒìŠ¤ íƒ€ì… ì¶”ê°€
                })
            
            print(f"âœ… ìœ ì‚¬ ë©”ì¼ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            print(f"âŒ ìœ ì‚¬ ë©”ì¼ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def get_similar_file_chunks(self, ticket_description: str, limit: int = 3) -> List[Dict[str, Any]]:
        """Vector DBì—ì„œ ìœ ì‚¬í•œ íŒŒì¼ ì²­í¬ë“¤ì„ ê²€ìƒ‰ (MultiQuery ì ìš©)"""
        try:
            # MultiQuery ê²€ìƒ‰ ì‚¬ìš©
            if self.multi_query_search_manager:
                print(f"ğŸ” MultiQuery íŒŒì¼ ì²­í¬ ê²€ìƒ‰ ì‹œì‘: '{ticket_description}'")
                results = self.multi_query_search_manager.search_file_chunks(ticket_description, k=limit)
                print(f"âœ… MultiQuery íŒŒì¼ ì²­í¬ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                
                # ê²°ê³¼ì— ì†ŒìŠ¤ íƒ€ì… ì¶”ê°€
                for result in results:
                    result["source_type"] = "file_chunk"
                
                return results
            
            # í´ë°±: ê¸°ë³¸ ê²€ìƒ‰
            print("âš ï¸ MultiQuery ì‚¬ìš© ë¶ˆê°€, ê¸°ë³¸ íŒŒì¼ ì²­í¬ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±")
            from vector_db_models import VectorDBManager
            
            vector_db = VectorDBManager()
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
            similar_chunks = vector_db.search_similar_file_chunks(
                query=ticket_description,
                n_results=limit
            )
            
            # ê²°ê³¼ì— ì†ŒìŠ¤ íƒ€ì… ì¶”ê°€
            for chunk in similar_chunks:
                chunk["source_type"] = "file_chunk"
            
            print(f"âœ… ìœ ì‚¬ íŒŒì¼ ì²­í¬ ê²€ìƒ‰ ì™„ë£Œ: {len(similar_chunks)}ê°œ ê²°ê³¼")
            return similar_chunks
            
        except Exception as e:
            print(f"âŒ ìœ ì‚¬ íŒŒì¼ ì²­í¬ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def get_integrated_similar_content(self, ticket_description: str, email_limit: int = 3, chunk_limit: int = 2) -> List[Dict[str, Any]]:
        """Multi-Vector + Cross-Encoder RAG ìš°ì„ , í´ë°±ìœ¼ë¡œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ í™œìš©í•œ ìœ ì‚¬í•œ ì½˜í…ì¸  ê²€ìƒ‰"""
        try:
            # Multi-Vector + Cross-Encoder RAG ìš°ì„  ì‹œë„
            if self.multi_vector_rag:
                print(f"ğŸ” Multi-Vector + Cross-Encoder RAG í†µí•© ê²€ìƒ‰ ì‹œì‘: '{ticket_description}'")
                rag_results = self.get_similar_tickets_with_rag(ticket_description, limit=5)
                
                if rag_results:
                    print(f"âœ… Multi-Vector + Cross-Encoder RAG ê²€ìƒ‰ ì™„ë£Œ: {len(rag_results)}ê°œ ê²°ê³¼")
                    return rag_results
                else:
                    print("âš ï¸ Multi-Vector RAG ê²°ê³¼ ì—†ìŒ, í´ë°± ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
            
            # í´ë°±: Retrieve then Re-rank ê²€ìƒ‰ ì‹œë„ (Vector + BM25 + CohereRerank)
            if self.retrieve_rerank_retriever:
                print(f"ğŸ” Retrieve then Re-rank ê²€ìƒ‰ ì‹œì‘: '{ticket_description}'")
                hybrid_results = self.retrieve_rerank_retriever.search(
                    query=ticket_description,
                    k=5
                )
                
                if hybrid_results:
                    print(f"âœ… Retrieve then Re-rank ê²€ìƒ‰ ì™„ë£Œ: {len(hybrid_results)}ê°œ ê²°ê³¼")
                    
                    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    formatted_results = []
                    for result in hybrid_results:
                        formatted_result = {
                            "id": result.get("id", ""),
                            "content": result.get("content", ""),
                            "source": result.get("source", "retrieve_rerank_whoosh"),
                            "similarity_score": result.get("similarity_score", 0.0),
                            "metadata": result.get("metadata", {}),
                            "search_type": result.get("search_type", "unknown")
                        }
                        formatted_results.append(formatted_result)
                    
                    return formatted_results
                else:
                    print("âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, QueryExpansionìœ¼ë¡œ í´ë°±")
            
            # í´ë°±: QueryExpansion ê²€ìƒ‰
            if self.query_expansion_retriever:
                print(f"ğŸ” QueryExpansion í†µí•© ê²€ìƒ‰ ì‹œì‘: '{ticket_description}'")
                expansion_results = self.query_expansion_retriever.search_with_expansion(
                    query=ticket_description,
                    k=5,
                    search_type="all"
                )
                
                if expansion_results:
                    print(f"âœ… QueryExpansion ê²€ìƒ‰ ì™„ë£Œ: {len(expansion_results)}ê°œ ê²°ê³¼")
                    
                    # QueryExpansion ê²°ê³¼ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    formatted_results = []
                    for result in expansion_results:
                        formatted_result = {
                            "id": result.get("id", ""),
                            "content": result.get("content", ""),
                            "source": result.get("source", "unknown"),
                            "similarity_score": result.get("similarity_score", 0.0),
                            "metadata": result.get("metadata", {}),
                            "expanded_query": result.get("expanded_query", ""),
                            "query_rank": result.get("query_rank", 1)
                        }
                        formatted_results.append(formatted_result)
                    
                    return formatted_results
                else:
                    print("âš ï¸ QueryExpansion ê²°ê³¼ ì—†ìŒ, MultiQueryë¡œ í´ë°±")
            
            # í´ë°±: MultiQuery êµ¬ì¡°ì  ì²­í‚¹ ê²€ìƒ‰
            if self.multi_query_search_manager:
                print(f"ğŸ” MultiQuery êµ¬ì¡°ì  ì²­í‚¹ ê²€ìƒ‰ ì‹œì‘: '{ticket_description}'")
                structured_results = self.multi_query_search_manager.search_structured_chunks(
                    query=ticket_description,
                    k=5,
                    chunk_types=['header'],  # í—¤ë” ì²­í¬ë§Œ ìš°ì„  ê²€ìƒ‰ (Summary + Description)
                    priority_filter=2  # ìš°ì„ ìˆœìœ„ 1-2ë§Œ (ë†’ì€ ìš°ì„ ìˆœìœ„)
                )
            else:
                # í´ë°±: ê¸°ë³¸ êµ¬ì¡°ì  ì²­í‚¹ ê²€ìƒ‰
                print("âš ï¸ MultiQuery ì‚¬ìš© ë¶ˆê°€, ê¸°ë³¸ êµ¬ì¡°ì  ì²­í‚¹ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±")
                from vector_db_models import VectorDBManager
                
                vector_db = VectorDBManager()
                
                # 1. êµ¬ì¡°ì  ì²­í‚¹ ê²€ìƒ‰ ìš°ì„  ì‹œë„
                print(f"ğŸ” êµ¬ì¡°ì  ì²­í‚¹ ê²€ìƒ‰ ì‹œì‘: '{ticket_description}'")
                structured_results = vector_db.search_structured_chunks(
                    query=ticket_description,
                    n_results=5,
                    chunk_types=['header'],  # í—¤ë” ì²­í¬ë§Œ ìš°ì„  ê²€ìƒ‰ (Summary + Description)
                    priority_filter=2  # ìš°ì„ ìˆœìœ„ 1-2ë§Œ (ë†’ì€ ìš°ì„ ìˆœìœ„)
                )
            
            if structured_results:
                print(f"âœ… êµ¬ì¡°ì  ì²­í‚¹ ê²€ìƒ‰ ì™„ë£Œ: {len(structured_results)}ê°œ ê²°ê³¼")
                
                # êµ¬ì¡°ì  ì²­í‚¹ ê²°ê³¼ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                formatted_results = []
                for result in structured_results:
                    formatted_result = {
                        "id": result["chunk_id"],
                        "content": result["content"],
                        "source": "structured_chunk",
                        "similarity_score": result["similarity_score"],
                        "metadata": {
                            "ticket_id": result["ticket_id"],
                            "chunk_type": result["chunk_type"],
                            "field_name": result["field_name"],
                            "priority": result["priority"],
                            "file_name": result["file_name"]
                        }
                    }
                    formatted_results.append(formatted_result)
                
                return formatted_results
            
            # 2. êµ¬ì¡°ì  ì²­í‚¹ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ Cohere Re-ranking ì‹œë„
            print("âš ï¸ êµ¬ì¡°ì  ì²­í‚¹ ê²°ê³¼ ì—†ìŒ, Cohere Re-rankingìœ¼ë¡œ í´ë°±...")
            try:
                from cohere_rerank_module import search_with_cohere_rerank
                
                # 1ì°¨ ê²€ìƒ‰ì—ì„œ ë” ë§ì€ í›„ë³´ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ k ì„¤ì •
                k = max(email_limit + chunk_limit, 20)
                
                print(f"ğŸ” Cohere Re-ranking ì••ì¶• ê²€ìƒ‰ ì‹œì‘: '{ticket_description}'")
                rerank_results = search_with_cohere_rerank(ticket_description, k=k)
                
                if rerank_results:
                    print(f"âœ… Cohere Re-ranking ê²€ìƒ‰ ì™„ë£Œ: {len(rerank_results)}ê°œ ê²°ê³¼")
                    return rerank_results
                else:
                    print("âš ï¸ Cohere Re-ranking ê²°ê³¼ê°€ ì—†ìŒ, ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±")
                    raise Exception("Cohere Re-ranking ê²°ê³¼ ì—†ìŒ")
                    
            except Exception as rerank_error:
                print(f"âš ï¸ Cohere Re-ranking ì‹¤íŒ¨: {str(rerank_error)}")
                print("ğŸ”„ ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ í´ë°±...")
                
                # í´ë°±: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                similar_emails = self.get_similar_emails(ticket_description, email_limit)
                similar_chunks = self.get_similar_file_chunks(ticket_description, chunk_limit)
                
                # ê²°ê³¼ í†µí•© ë° ì •ë ¬
                all_results = similar_emails + similar_chunks
                
                # ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
                all_results.sort(key=lambda x: x.get("similarity_score", 0.0), reverse=True)
                
                print(f"âœ… ê¸°ë³¸ í†µí•© ê²€ìƒ‰ ì™„ë£Œ: ë©”ì¼ {len(similar_emails)}ê°œ, íŒŒì¼ ì²­í¬ {len(similar_chunks)}ê°œ")
                return all_results
            
        except Exception as e:
            print(f"âŒ í†µí•© ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def generate_ai_recommendation(self, ticket_data: Dict[str, Any], similar_content: List[Dict[str, Any]]) -> Dict[str, Any]:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ í‹°ì¼“ ì²˜ë¦¬ ë°©ì•ˆ ì¶”ì²œ ìƒì„±"""
        if not self.client:
            return {
                "success": False,
                "error": "Azure OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "recommendation": "AI ì¶”ì²œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Azure OpenAI ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            }
        
        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_recommendation_prompt(ticket_data, similar_content)
            
            # Azure OpenAI API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì—…ë¬´ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” í‹°ì¼“ ì²˜ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í‹°ì¼“ ì •ë³´ì™€ ìœ ì‚¬í•œ ì‚¬ë¡€ë“¤ì„ ë¶„ì„í•˜ì—¬ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì²˜ë¦¬ ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            recommendation = response.choices[0].message.content
            
            return {
                "success": True,
                "recommendation": recommendation,
                "ticket_id": ticket_data.get("ticket_id"),
                "generated_at": datetime.now().isoformat(),
                "similar_content_count": len(similar_content)
            }
            
        except Exception as e:
            error_str = str(e)
            print(f"âŒ AI ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {error_str}")
            
            # ì½˜í…ì¸  í•„í„° ì˜¤ë¥˜ ì²˜ë¦¬
            if "content_filter" in error_str or "content management policy" in error_str:
                print("âš ï¸ Azure OpenAI ì½˜í…ì¸  í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë¨")
                return {
                    "success": False,
                    "error": "ì½˜í…ì¸  í•„í„°",
                    "recommendation": "ì´ í‹°ì¼“ì˜ ë‚´ìš©ì´ Azure OpenAI ì½˜í…ì¸  ì •ì±…ì— ì˜í•´ í•„í„°ë§ë˜ì—ˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œì„ ì‚¬ìš©í•©ë‹ˆë‹¤.",
                    "fallback": True
                }
            
            return {
                "success": False,
                "error": str(e),
                "recommendation": f"AI ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
    
    def _generate_keyword_based_recommendation(self, ticket_data: Dict[str, Any]) -> Dict[str, Any]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ì¶”ì²œ ìƒì„±"""
        try:
            title = ticket_data.get('title', '').lower()
            description = ticket_data.get('description', '').lower()
            content = f"{title} {description}"
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ ë¡œì§
            recommendations = []
            
            # ì„œë²„ ê´€ë ¨ í‚¤ì›Œë“œ
            if any(keyword in content for keyword in ['ì„œë²„', 'server', 'api', 'ì ê²€', 'ì—ëŸ¬', 'error']):
                recommendations.append("â€¢ ì„œë²„ ìƒíƒœ í™•ì¸ ë° ë¡œê·¸ ë¶„ì„ì„ ê¶Œì¥í•©ë‹ˆë‹¤")
                recommendations.append("â€¢ API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•´ë³´ì„¸ìš”")
                recommendations.append("â€¢ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë„êµ¬ë¥¼ í™œìš©í•˜ì„¸ìš”")
            
            # UI ê´€ë ¨ í‚¤ì›Œë“œ
            if any(keyword in content for keyword in ['ui', 'ì¸í„°í˜ì´ìŠ¤', 'í™”ë©´', 'ë²„íŠ¼', 'ì²´í¬ë°•ìŠ¤']):
                recommendations.append("â€¢ UI/UX ê°œì„ ì‚¬í•­ì„ ê²€í† í•´ë³´ì„¸ìš”")
                recommendations.append("â€¢ ì‚¬ìš©ì í”¼ë“œë°±ì„ ìˆ˜ì§‘í•˜ì„¸ìš”")
                recommendations.append("â€¢ ë””ìì¸ ì‹œìŠ¤í…œ ê°€ì´ë“œë¼ì¸ì„ í™•ì¸í•˜ì„¸ìš”")
            
            # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ í‚¤ì›Œë“œ
            if any(keyword in content for keyword in ['ë°ì´í„°ë² ì´ìŠ¤', 'database', 'db', 'ì¿¼ë¦¬', 'query']):
                recommendations.append("â€¢ ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”")
                recommendations.append("â€¢ ì¿¼ë¦¬ ì‹¤í–‰ ê³„íšì„ ë¶„ì„í•´ë³´ì„¸ìš”")
                recommendations.append("â€¢ ì¸ë±ìŠ¤ ìµœì í™”ë¥¼ ê²€í† í•˜ì„¸ìš”")
            
            # ë³´ì•ˆ ê´€ë ¨ í‚¤ì›Œë“œ
            if any(keyword in content for keyword in ['ë³´ì•ˆ', 'security', 'ì¸ì¦', 'auth', 'ê¶Œí•œ']):
                recommendations.append("â€¢ ë³´ì•ˆ ì •ì±…ì„ ì¬ê²€í† í•˜ì„¸ìš”")
                recommendations.append("â€¢ ì ‘ê·¼ ê¶Œí•œì„ ì ê²€í•´ë³´ì„¸ìš”")
                recommendations.append("â€¢ ë³´ì•ˆ ê°ì‚¬ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”")
            
            # ê¸°ë³¸ ì¶”ì²œ (í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš°)
            if not recommendations:
                recommendations = [
                    "â€¢ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€í† í•´ë³´ì„¸ìš”",
                    "â€¢ íŒ€ ë‚´ë¶€ ê²€í† ë¥¼ ì§„í–‰í•˜ì„¸ìš”",
                    "â€¢ ìš°ì„ ìˆœìœ„ë¥¼ ì¬í‰ê°€í•´ë³´ì„¸ìš”"
                ]
            
            return {
                "success": True,
                "recommendation": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ:\n" + "\n".join(recommendations),
                "ticket_id": ticket_data.get("ticket_id"),
                "generated_at": datetime.now().isoformat(),
                "method": "keyword_based"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                "recommendation": "ì¶”ì²œì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
    
    def _build_recommendation_prompt(self, ticket_data: Dict[str, Any], similar_content: List[Dict[str, Any]]) -> str:
        """ì¶”ì²œ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # í‹°ì¼“ ê¸°ë³¸ ì •ë³´
        ticket_info = f"""
=== í‹°ì¼“ ì •ë³´ ===
- ID: {ticket_data.get('ticket_id', 'N/A')}
- ì œëª©: {ticket_data.get('title', 'N/A')}
- ì„¤ëª…: {ticket_data.get('description', 'N/A')}
- ìƒíƒœ: {ticket_data.get('status', 'N/A')}
- ìš°ì„ ìˆœìœ„: {ticket_data.get('priority', 'N/A')}
- íƒ€ì…: {ticket_data.get('ticket_type', 'N/A')}
- ë‹´ë‹¹ì: {ticket_data.get('reporter', 'N/A')}
- ë ˆì´ë¸”: {', '.join(ticket_data.get('labels', []))}
"""
        
        # ì›ë³¸ ë©”ì¼ ì •ë³´
        original_mail = ticket_data.get('original_mail', {})
        mail_info = f"""
=== ì›ë³¸ ë©”ì¼ ì •ë³´ ===
- ë°œì‹ ì: {original_mail.get('sender', 'N/A')}
- ì œëª©: {original_mail.get('subject', 'N/A')}
- ì •ì œëœ ë‚´ìš©: {original_mail.get('refined_content', 'N/A')}
- ìš”ì•½: {original_mail.get('content_summary', 'N/A')}
- í•µì‹¬ í¬ì¸íŠ¸: {', '.join(original_mail.get('key_points', []))}
"""
        
        # ìœ ì‚¬ ì½˜í…ì¸  ì •ë³´ (RAG ê²€ìƒ‰ ê²°ê³¼ + ë©”ì¼ + íŒŒì¼ ì²­í¬)
        similar_info = ""
        if similar_content:
            similar_info = "\n=== ìœ ì‚¬í•œ ì‚¬ë¡€ë“¤ ===\n"
            
            # RAG ê²€ìƒ‰ ê²°ê³¼, ë©”ì¼, íŒŒì¼ ì²­í¬ë¥¼ ë¶„ë¦¬í•˜ì—¬ í‘œì‹œ
            rag_results = [item for item in similar_content if item.get('source') == 'multi_vector_rag']
            emails = [item for item in similar_content if item.get('source_type') == 'email']
            file_chunks = [item for item in similar_content if item.get('source_type') == 'file_chunk']
            
            # RAG ê²€ìƒ‰ ê²°ê³¼ ì •ë³´ (ìš°ì„  í‘œì‹œ)
            if rag_results:
                similar_info += "\nğŸ¯ AI ê²€ìƒ‰ ê²°ê³¼ (Multi-Vector + Cross-Encoder):\n"
                for i, result in enumerate(rag_results[:3], 1):  # ìƒìœ„ 3ê°œ ì‚¬ìš©
                    content_preview = result.get('content', '')[:300] + "..." if len(result.get('content', '')) > 300 else result.get('content', '')
                    similar_info += f"""
ê²€ìƒ‰ ê²°ê³¼ {i}:
- í‹°ì¼“ ID: {result.get('ticket_id', 'N/A')}
- ì²­í¬ íƒ€ì…: {result.get('chunk_type', 'N/A')}
- Cross-Encoder ì ìˆ˜: {result.get('cross_encoder_score', 0.0):.4f}
- ë‚´ìš©: {content_preview}
- ìœ ì‚¬ë„: {result.get('similarity_score', 0.0):.2f}
"""
            
            # ìœ ì‚¬ ë©”ì¼ ì •ë³´
            if emails:
                similar_info += "\nğŸ“§ ìœ ì‚¬í•œ ë©”ì¼ ì‚¬ë¡€:\n"
                for i, email in enumerate(emails[:2], 1):  # ìƒìœ„ 2ê°œë§Œ ì‚¬ìš©
                    similar_info += f"""
ë©”ì¼ ì‚¬ë¡€ {i}:
- ì œëª©: {email.get('subject', 'N/A')}
- ë°œì‹ ì: {email.get('sender', 'N/A')}
- ìš”ì•½: {email.get('content_summary', 'N/A')}
- ìœ ì‚¬ë„: {email.get('similarity_score', 0.0):.2f}
"""
            
            # ìœ ì‚¬ íŒŒì¼ ì²­í¬ ì •ë³´
            if file_chunks:
                similar_info += "\nğŸ“„ ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©:\n"
                for i, chunk in enumerate(file_chunks[:2], 1):  # ìƒìœ„ 2ê°œë§Œ ì‚¬ìš©
                    content_preview = chunk.get('content', '')[:200] + "..." if len(chunk.get('content', '')) > 200 else chunk.get('content', '')
                    similar_info += f"""
ë¬¸ì„œ ì‚¬ë¡€ {i}:
- íŒŒì¼ëª…: {chunk.get('file_name', 'N/A')}
- íŒŒì¼íƒ€ì…: {chunk.get('file_type', 'N/A')}
- ë‚´ìš©: {content_preview}
- ìœ ì‚¬ë„: {chunk.get('similarity_score', 0.0):.2f}
"""
        else:
            similar_info = "\n=== ìœ ì‚¬í•œ ì‚¬ë¡€ë“¤ ===\nìœ ì‚¬í•œ ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ìµœì¢… í”„ë¡¬í”„íŠ¸
        prompt = f"""
{ticket_info}

{mail_info}

{similar_info}

=== ìš”ì²­ì‚¬í•­ ===
ìœ„ í‹°ì¼“ ì •ë³´ì™€ AI ê²€ìƒ‰ ê²°ê³¼(ìœ ì‚¬í•œ í‹°ì¼“ ì‚¬ë¡€ë“¤)ë¥¼ ë¶„ì„í•˜ì—¬, ì´ í‹°ì¼“ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.

**íŠ¹íˆ AI ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì°¾ì€ ìœ ì‚¬í•œ í‹°ì¼“ë“¤ì˜ ì²˜ë¦¬ ë°©ì‹ì„ ì°¸ê³ í•˜ì—¬** ë‹¤ìŒ í•­ëª©ë“¤ì„ í¬í•¨í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”:

1. **ì¦‰ì‹œ ì²˜ë¦¬ ë°©ì•ˆ**: ìš°ì„ ì ìœ¼ë¡œ í•´ì•¼ í•  ì‘ì—…ë“¤
2. **ë‹¨ê³„ë³„ ì²˜ë¦¬ ê³„íš**: ì²´ê³„ì ì¸ ì²˜ë¦¬ ìˆœì„œ (ìœ ì‚¬ ì‚¬ë¡€ ì°¸ê³ )
3. **ì£¼ì˜ì‚¬í•­**: ì²˜ë¦¬ ì‹œ ê³ ë ¤í•´ì•¼ í•  ì ë“¤
4. **ì˜ˆìƒ ì†Œìš”ì‹œê°„**: ê° ë‹¨ê³„ë³„ ì˜ˆìƒ ì‹œê°„
5. **ê´€ë ¨ ë¶€ì„œ/ë‹´ë‹¹ì**: ì—°ë½ì´ í•„ìš”í•œ ë¶€ì„œë‚˜ ë‹´ë‹¹ì
6. **ì°¸ê³  ë¬¸ì„œ**: ê´€ë ¨ ë¬¸ì„œë‚˜ ìë£Œ í™œìš© ë°©ì•ˆ
7. **ìœ ì‚¬ ì‚¬ë¡€ í™œìš©**: AI ê²€ìƒ‰ ê²°ê³¼ì˜ ìœ ì‚¬í•œ í‹°ì¼“ ì²˜ë¦¬ ë°©ì‹ì„ ì–´ë–»ê²Œ ì ìš©í•  ìˆ˜ ìˆëŠ”ì§€

ë‹µë³€ì€ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        return prompt
    
    def get_recommendation_for_ticket(self, ticket_id: int) -> Dict[str, Any]:
        """íŠ¹ì • í‹°ì¼“ì— ëŒ€í•œ AI ì¶”ì²œ ìƒì„±"""
        try:
            # í‹°ì¼“ ì •ë³´ ì¡°íšŒ
            from sqlite_ticket_models import SQLiteTicketManager
            from vector_db_models import VectorDBManager
            
            ticket_manager = SQLiteTicketManager()
            vector_db = VectorDBManager()
            
            # í‹°ì¼“ ë°ì´í„° ì¡°íšŒ
            ticket = ticket_manager.get_ticket_by_id(ticket_id)
            if not ticket:
                return {
                    "success": False,
                    "error": f"í‹°ì¼“ {ticket_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "recommendation": "í‹°ì¼“ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # ì›ë³¸ ë©”ì¼ ì •ë³´ ì¡°íšŒ
            original_mail = vector_db.get_mail_by_id(ticket.original_message_id)
            mail_data = {}
            if original_mail:
                mail_data = {
                    "sender": original_mail.sender,
                    "subject": original_mail.subject,
                    "refined_content": original_mail.refined_content,
                    "content_summary": original_mail.content_summary,
                    "key_points": original_mail.key_points
                }
            
            # í‹°ì¼“ ë°ì´í„° êµ¬ì„±
            ticket_data = {
                "ticket_id": ticket.ticket_id,
                "title": ticket.title,
                "description": ticket.description,
                "status": ticket.status,
                "priority": ticket.priority,
                "ticket_type": ticket.ticket_type,
                "reporter": ticket.reporter,
                "labels": ticket.labels,
                "original_mail": mail_data
            }
            
            # í†µí•© ê²€ìƒ‰ (ë©”ì¼ + íŒŒì¼ ì²­í¬)
            search_query = f"{ticket.title} {ticket.description or ''}"
            similar_content = self.get_integrated_similar_content(search_query, email_limit=3, chunk_limit=2)
            
            # AI ì¶”ì²œ ìƒì„±
            recommendation = self.generate_ai_recommendation(ticket_data, similar_content)
            
            # ì½˜í…ì¸  í•„í„° ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œìœ¼ë¡œ í´ë°±
            if not recommendation.get("success") and recommendation.get("fallback"):
                print("ğŸ”„ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œìœ¼ë¡œ í´ë°±...")
                fallback_recommendation = self._generate_keyword_based_recommendation(ticket_data)
                if fallback_recommendation.get("success"):
                    return fallback_recommendation
            
            return recommendation
            
        except Exception as e:
            print(f"âŒ í‹°ì¼“ ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "recommendation": f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
ticket_ai_recommender = TicketAIRecommender()

def get_ticket_ai_recommendation(ticket_id: int) -> Dict[str, Any]:
    """í‹°ì¼“ AI ì¶”ì²œì„ ê°€ì ¸ì˜¤ëŠ” í¸ì˜ í•¨ìˆ˜"""
    return ticket_ai_recommender.get_recommendation_for_ticket(ticket_id)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª í‹°ì¼“ AI ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (Multi-Vector + Cross-Encoder RAG í†µí•©)")
    
    # ì²« ë²ˆì§¸ í‹°ì¼“ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    try:
        from sqlite_ticket_models import SQLiteTicketManager
        ticket_manager = SQLiteTicketManager()
        tickets = ticket_manager.get_all_tickets()
        
        if tickets:
            test_ticket_id = tickets[0].ticket_id
            print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ í‹°ì¼“ ID: {test_ticket_id}")
            
            # RAG ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
            recommender = TicketAIRecommender()
            if recommender.multi_vector_rag:
                print("âœ… Multi-Vector + Cross-Encoder RAG ì‹œìŠ¤í…œ í™œì„±í™”")
            else:
                print("âš ï¸ Multi-Vector RAG ì‹œìŠ¤í…œ ë¹„í™œì„±í™”, í´ë°± ëª¨ë“œ")
            
            recommendation = get_ticket_ai_recommendation(test_ticket_id)
            
            if recommendation.get("success"):
                print("âœ… AI ì¶”ì²œ ìƒì„± ì„±ê³µ!")
                print(f"ğŸ“ ì¶”ì²œ ë‚´ìš©:\n{recommendation.get('recommendation', 'N/A')}")
                print(f"ğŸ” ìœ ì‚¬ ì½˜í…ì¸  ìˆ˜: {recommendation.get('similar_content_count', 0)}ê°œ")
            else:
                print(f"âŒ AI ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {recommendation.get('error', 'N/A')}")
        else:
            print("âŒ í…ŒìŠ¤íŠ¸í•  í‹°ì¼“ì´ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
